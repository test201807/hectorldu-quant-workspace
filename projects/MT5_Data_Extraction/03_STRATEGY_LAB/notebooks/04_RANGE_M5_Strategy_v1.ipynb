{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae0fa76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Celda 00 RANGE v1.0.0] Manifest CREADO (nuevo): C:\\Quant\\projects\\MT5_Data_Extraction\\ER_STRATEGY_LAB\\notebooks\\outputs\\range_m5_strategy\\v1\\run_20260210_233822_645b77a6\\run_manifest_range_v1.json\n",
      "\n",
      "--- Celda 00 RANGE v1.0.0 | Estado final ---\n",
      "RUN_MODE   : NEW_RUN_DEFAULT\n",
      "RUN_ID     : 20260210_233822_645b77a6\n",
      "RUN_DIR    : C:\\Quant\\projects\\MT5_Data_Extraction\\ER_STRATEGY_LAB\\notebooks\\outputs\\range_m5_strategy\\v1\\run_20260210_233822_645b77a6\n",
      "N_ARTIFACTS: 37\n",
      "polars: 1.34.0\n",
      "\n",
      "[Celda 00 RANGE v1.0.0] OK\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# Celda 00 v1.0.0 — RANGE M5 Strategy: Run Manifest + Paths + Canonical Schema\n",
    "# Politica: siempre crea run nuevo por defecto.\n",
    "# Env vars: RANGE_M5_ROOT, RANGE_M5_OUTPUTS_ROOT, RANGE_M5_RUN_ID, RANGE_M5_RESUME_LATEST\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import platform\n",
    "import hashlib\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "# --- Unified path contract (single source of truth) ---\n",
    "for _p in [Path.cwd().resolve()] + list(Path.cwd().resolve().parents):\n",
    "    _contract = _p / \"shared\" / \"contracts\" / \"path_contract.py\"\n",
    "    if _contract.exists():\n",
    "        if str(_contract.parent) not in sys.path:\n",
    "            sys.path.insert(0, str(_contract.parent))\n",
    "        break\n",
    "import path_contract  # noqa: E402\n",
    "\n",
    "# --- Helpers ---\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "def _safe_mkdir(p: Path) -> None:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _write_json(path: Path, obj: Dict[str, Any]) -> None:\n",
    "    _safe_mkdir(path.parent)\n",
    "    path.write_text(json.dumps(obj, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "def _read_json(path: Path) -> Dict[str, Any]:\n",
    "    return json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "def _write_text(path: Path, text: str) -> None:\n",
    "    _safe_mkdir(path.parent)\n",
    "    path.write_text(text, encoding=\"utf-8\")\n",
    "\n",
    "def _read_text(path: Path) -> str:\n",
    "    return path.read_text(encoding=\"utf-8\").strip()\n",
    "\n",
    "def _sha1(s: str) -> str:\n",
    "    return hashlib.sha1(s.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def _env(name: str, default: Optional[str] = None) -> Optional[str]:\n",
    "    v = os.getenv(name)\n",
    "    return v if v not in (None, \"\") else default\n",
    "\n",
    "def _env_bool(name: str, default: bool = False) -> bool:\n",
    "    v = os.getenv(name, \"\")\n",
    "    if v is None or v.strip() == \"\":\n",
    "        return default\n",
    "    return v.strip().lower() in (\"1\", \"true\", \"yes\", \"y\")\n",
    "\n",
    "# --- Detect PROJECT_ROOT ---\n",
    "def _detect_project_root() -> Path:\n",
    "    forced = _env(\"RANGE_M5_ROOT\")\n",
    "    if forced:\n",
    "        return Path(forced).resolve()\n",
    "    return path_contract.detect_project_root()\n",
    "\n",
    "PROJECT_ROOT = _detect_project_root()\n",
    "\n",
    "# --- Paths ---\n",
    "WORKDIR = Path.cwd().resolve()\n",
    "OUTPUTS_ROOT = Path(_env(\"RANGE_M5_OUTPUTS_ROOT\", str(path_contract.range_outputs_dir(PROJECT_ROOT)))).resolve()\n",
    "LATEST_RUN_MARKER = OUTPUTS_ROOT / \"_latest_run.txt\"\n",
    "\n",
    "FORCED_RUN_ID = (_env(\"RANGE_M5_RUN_ID\") or \"\").strip() or None\n",
    "RESUME_LATEST = _env_bool(\"RANGE_M5_RESUME_LATEST\", default=False)\n",
    "\n",
    "def _new_run_id() -> str:\n",
    "    ts = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%S\")\n",
    "    salt = _sha1(f\"{ts}|{platform.node()}|{os.getpid()}\")[:8]\n",
    "    return f\"{ts}_{salt}\"\n",
    "\n",
    "if FORCED_RUN_ID:\n",
    "    RUN_MODE = \"FORCED_RUN_ID\"\n",
    "    RUN_ID = FORCED_RUN_ID\n",
    "elif RESUME_LATEST and LATEST_RUN_MARKER.exists():\n",
    "    RUN_MODE = \"RESUME_LATEST\"\n",
    "    RUN_ID = _read_text(LATEST_RUN_MARKER) or _new_run_id()\n",
    "else:\n",
    "    RUN_MODE = \"NEW_RUN_DEFAULT\"\n",
    "    RUN_ID = _new_run_id()\n",
    "\n",
    "RUN_DIR = OUTPUTS_ROOT / f\"run_{RUN_ID}\"\n",
    "RUN_MANIFEST_PATH = RUN_DIR / \"run_manifest_range_v1.json\"\n",
    "RUN_MANIFEST_LATEST_PATH = OUTPUTS_ROOT / \"run_manifest_range_v1_latest.json\"\n",
    "\n",
    "SCHEMA_VERSION = \"v1.0.0\"\n",
    "ENGINE_VERSION = \"v1.0.0\"\n",
    "\n",
    "CANONICAL_SCHEMA = {\n",
    "    \"ohlcv_m5\": {\n",
    "        \"required_columns\": [\"time_utc\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"spread\", \"symbol\"],\n",
    "    },\n",
    "    \"engine_trades\": {\n",
    "        \"required_columns\": [\n",
    "            \"symbol\", \"fold_id\", \"segment\", \"side\",\n",
    "            \"signal_time_utc\", \"entry_time_utc\", \"exit_time_utc\",\n",
    "            \"entry_price\", \"exit_price\",\n",
    "            \"gross_pnl\", \"net_pnl_base\", \"net_pnl_stress\",\n",
    "            \"hold_bars\", \"exit_reason\"\n",
    "        ],\n",
    "    }\n",
    "}\n",
    "\n",
    "def _build_artifacts(run_dir: Path) -> Dict[str, str]:\n",
    "    return {\n",
    "        \"instrument_specs\":        str(run_dir / \"instrument_specs_range_v1.parquet\"),\n",
    "        \"instrument_specs_snapshot\": str(run_dir / \"instrument_specs_snapshot_range_v1.json\"),\n",
    "        \"ohlcv_clean\":             str(run_dir / \"ohlcv_clean_m5.parquet\"),\n",
    "        \"data_qa_report\":          str(run_dir / \"data_qa_report_range_v1.json\"),\n",
    "        \"cost_model_snapshot\":     str(run_dir / \"cost_model_snapshot_range_v1.json\"),\n",
    "        \"wfo_folds\":               str(run_dir / \"wfo_folds_range_v1.parquet\"),\n",
    "        \"wfo_folds_snapshot\":      str(run_dir / \"wfo_folds_snapshot_range_v1.json\"),\n",
    "        \"features_m5\":             str(run_dir / \"features_m5_range_v1.parquet\"),\n",
    "        \"features_snapshot\":       str(run_dir / \"features_snapshot_range_v1.json\"),\n",
    "        \"regime_params_by_fold\":   str(run_dir / \"regime_params_by_fold_range_v1.parquet\"),\n",
    "        \"regime_params_snapshot\":  str(run_dir / \"regime_params_snapshot_range_v1.json\"),\n",
    "        \"signals_all\":             str(run_dir / \"signals_all_range_v1.parquet\"),\n",
    "        \"signals_snapshot\":        str(run_dir / \"signals_snapshot_range_v1.json\"),\n",
    "        \"qa_timing\":               str(run_dir / \"qa_timing_range_v1.parquet\"),\n",
    "        \"alpha_multi_horizon_report\": str(run_dir / \"alpha_multi_horizon_report_range_v1.parquet\"),\n",
    "        \"alpha_multi_horizon_snapshot\": str(run_dir / \"alpha_multi_horizon_snapshot_range_v1.json\"),\n",
    "        \"trades_engine\":           str(run_dir / \"trades_engine_range_v1.parquet\"),\n",
    "        \"summary_engine\":          str(run_dir / \"summary_engine_range_v1.parquet\"),\n",
    "        \"engine_qa_report\":        str(run_dir / \"engine_qa_report_range_v1.json\"),\n",
    "        \"equity_engine\":           str(run_dir / \"equity_curve_engine_range_v1.parquet\"),\n",
    "        \"engine_report_snapshot\":  str(run_dir / \"engine_report_snapshot_range_v1.json\"),\n",
    "        \"diagnostics\":             str(run_dir / \"diagnostics_range_v1.parquet\"),\n",
    "        \"diagnostics_snapshot\":    str(run_dir / \"diagnostics_snapshot_range_v1.json\"),\n",
    "        \"tuning_results\":          str(run_dir / \"tuning_results_range_v1.parquet\"),\n",
    "        \"tuning_best_params\":      str(run_dir / \"tuning_best_params_range_v1.parquet\"),\n",
    "        \"tuning_snapshot\":         str(run_dir / \"tuning_snapshot_range_v1.json\"),\n",
    "        \"alpha_design\":            str(run_dir / \"alpha_design_range_v1.parquet\"),\n",
    "        \"alpha_design_snapshot\":   str(run_dir / \"alpha_design_snapshot_range_v1.json\"),\n",
    "        \"overlay_trades\":          str(run_dir / \"overlay_trades_range_v1.parquet\"),\n",
    "        \"overlay_summary\":         str(run_dir / \"overlay_summary_range_v1.parquet\"),\n",
    "        \"overlay_snapshot\":        str(run_dir / \"overlay_snapshot_range_v1.json\"),\n",
    "        \"selection\":               str(run_dir / \"selection_range_v1.parquet\"),\n",
    "        \"selection_snapshot\":      str(run_dir / \"selection_snapshot_range_v1.json\"),\n",
    "        \"deploy_pack\":             str(run_dir / \"deploy_pack_range_v1.parquet\"),\n",
    "        \"deploy_pack_json\":        str(run_dir / \"deploy_pack_range_v1.json\"),\n",
    "        \"qa_alignment\":            str(run_dir / \"qa_alignment_range_v1.parquet\"),\n",
    "        \"qa_alignment_snapshot\":   str(run_dir / \"qa_alignment_snapshot_range_v1.json\"),\n",
    "    }\n",
    "\n",
    "def _build_manifest() -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"schema_version\": SCHEMA_VERSION, \"engine_version\": ENGINE_VERSION,\n",
    "        \"strategy\": \"RANGE_MEAN_REVERSION\",\n",
    "        \"run_mode\": RUN_MODE, \"run_id\": RUN_ID,\n",
    "        \"created_utc\": _now_utc_iso(),\n",
    "        \"project_root\": str(PROJECT_ROOT), \"workdir\": str(WORKDIR),\n",
    "        \"outputs_root\": str(OUTPUTS_ROOT), \"run_dir\": str(RUN_DIR),\n",
    "        \"artifacts\": _build_artifacts(RUN_DIR),\n",
    "        \"canonical_schema\": CANONICAL_SCHEMA,\n",
    "        \"runtime\": {\n",
    "            \"python\": sys.version.replace(\"\\n\", \" \"),\n",
    "            \"platform\": platform.platform(),\n",
    "            \"node\": platform.node(), \"pid\": os.getpid(),\n",
    "        },\n",
    "    }\n",
    "\n",
    "_safe_mkdir(RUN_DIR)\n",
    "_safe_mkdir(OUTPUTS_ROOT)\n",
    "\n",
    "manifest: Dict[str, Any]\n",
    "if RUN_MANIFEST_PATH.exists() and RUN_MODE in (\"RESUME_LATEST\", \"FORCED_RUN_ID\"):\n",
    "    manifest = _read_json(RUN_MANIFEST_PATH)\n",
    "    manifest[\"artifacts\"] = _build_artifacts(Path(manifest.get(\"run_dir\", str(RUN_DIR))))\n",
    "    _write_json(RUN_MANIFEST_PATH, manifest)\n",
    "    print(f\"[Celda 00 RANGE v1.0.0] Manifest CARGADO (resume): {RUN_MANIFEST_PATH}\")\n",
    "else:\n",
    "    manifest = _build_manifest()\n",
    "    _write_json(RUN_MANIFEST_PATH, manifest)\n",
    "    print(f\"[Celda 00 RANGE v1.0.0] Manifest CREADO (nuevo): {RUN_MANIFEST_PATH}\")\n",
    "\n",
    "_write_text(LATEST_RUN_MARKER, RUN_ID)\n",
    "_write_json(RUN_MANIFEST_LATEST_PATH, manifest)\n",
    "\n",
    "RUN: Dict[str, Any] = {\n",
    "    \"RUN_ID\": manifest[\"run_id\"],\n",
    "    \"RUN_MODE\": manifest[\"run_mode\"],\n",
    "    \"RUN_DIR\": Path(manifest[\"run_dir\"]),\n",
    "    \"PROJECT_ROOT\": Path(manifest[\"project_root\"]),\n",
    "    \"WORKDIR\": Path(manifest[\"workdir\"]),\n",
    "    \"OUTPUTS_ROOT\": Path(manifest[\"outputs_root\"]),\n",
    "    \"ARTIFACTS\": {k: Path(v) for k, v in manifest[\"artifacts\"].items()},\n",
    "    \"SCHEMA_VERSION\": manifest[\"schema_version\"],\n",
    "    \"ENGINE_VERSION\": manifest[\"engine_version\"],\n",
    "    \"CANONICAL_SCHEMA\": manifest[\"canonical_schema\"],\n",
    "}\n",
    "\n",
    "print(f\"\\n--- Celda 00 RANGE v1.0.0 | Estado final ---\")\n",
    "print(f\"RUN_MODE   : {RUN['RUN_MODE']}\")\n",
    "print(f\"RUN_ID     : {RUN['RUN_ID']}\")\n",
    "print(f\"RUN_DIR    : {RUN['RUN_DIR']}\")\n",
    "print(f\"N_ARTIFACTS: {len(RUN['ARTIFACTS'])}\")\n",
    "\n",
    "import polars as pl\n",
    "print(f\"polars: {pl.__version__}\")\n",
    "print(f\"\\n[Celda 00 RANGE v1.0.0] OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b8597f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Celda 01 RANGE v1.0.0 :: Universe + Instrument Specs\n",
      "[Celda 01] WARNING: basket_range_core no encontrado, usando fallback: ['EURUSD', 'GBPUSD', 'USDJPY', 'USDCHF', 'AUDCAD', 'EURGBP']\n",
      "[Celda 01] symbols (6): ['EURUSD', 'GBPUSD', 'USDJPY', 'USDCHF', 'AUDCAD', 'EURGBP']\n",
      "[Celda 01] OUT: C:\\Quant\\projects\\MT5_Data_Extraction\\ER_STRATEGY_LAB\\notebooks\\outputs\\range_m5_strategy\\v1\\run_20260210_233822_645b77a6\\instrument_specs_range_v1.parquet (6 rows)\n",
      ">>> Celda 01 RANGE v1.0.0 :: OK\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# Celda 01 v1.0.0 — Universe (RANGE) + Instrument Specs\n",
    "# --- Search for basket_range_core from NB2 outputs ---\n",
    "basket_path = path_contract.nb2_basket(\"range\", PROJECT_ROOT)\n",
    "\n",
    "# Fallback: legacy locations\n",
    "if basket_path is None:\n",
    "    _LEGACY_BASKETS = [\n",
    "        path_contract.nb2_outputs_dir(PROJECT_ROOT) / \"basket_range_core.parquet\",\n",
    "    ]\n",
    "    for p in _LEGACY_BASKETS:\n",
    "        if p.exists():\n",
    "            basket_path = p\n",
    "            break\n",
    "\n",
    "FALLBACK_SYMBOLS = [\"EURUSD\", \"GBPUSD\", \"USDJPY\", \"USDCHF\", \"AUDCAD\", \"EURGBP\"]\n",
    "\n",
    "if basket_path is not None:\n",
    "    print(f\"[Celda 01] basket_range_core encontrado: {basket_path}\")\n",
    "    basket_df = pl.read_parquet(basket_path)\n",
    "    if \"symbol\" in basket_df.columns:\n",
    "        symbols = basket_df.get_column(\"symbol\").unique().sort().to_list()\n",
    "    else:\n",
    "        symbols = FALLBACK_SYMBOLS\n",
    "        print(\"[Celda 01] WARNING: basket sin columna 'symbol', usando fallback.\")\n",
    "else:\n",
    "    symbols = FALLBACK_SYMBOLS\n",
    "    print(f\"[Celda 01] WARNING: basket_range_core no encontrado, usando fallback: {symbols}\")\n",
    "\n",
    "symbols = [s.upper().strip() for s in symbols]\n",
    "print(f\"[Celda 01] symbols ({len(symbols)}): {symbols}\")\n",
    "\n",
    "# --- Instrument specs ---\n",
    "# Default specs for common pairs / instruments\n",
    "DEFAULT_SPEC = {\n",
    "    \"asset_class\": \"forex\", \"point_value\": 1.0, \"tick_size\": 0.00001,\n",
    "    \"cost_base_bps\": 3.0, \"cost_stress_bps\": 6.0,\n",
    "    \"session_start_utc\": \"00:00\", \"session_end_utc\": \"23:59\",\n",
    "}\n",
    "\n",
    "OVERRIDES = {\n",
    "    \"XAUUSD\": {\"asset_class\": \"commodity\", \"point_value\": 100.0, \"tick_size\": 0.01, \"cost_base_bps\": 5.0, \"cost_stress_bps\": 10.0},\n",
    "    \"XAUAUD\": {\"asset_class\": \"commodity\", \"point_value\": 100.0, \"tick_size\": 0.01, \"cost_base_bps\": 5.0, \"cost_stress_bps\": 10.0},\n",
    "    \"USDJPY\": {\"tick_size\": 0.001, \"cost_base_bps\": 2.0, \"cost_stress_bps\": 4.0},\n",
    "    \"EURJPY\": {\"tick_size\": 0.001, \"cost_base_bps\": 3.0, \"cost_stress_bps\": 6.0},\n",
    "}\n",
    "\n",
    "specs_rows = []\n",
    "for sym in symbols:\n",
    "    spec = dict(DEFAULT_SPEC)\n",
    "    spec.update(OVERRIDES.get(sym, {}))\n",
    "    spec[\"symbol\"] = sym\n",
    "    specs_rows.append(spec)\n",
    "\n",
    "specs_df = pl.DataFrame(specs_rows)\n",
    "specs_df.write_parquet(str(OUT_SPECS), compression=\"zstd\")\n",
    "\n",
    "snap = {\n",
    "    \"created_utc\": _now_utc_iso(), \"version\": \"v1.0.0\",\n",
    "    \"symbols\": symbols, \"basket_source\": str(basket_path) if basket_path else \"FALLBACK\",\n",
    "    \"n_symbols\": len(symbols),\n",
    "}\n",
    "Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, ensure_ascii=False, default=str), encoding=\"utf-8\")\n",
    "\n",
    "RUN[\"symbols\"] = symbols\n",
    "RUN[\"instrument_specs\"] = {r[\"symbol\"]: r for r in specs_rows}\n",
    "\n",
    "print(f\"[Celda 01] OUT: {OUT_SPECS} ({specs_df.height} rows)\")\n",
    "print(\">>> Celda 01 RANGE v1.0.0 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e379f041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Celda 02 RANGE v1.0.0 :: Load M5 + QA\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[Celda 02] ERROR: no M5 data directory found. Run NB1+NB2 first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 95\u001b[39m\n\u001b[32m     93\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Celda 02] ERROR: no M5 data found for any symbol in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm5_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m[Celda 02] ERROR: no M5 data directory found. Run NB1+NB2 first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     97\u001b[39m Path(OUT_QA).write_text(json.dumps(qa_report, indent=\u001b[32m2\u001b[39m, default=\u001b[38;5;28mstr\u001b[39m), encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     98\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Celda 02] OUT: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUT_OHLCV\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqa_report.get(\u001b[33m'\u001b[39m\u001b[33mn_rows\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[32m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: [Celda 02] ERROR: no M5 data directory found. Run NB1+NB2 first."
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# Celda 02 v1.0.0 — Load M5 (m5_clean) + Canonicalize + QA (RANGE)\n",
    "# Identico patron a TREND v2 Cell 02: busca ohlcv_clean_m5.parquet de NB2 o construye.\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 02 RANGE v1.0.0 :: Load M5 + QA\")\n",
    "\n",
    "if \"RUN\" not in globals():\n",
    "    raise RuntimeError(\"[Celda 02] ERROR: RUN no existe.\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "PROJECT_ROOT: Path = RUN[\"PROJECT_ROOT\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "symbols = RUN.get(\"symbols\", [])\n",
    "\n",
    "OUT_OHLCV = ARTIFACTS[\"ohlcv_clean\"]\n",
    "OUT_QA = ARTIFACTS[\"data_qa_report\"]\n",
    "\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "# --- Search for M5 data ---\n",
    "M5_CANDIDATES = [\n",
    "    path_contract.m5_clean_dir(PROJECT_ROOT),   # data/historical_data/m5_clean\n",
    "    path_contract.m5_raw_dir(PROJECT_ROOT),      # data/bulk_data/m5_raw\n",
    "]\n",
    "M5_CANDIDATES = [c for c in M5_CANDIDATES if c is not None]\n",
    "\n",
    "# Also check for a single consolidated parquet from previous runs\n",
    "CONSOLIDATED_CANDIDATES = [\n",
    "    path_contract.nb2_outputs_dir(PROJECT_ROOT),\n",
    "]\n",
    "\n",
    "m5_dir = None\n",
    "for d in M5_CANDIDATES:\n",
    "    if d.exists() and any(d.glob(\"*.parquet\")):\n",
    "        m5_dir = d\n",
    "        break\n",
    "\n",
    "if m5_dir is None:\n",
    "    # Try finding individual symbol parquets anywhere under processed_data\n",
    "    pdata = PROJECT_ROOT / \"processed_data\"\n",
    "    if pdata.exists():\n",
    "        for sub in pdata.iterdir():\n",
    "            if sub.is_dir() and any(sub.glob(\"*m5*.parquet\")):\n",
    "                m5_dir = sub\n",
    "                break\n",
    "\n",
    "qa_report = {\"created_utc\": _now_utc_iso(), \"symbols_requested\": symbols}\n",
    "\n",
    "if OUT_OHLCV.exists():\n",
    "    print(f\"[Celda 02] Cache: usando {OUT_OHLCV}\")\n",
    "    df = pl.read_parquet(OUT_OHLCV)\n",
    "\n",
    "    # --- Column renames (NB1 compat) ---\n",
    "    _renames = {}\n",
    "    if \"timestamp_utc\" in df.columns and \"time_utc\" not in df.columns:\n",
    "        _renames[\"timestamp_utc\"] = \"time_utc\"\n",
    "    if \"tick_volume\" in df.columns and \"volume\" not in df.columns:\n",
    "        _renames[\"tick_volume\"] = \"volume\"\n",
    "    if \"spread_points\" in df.columns and \"spread\" not in df.columns:\n",
    "        _renames[\"spread_points\"] = \"spread\"\n",
    "    if _renames:\n",
    "        df = df.rename(_renames)\n",
    "    qa_report[\"status\"] = \"CACHED\"\n",
    "    qa_report[\"n_rows\"] = df.height\n",
    "elif m5_dir is not None:\n",
    "    print(f\"[Celda 02] M5 dir: {m5_dir}\")\n",
    "    dfs = []\n",
    "    for sym in symbols:\n",
    "        candidates = list(m5_dir.glob(f\"*{sym}*m5*.parquet\")) + list(m5_dir.glob(f\"*{sym.lower()}*m5*.parquet\"))\n",
    "        if not candidates:\n",
    "            candidates = list(m5_dir.glob(f\"*{sym}*.parquet\"))\n",
    "        if candidates:\n",
    "            df_sym = pl.read_parquet(candidates[0])\n",
    "            if \"symbol\" not in df_sym.columns:\n",
    "                df_sym = df_sym.with_columns(pl.lit(sym).alias(\"symbol\"))\n",
    "            dfs.append(df_sym)\n",
    "            print(f\"  {sym}: {candidates[0].name} ({df_sym.height} rows)\")\n",
    "        else:\n",
    "            print(f\"  {sym}: NOT FOUND in {m5_dir}\")\n",
    "\n",
    "    if dfs:\n",
    "        df = pl.concat(dfs, how=\"vertical_relaxed\")\n",
    "        # Canonicalize\n",
    "        required = [\"symbol\", \"time_utc\", \"open\", \"high\", \"low\", \"close\"]\n",
    "        for col in required:\n",
    "            if col not in df.columns:\n",
    "                raise RuntimeError(f\"[Celda 02] ERROR: columna {col} faltante. Columnas: {df.columns}\")\n",
    "        df = df.with_columns(pl.col(\"time_utc\").cast(pl.Datetime(\"us\", \"UTC\"), strict=False))\n",
    "        df = df.unique(subset=[\"symbol\", \"time_utc\"], keep=\"last\").sort([\"symbol\", \"time_utc\"])\n",
    "        df.write_parquet(str(OUT_OHLCV), compression=\"zstd\")\n",
    "        qa_report[\"status\"] = \"BUILT\"\n",
    "        qa_report[\"n_rows\"] = df.height\n",
    "        qa_report[\"n_symbols\"] = df.get_column(\"symbol\").n_unique()\n",
    "    else:\n",
    "        raise RuntimeError(f\"[Celda 02] ERROR: no M5 data found for any symbol in {m5_dir}\")\n",
    "else:\n",
    "    raise RuntimeError(\"[Celda 02] ERROR: no M5 data directory found. Run NB1+NB2 first.\")\n",
    "\n",
    "Path(OUT_QA).write_text(json.dumps(qa_report, indent=2, default=str), encoding=\"utf-8\")\n",
    "print(f\"[Celda 02] OUT: {OUT_OHLCV} ({qa_report.get('n_rows', 0)} rows)\")\n",
    "print(\">>> Celda 02 RANGE v1.0.0 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096c9152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# Celda 03 v1.0.0 — Cost Model (base/stress + slippage proxy) [RANGE]\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 03 RANGE v1.0.0 :: Cost Model\")\n",
    "\n",
    "if \"RUN\" not in globals():\n",
    "    raise RuntimeError(\"[Celda 03] ERROR: RUN no existe.\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "\n",
    "OUT_SNAP = ARTIFACTS[\"cost_model_snapshot\"]\n",
    "\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "specs = RUN.get(\"instrument_specs\", {})\n",
    "symbols = RUN.get(\"symbols\", [])\n",
    "\n",
    "costs_by_symbol = {}\n",
    "for sym in symbols:\n",
    "    s = specs.get(sym, {})\n",
    "    costs_by_symbol[sym] = {\n",
    "        \"cost_base_bps\": float(s.get(\"cost_base_bps\", 3.0)),\n",
    "        \"cost_stress_bps\": float(s.get(\"cost_stress_bps\", 6.0)),\n",
    "    }\n",
    "\n",
    "snap = {\n",
    "    \"created_utc\": _now_utc_iso(), \"version\": \"v1.0.0\",\n",
    "    \"strategy\": \"RANGE_MEAN_REVERSION\",\n",
    "    \"costs_by_symbol\": costs_by_symbol,\n",
    "    \"cost_reported_is_roundtrip\": True,\n",
    "}\n",
    "Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, default=str), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"[Celda 03] costs for {len(costs_by_symbol)} symbols\")\n",
    "for sym, c in costs_by_symbol.items():\n",
    "    print(f\"  {sym}: base={c['cost_base_bps']}bps stress={c['cost_stress_bps']}bps\")\n",
    "print(\">>> Celda 03 RANGE v1.0.0 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ab5cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# Celda 04 v1.0.0 — WFO Builder (IS=18m, OOS=3m, >=6 folds) [RANGE]\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from typing import Dict\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 04 RANGE v1.0.0 :: WFO Builder\")\n",
    "\n",
    "if \"RUN\" not in globals():\n",
    "    raise RuntimeError(\"[Celda 04] ERROR: RUN no existe.\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "\n",
    "OHLCV_PATH = ARTIFACTS[\"ohlcv_clean\"]\n",
    "OUT_FOLDS = ARTIFACTS[\"wfo_folds\"]\n",
    "OUT_SNAP = ARTIFACTS[\"wfo_folds_snapshot\"]\n",
    "\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "IS_MONTHS = 18\n",
    "OOS_MONTHS = 3\n",
    "EMBARGO_DAYS = 5\n",
    "MIN_FOLDS = 6\n",
    "\n",
    "df = pl.read_parquet(OHLCV_PATH)\n",
    "t_min = df.get_column(\"time_utc\").min()\n",
    "t_max = df.get_column(\"time_utc\").max()\n",
    "\n",
    "print(f\"[Celda 04] data range: {t_min} to {t_max}\")\n",
    "\n",
    "# Build folds\n",
    "folds = []\n",
    "fold_id = 1\n",
    "cursor = t_min\n",
    "\n",
    "while True:\n",
    "    is_start = cursor\n",
    "    is_end = is_start + timedelta(days=IS_MONTHS * 30)\n",
    "    embargo_end = is_end + timedelta(days=EMBARGO_DAYS)\n",
    "    oos_start = embargo_end\n",
    "    oos_end = oos_start + timedelta(days=OOS_MONTHS * 30)\n",
    "\n",
    "    if oos_end > t_max:\n",
    "        break\n",
    "\n",
    "    folds.append({\n",
    "        \"fold_id\": fold_id,\n",
    "        \"IS_start\": is_start,\n",
    "        \"IS_end\": is_end,\n",
    "        \"embargo_start\": is_end,\n",
    "        \"embargo_end\": embargo_end,\n",
    "        \"OOS_start\": oos_start,\n",
    "        \"OOS_end\": oos_end,\n",
    "        \"embargo_days\": EMBARGO_DAYS,\n",
    "    })\n",
    "    fold_id += 1\n",
    "    cursor = cursor + timedelta(days=OOS_MONTHS * 30)\n",
    "\n",
    "print(f\"[Celda 04] {len(folds)} folds generated (min={MIN_FOLDS})\")\n",
    "\n",
    "if len(folds) < MIN_FOLDS:\n",
    "    print(f\"[Celda 04] WARNING: {len(folds)} < {MIN_FOLDS} folds. Datos insuficientes.\")\n",
    "\n",
    "folds_df = pl.DataFrame(folds)\n",
    "folds_df.write_parquet(str(OUT_FOLDS), compression=\"zstd\")\n",
    "\n",
    "snap = {\n",
    "    \"created_utc\": _now_utc_iso(), \"version\": \"v1.0.0\",\n",
    "    \"IS_months\": IS_MONTHS, \"OOS_months\": OOS_MONTHS, \"embargo_days\": EMBARGO_DAYS,\n",
    "    \"n_folds\": len(folds),\n",
    "    \"folds_summary\": [{\"fold_id\": f[\"fold_id\"], \"IS_start\": str(f[\"IS_start\"]), \"OOS_end\": str(f[\"OOS_end\"])} for f in folds],\n",
    "}\n",
    "Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, default=str), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"[Celda 04] OUT: {OUT_FOLDS} ({folds_df.height} rows)\")\n",
    "print(\">>> Celda 04 RANGE v1.0.0 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16060e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# Celda 05 v1.0.0 — Feature Set (RANGE): Base + Bollinger %B + Distance-to-Mean\n",
    "# Extra features vs TREND: pct_b, dist_mean_atr, range_width_atr\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 05 RANGE v1.0.0 :: Feature Set (Range)\")\n",
    "\n",
    "if \"RUN\" not in globals():\n",
    "    raise RuntimeError(\"[Celda 05] ERROR: RUN no existe.\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "\n",
    "OHLCV_PATH = ARTIFACTS[\"ohlcv_clean\"]\n",
    "OUT_FEATURES = ARTIFACTS[\"features_m5\"]\n",
    "OUT_SNAP = ARTIFACTS[\"features_snapshot\"]\n",
    "\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "# Params\n",
    "ER_WIN = int(os.getenv(\"RANGE_M5_ER_WIN\", \"288\"))\n",
    "VOL_WIN = int(os.getenv(\"RANGE_M5_VOL_WIN\", \"288\"))\n",
    "MOM_WIN = int(os.getenv(\"RANGE_M5_MOM_WIN\", \"288\"))\n",
    "ATR_WIN = int(os.getenv(\"RANGE_M5_ATR_WIN\", \"96\"))\n",
    "BB_WIN = int(os.getenv(\"RANGE_M5_BB_WIN\", \"96\"))\n",
    "BB_STD = float(os.getenv(\"RANGE_M5_BB_STD\", \"2.0\"))\n",
    "MEAN_WIN = int(os.getenv(\"RANGE_M5_MEAN_WIN\", \"96\"))\n",
    "RANGE_WIN = int(os.getenv(\"RANGE_M5_RANGE_WIN\", \"96\"))\n",
    "EPS = 1e-12\n",
    "\n",
    "FORCE_REBUILD = os.getenv(\"RANGE_M5_FORCE_REBUILD_FEATURES\", \"\").strip().lower() in (\"1\", \"true\")\n",
    "\n",
    "if OUT_FEATURES.exists() and OUT_SNAP.exists() and not FORCE_REBUILD:\n",
    "    print(f\"[Celda 05] Cache: {OUT_FEATURES}\")\n",
    "else:\n",
    "    lf = (\n",
    "        pl.scan_parquet(OHLCV_PATH)\n",
    "        .select([\"symbol\", \"time_utc\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"spread\"])\n",
    "        .sort([\"symbol\", \"time_utc\"])\n",
    "    )\n",
    "\n",
    "    close_prev = pl.col(\"close\").shift(1).over(\"symbol\")\n",
    "    abs_diff_expr = (pl.col(\"close\") - close_prev).abs()\n",
    "    ret_expr = (\n",
    "        pl.when(close_prev.is_not_null() & (close_prev > 0))\n",
    "        .then(pl.col(\"close\") / close_prev - 1.0)\n",
    "        .otherwise(None)\n",
    "    )\n",
    "    tr_expr = pl.max_horizontal([\n",
    "        (pl.col(\"high\") - pl.col(\"low\")),\n",
    "        (pl.col(\"high\") - close_prev).abs(),\n",
    "        (pl.col(\"low\") - close_prev).abs(),\n",
    "    ])\n",
    "\n",
    "    lf1 = lf.with_columns([\n",
    "        ret_expr.alias(\"ret\"),\n",
    "        abs_diff_expr.alias(\"abs_diff\"),\n",
    "        tr_expr.alias(\"true_range\"),\n",
    "    ])\n",
    "\n",
    "    # Base features (same as TREND)\n",
    "    lf2 = lf1.with_columns([\n",
    "        (pl.col(\"ret\").rolling_std(window_size=VOL_WIN, min_samples=VOL_WIN).over(\"symbol\") * 10_000)\n",
    "            .alias(f\"vol_bps_{VOL_WIN}\"),\n",
    "        (pl.col(\"true_range\").rolling_mean(window_size=ATR_WIN, min_samples=ATR_WIN).over(\"symbol\") / pl.col(\"close\") * 10_000)\n",
    "            .alias(f\"atr_bps_{ATR_WIN}\"),\n",
    "        ((pl.col(\"close\") / pl.col(\"close\").shift(MOM_WIN).over(\"symbol\") - 1.0) * 10_000)\n",
    "            .alias(f\"mom_bps_{MOM_WIN}\"),\n",
    "        ((pl.col(\"close\") - pl.col(\"close\").shift(ER_WIN).over(\"symbol\")).abs() /\n",
    "         (pl.col(\"abs_diff\").rolling_sum(window_size=ER_WIN, min_samples=ER_WIN).over(\"symbol\") + EPS))\n",
    "            .alias(f\"er_{ER_WIN}\"),\n",
    "        # ATR in price units (for distance calculations)\n",
    "        pl.col(\"true_range\").rolling_mean(window_size=ATR_WIN, min_samples=ATR_WIN).over(\"symbol\")\n",
    "            .alias(\"atr_price\"),\n",
    "    ])\n",
    "\n",
    "    # Range-specific features\n",
    "    lf3 = lf2.with_columns([\n",
    "        # Bollinger Bands\n",
    "        pl.col(\"close\").rolling_mean(window_size=BB_WIN, min_samples=BB_WIN).over(\"symbol\").alias(\"bb_mid\"),\n",
    "        pl.col(\"close\").rolling_std(window_size=BB_WIN, min_samples=BB_WIN).over(\"symbol\").alias(\"bb_std\"),\n",
    "    ])\n",
    "\n",
    "    lf4 = lf3.with_columns([\n",
    "        # Bollinger %B: (close - lower) / (upper - lower)\n",
    "        ((pl.col(\"close\") - (pl.col(\"bb_mid\") - BB_STD * pl.col(\"bb_std\"))) /\n",
    "         (2.0 * BB_STD * pl.col(\"bb_std\") + EPS)).alias(\"pct_b\"),\n",
    "        # Distance to mean in ATR units\n",
    "        ((pl.col(\"close\") - pl.col(\"bb_mid\")) / (pl.col(\"atr_price\") + EPS)).alias(\"dist_mean_atr\"),\n",
    "        # Range width in ATR units (rolling high-low / ATR)\n",
    "        ((pl.col(\"high\").rolling_max(window_size=RANGE_WIN, min_samples=RANGE_WIN).over(\"symbol\") -\n",
    "          pl.col(\"low\").rolling_min(window_size=RANGE_WIN, min_samples=RANGE_WIN).over(\"symbol\")) /\n",
    "         (pl.col(\"atr_price\") + EPS)).alias(\"range_width_atr\"),\n",
    "    ])\n",
    "\n",
    "    lf_feat = lf4.select([\n",
    "        \"symbol\", \"time_utc\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"spread\",\n",
    "        \"ret\",\n",
    "        f\"vol_bps_{VOL_WIN}\", f\"atr_bps_{ATR_WIN}\", f\"mom_bps_{MOM_WIN}\", f\"er_{ER_WIN}\",\n",
    "        \"atr_price\",\n",
    "        \"pct_b\", \"dist_mean_atr\", \"range_width_atr\",\n",
    "    ]).sort([\"symbol\", \"time_utc\"])\n",
    "\n",
    "    df_feat = lf_feat.collect()\n",
    "\n",
    "    df_feat.write_parquet(str(OUT_FEATURES), compression=\"zstd\")\n",
    "\n",
    "    snap = {\n",
    "        \"created_utc\": _now_utc_iso(), \"version\": \"v1.0.0\",\n",
    "        \"params\": {\"ER_WIN\": ER_WIN, \"VOL_WIN\": VOL_WIN, \"MOM_WIN\": MOM_WIN, \"ATR_WIN\": ATR_WIN,\n",
    "                   \"BB_WIN\": BB_WIN, \"BB_STD\": BB_STD, \"MEAN_WIN\": MEAN_WIN, \"RANGE_WIN\": RANGE_WIN},\n",
    "        \"n_rows\": df_feat.height,\n",
    "        \"symbols\": df_feat.get_column(\"symbol\").unique().sort().to_list(),\n",
    "        \"schema_cols\": df_feat.columns,\n",
    "    }\n",
    "    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, default=str), encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"[Celda 05] Features: {df_feat.height} rows, {len(df_feat.columns)} cols\")\n",
    "    print(f\"[Celda 05] Cols: {df_feat.columns}\")\n",
    "\n",
    "print(f\"[Celda 05] OUT: {OUT_FEATURES}\")\n",
    "print(\">>> Celda 05 RANGE v1.0.0 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defd40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# Celda 06 v1.0.0 — Regime Gate (RANGE): Low ER + Low Vol = ranging market\n",
    "# Gate: ER <= thr_er_high AND vol <= thr_vol (sin threshold de momentum)\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json, math\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 06 RANGE v1.0.0 :: Regime Gate (ranging markets)\")\n",
    "\n",
    "if \"RUN\" not in globals():\n",
    "    raise RuntimeError(\"[Celda 06] ERROR: RUN no existe.\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "\n",
    "FEATURES_PATH = ARTIFACTS[\"features_m5\"]\n",
    "WFO_PATH = ARTIFACTS[\"wfo_folds\"]\n",
    "\n",
    "OUT_REGIME = ARTIFACTS[\"regime_params_by_fold\"]\n",
    "OUT_SNAP = ARTIFACTS[\"regime_params_snapshot\"]\n",
    "\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "ER_COL = \"er_288\"\n",
    "VOL_COL = \"vol_bps_288\"\n",
    "\n",
    "# RANGE gate: ER <= threshold (low efficiency = ranging)\n",
    "Q_ER_HIGH = 0.40   # ER at or below 40th percentile = ranging\n",
    "Q_VOL = 0.90       # vol below 90th percentile = not volatile\n",
    "\n",
    "COV_IS_MIN = 0.10\n",
    "COV_IS_MAX = 0.80\n",
    "MIN_IS_ROWS = 5_000\n",
    "\n",
    "def _q_safe(s, q):\n",
    "    s2 = s.drop_nulls()\n",
    "    if s2.len() == 0: return None\n",
    "    v = s2.quantile(q, interpolation=\"nearest\")\n",
    "    if v is None: return None\n",
    "    fv = float(v)\n",
    "    return fv if math.isfinite(fv) else None\n",
    "\n",
    "df_feat = pl.read_parquet(FEATURES_PATH)\n",
    "df_folds = pl.read_parquet(WFO_PATH)\n",
    "\n",
    "symbols = df_feat.get_column(\"symbol\").unique().sort().to_list()\n",
    "fold_ids = df_folds.get_column(\"fold_id\").unique().sort().to_list()\n",
    "\n",
    "rows = []\n",
    "for sym in symbols:\n",
    "    df_sym = df_feat.filter(pl.col(\"symbol\") == sym).sort(\"time_utc\")\n",
    "    for fid in fold_ids:\n",
    "        fold_row = df_folds.filter(pl.col(\"fold_id\") == fid).row(0, named=True)\n",
    "        is_s, is_e = fold_row[\"IS_start\"], fold_row[\"IS_end\"]\n",
    "        oos_s, oos_e = fold_row[\"OOS_start\"], fold_row[\"OOS_end\"]\n",
    "\n",
    "        df_is = df_sym.filter(\n",
    "            (pl.col(\"time_utc\") >= is_s) & (pl.col(\"time_utc\") <= is_e)\n",
    "        ).drop_nulls([ER_COL, VOL_COL])\n",
    "\n",
    "        df_oos = df_sym.filter(\n",
    "            (pl.col(\"time_utc\") >= oos_s) & (pl.col(\"time_utc\") <= oos_e)\n",
    "        ).drop_nulls([ER_COL, VOL_COL])\n",
    "\n",
    "        for side in (\"LONG\", \"SHORT\"):\n",
    "            if df_is.height < MIN_IS_ROWS:\n",
    "                rows.append({\"symbol\": sym, \"fold_id\": fid, \"side\": side, \"scheme\": \"SKIP\",\n",
    "                            \"thr_er_high\": None, \"thr_vol\": None, \"cov_is\": 0.0, \"cov_oos\": 0.0,\n",
    "                            \"n_is\": df_is.height, \"n_oos\": df_oos.height})\n",
    "                continue\n",
    "\n",
    "            thr_er = _q_safe(df_is.get_column(ER_COL), Q_ER_HIGH)\n",
    "            thr_vol = _q_safe(df_is.get_column(VOL_COL), Q_VOL)\n",
    "\n",
    "            if thr_er is None or thr_vol is None:\n",
    "                rows.append({\"symbol\": sym, \"fold_id\": fid, \"side\": side, \"scheme\": \"FAIL\",\n",
    "                            \"thr_er_high\": None, \"thr_vol\": None, \"cov_is\": 0.0, \"cov_oos\": 0.0,\n",
    "                            \"n_is\": df_is.height, \"n_oos\": df_oos.height})\n",
    "                continue\n",
    "\n",
    "            gate = (pl.col(ER_COL) <= thr_er) & (pl.col(VOL_COL) <= thr_vol)\n",
    "            cov_is = float(df_is.select(gate.mean()).item())\n",
    "            cov_oos = float(df_oos.select(gate.mean()).item()) if df_oos.height > 0 else 0.0\n",
    "\n",
    "            rows.append({\n",
    "                \"symbol\": sym, \"fold_id\": fid, \"side\": side, \"scheme\": \"BASE\",\n",
    "                \"thr_er_high\": float(thr_er), \"thr_vol\": float(thr_vol),\n",
    "                \"cov_is\": cov_is, \"cov_oos\": cov_oos,\n",
    "                \"n_is\": df_is.height, \"n_oos\": df_oos.height,\n",
    "            })\n",
    "            print(f\"[Celda 06] {sym} fold={fid} {side}: cov_IS={cov_is:.3f} cov_OOS={cov_oos:.3f}\")\n",
    "\n",
    "gate_df = pl.DataFrame(rows).sort([\"symbol\", \"fold_id\", \"side\"])\n",
    "gate_df.write_parquet(str(OUT_REGIME), compression=\"zstd\")\n",
    "\n",
    "snap = {\"created_utc\": _now_utc_iso(), \"version\": \"v1.0.0\",\n",
    "        \"gate_type\": \"RANGE (ER<=thr, vol<=thr)\",\n",
    "        \"params\": {\"Q_ER_HIGH\": Q_ER_HIGH, \"Q_VOL\": Q_VOL}}\n",
    "Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, default=str), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"\\n[Celda 06] OUT: {OUT_REGIME} ({gate_df.height} rows)\")\n",
    "print(\">>> Celda 06 RANGE v1.0.0 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd71f11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# Celda 07 v1.0.0 — Senales RANGE (Mean-Reversion) + Ejecucion t+1 + Costos\n",
    "# LONG: dist_mean_atr <= -BAND_K (precio debajo de mean)\n",
    "# SHORT: dist_mean_atr >= +BAND_K\n",
    "# BAND_K = 1.5\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 07 RANGE v1.0.0 :: Senales Mean-Reversion\")\n",
    "\n",
    "if \"RUN\" not in globals():\n",
    "    raise RuntimeError(\"[Celda 07] ERROR: RUN no existe.\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "\n",
    "FEATURES_PATH = ARTIFACTS[\"features_m5\"]\n",
    "WFO_PATH = ARTIFACTS[\"wfo_folds\"]\n",
    "REGIME_PATH = ARTIFACTS[\"regime_params_by_fold\"]\n",
    "COST_SNAP_PATH = ARTIFACTS[\"cost_model_snapshot\"]\n",
    "\n",
    "OUT_SIGNALS = ARTIFACTS[\"signals_all\"]\n",
    "OUT_SNAP = ARTIFACTS[\"signals_snapshot\"]\n",
    "\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "ER_COL = \"er_288\"\n",
    "VOL_COL = \"vol_bps_288\"\n",
    "DIST_COL = \"dist_mean_atr\"\n",
    "BAND_K = 1.5\n",
    "\n",
    "df_feat = pl.read_parquet(FEATURES_PATH)\n",
    "df_folds = pl.read_parquet(WFO_PATH)\n",
    "df_regime = pl.read_parquet(REGIME_PATH)\n",
    "cost_snap = json.loads(Path(COST_SNAP_PATH).read_text(encoding=\"utf-8\"))\n",
    "costs_by_sym = cost_snap.get(\"costs_by_symbol\", {})\n",
    "\n",
    "symbols = df_feat.get_column(\"symbol\").unique().sort().to_list()\n",
    "fold_ids = df_folds.get_column(\"fold_id\").unique().sort().to_list()\n",
    "\n",
    "all_trades = []\n",
    "for sym in symbols:\n",
    "    df_sym = df_feat.filter(pl.col(\"symbol\") == sym).sort(\"time_utc\")\n",
    "    cinfo = costs_by_sym.get(sym, {})\n",
    "    cost_base_rt = float(cinfo.get(\"cost_base_bps\", 3.0)) / 10_000\n",
    "    cost_stress_rt = float(cinfo.get(\"cost_stress_bps\", 6.0)) / 10_000\n",
    "\n",
    "    for fid in fold_ids:\n",
    "        fold_row = df_folds.filter(pl.col(\"fold_id\") == fid).row(0, named=True)\n",
    "        is_s, is_e = fold_row[\"IS_start\"], fold_row[\"IS_end\"]\n",
    "        oos_s, oos_e = fold_row[\"OOS_start\"], fold_row[\"OOS_end\"]\n",
    "\n",
    "        for side in (\"LONG\", \"SHORT\"):\n",
    "            rg = df_regime.filter(\n",
    "                (pl.col(\"symbol\") == sym) & (pl.col(\"fold_id\") == fid) & (pl.col(\"side\") == side)\n",
    "            )\n",
    "            if rg.is_empty():\n",
    "                continue\n",
    "            rg_row = rg.row(0, named=True)\n",
    "            if rg_row.get(\"thr_er_high\") is None:\n",
    "                continue\n",
    "\n",
    "            thr_er = float(rg_row[\"thr_er_high\"])\n",
    "            thr_vol = float(rg_row[\"thr_vol\"])\n",
    "\n",
    "            # Regime gate (ranging market)\n",
    "            regime_gate = (pl.col(ER_COL) <= thr_er) & (pl.col(VOL_COL) <= thr_vol)\n",
    "\n",
    "            # Mean-reversion signal\n",
    "            if side == \"LONG\":\n",
    "                signal_gate = regime_gate & (pl.col(DIST_COL) <= -BAND_K)\n",
    "            else:\n",
    "                signal_gate = regime_gate & (pl.col(DIST_COL) >= BAND_K)\n",
    "\n",
    "            dfx = (\n",
    "                df_sym\n",
    "                .with_columns(signal_gate.alias(\"signal_gate\"))\n",
    "                .with_columns([\n",
    "                    pl.col(\"time_utc\").shift(-1).alias(\"entry_time\"),\n",
    "                    pl.col(\"time_utc\").shift(-2).alias(\"exit_time\"),\n",
    "                    pl.col(\"open\").shift(-1).alias(\"entry_price\"),\n",
    "                    pl.col(\"open\").shift(-2).alias(\"exit_price\"),\n",
    "                ])\n",
    "                .filter(pl.col(\"signal_gate\"))\n",
    "                .filter(pl.col(\"entry_price\").is_not_null() & pl.col(\"exit_price\").is_not_null())\n",
    "                .filter((pl.col(\"entry_price\") > 0) & (pl.col(\"exit_price\") > 0))\n",
    "            )\n",
    "\n",
    "            seg_expr = (\n",
    "                pl.when((pl.col(\"entry_time\") >= is_s) & (pl.col(\"entry_time\") <= is_e)).then(pl.lit(\"IS\"))\n",
    "                .when((pl.col(\"entry_time\") >= oos_s) & (pl.col(\"entry_time\") <= oos_e)).then(pl.lit(\"OOS\"))\n",
    "                .otherwise(pl.lit(None))\n",
    "            )\n",
    "\n",
    "            sign = 1.0 if side == \"LONG\" else -1.0\n",
    "            dfx = (\n",
    "                dfx\n",
    "                .with_columns([\n",
    "                    seg_expr.alias(\"segment\"),\n",
    "                    pl.lit(sym).alias(\"_sym\"), pl.lit(fid).alias(\"_fid\"), pl.lit(side).alias(\"_side\"),\n",
    "                    (sign * (pl.col(\"exit_price\") / pl.col(\"entry_price\") - 1.0)).alias(\"gross_ret\"),\n",
    "                ])\n",
    "                .filter(pl.col(\"segment\").is_not_null())\n",
    "                .with_columns([\n",
    "                    (pl.col(\"gross_ret\") - cost_base_rt).alias(\"net_ret_base\"),\n",
    "                    (pl.col(\"gross_ret\") - cost_stress_rt).alias(\"net_ret_stress\"),\n",
    "                ])\n",
    "                .select([\n",
    "                    pl.col(\"_sym\").alias(\"symbol\"), pl.col(\"_fid\").alias(\"fold_id\"),\n",
    "                    \"segment\", pl.col(\"_side\").alias(\"side\"),\n",
    "                    pl.col(\"time_utc\").alias(\"signal_time\"),\n",
    "                    \"entry_time\", \"exit_time\", \"entry_price\", \"exit_price\",\n",
    "                    \"gross_ret\", \"net_ret_base\", \"net_ret_stress\",\n",
    "                    ER_COL, VOL_COL, DIST_COL,\n",
    "                ])\n",
    "            )\n",
    "            if dfx.height > 0:\n",
    "                all_trades.append(dfx)\n",
    "                print(f\"[Celda 07] {sym} fold={fid} {side}: {dfx.height} signals\")\n",
    "\n",
    "if not all_trades:\n",
    "    raise RuntimeError(\"[Celda 07] GATE FAIL: 0 signals.\")\n",
    "\n",
    "signals_df = pl.concat(all_trades, how=\"vertical_relaxed\").sort([\"symbol\", \"fold_id\", \"signal_time\"])\n",
    "signals_df.write_parquet(str(OUT_SIGNALS), compression=\"zstd\")\n",
    "\n",
    "snap = {\"created_utc\": _now_utc_iso(), \"version\": \"v1.0.0\", \"n_signals\": signals_df.height,\n",
    "        \"strategy\": \"MEAN_REVERSION\", \"BAND_K\": BAND_K}\n",
    "Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, default=str), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"\\n[Celda 07] OUT: {OUT_SIGNALS} ({signals_df.height} rows)\")\n",
    "print(\">>> Celda 07 RANGE v1.0.0 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929faa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# Celda 08 v1.0.0 — QA Timing Trades [RANGE]\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 08 RANGE v1.0.0 :: QA Timing\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "SIGNALS_PATH = ARTIFACTS[\"signals_all\"]\n",
    "OUT_QA = ARTIFACTS[\"qa_timing\"]\n",
    "\n",
    "df = pl.read_parquet(SIGNALS_PATH)\n",
    "df = df.with_columns([\n",
    "    ((pl.col(\"entry_time\") - pl.col(\"signal_time\")).dt.total_seconds()).alias(\"dt_entry_s\"),\n",
    "    ((pl.col(\"exit_time\") - pl.col(\"entry_time\")).dt.total_seconds()).alias(\"dt_hold_s\"),\n",
    "])\n",
    "\n",
    "qa = (\n",
    "    df.group_by([\"symbol\", \"segment\"])\n",
    "    .agg([\n",
    "        pl.len().alias(\"n\"),\n",
    "        pl.col(\"dt_entry_s\").median().alias(\"dt_entry_med\"),\n",
    "        pl.col(\"dt_hold_s\").median().alias(\"dt_hold_med\"),\n",
    "        pl.col(\"dt_hold_s\").quantile(0.90, interpolation=\"nearest\").alias(\"dt_hold_p90\"),\n",
    "        pl.col(\"dt_hold_s\").max().alias(\"dt_hold_max\"),\n",
    "    ])\n",
    "    .sort([\"symbol\", \"segment\"])\n",
    ")\n",
    "qa.write_parquet(str(OUT_QA), compression=\"zstd\")\n",
    "print(qa)\n",
    "print(\">>> Celda 08 RANGE v1.0.0 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f7f221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# Celda 09 v1.0.0 — Alpha Multi-Horizon Report [RANGE]\n",
    "# Shorter horizons: [1, 3, 6, 12, 24, 48, 96]\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 09 RANGE v1.0.0 :: Alpha Multi-Horizon\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "\n",
    "FEATURES_PATH = ARTIFACTS[\"features_m5\"]\n",
    "WFO_PATH = ARTIFACTS[\"wfo_folds\"]\n",
    "REGIME_PATH = ARTIFACTS[\"regime_params_by_fold\"]\n",
    "COST_SNAP_PATH = ARTIFACTS[\"cost_model_snapshot\"]\n",
    "\n",
    "OUT_ALPHA = ARTIFACTS[\"alpha_multi_horizon_report\"]\n",
    "OUT_SNAP = ARTIFACTS[\"alpha_multi_horizon_snapshot\"]\n",
    "\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "HORIZONS = [1, 3, 6, 12, 24, 48, 96]\n",
    "ER_COL = \"er_288\"\n",
    "VOL_COL = \"vol_bps_288\"\n",
    "DIST_COL = \"dist_mean_atr\"\n",
    "BAND_K = 1.5\n",
    "\n",
    "df_feat = pl.read_parquet(FEATURES_PATH)\n",
    "df_folds = pl.read_parquet(WFO_PATH)\n",
    "df_regime = pl.read_parquet(REGIME_PATH)\n",
    "cost_snap = json.loads(Path(COST_SNAP_PATH).read_text(encoding=\"utf-8\"))\n",
    "costs_by_sym = cost_snap.get(\"costs_by_symbol\", {})\n",
    "\n",
    "symbols = df_feat.get_column(\"symbol\").unique().sort().to_list()\n",
    "fold_ids = df_folds.get_column(\"fold_id\").unique().sort().to_list()\n",
    "\n",
    "# Precompute fwd returns\n",
    "for h in HORIZONS:\n",
    "    df_feat = df_feat.with_columns(\n",
    "        (pl.col(\"close\").shift(-h).over(\"symbol\") / pl.col(\"close\") - 1.0).alias(f\"fwd_{h}\")\n",
    "    )\n",
    "df_feat = df_feat.with_columns(pl.col(\"time_utc\").dt.weekday().alias(\"_dow\")).filter(pl.col(\"_dow\") <= 5)\n",
    "\n",
    "rows = []\n",
    "for sym in symbols:\n",
    "    df_sym = df_feat.filter(pl.col(\"symbol\") == sym)\n",
    "    cinfo = costs_by_sym.get(sym, {})\n",
    "    cost_rt = float(cinfo.get(\"cost_base_bps\", 3.0)) / 10_000\n",
    "    cost_stress_rt = float(cinfo.get(\"cost_stress_bps\", 6.0)) / 10_000\n",
    "\n",
    "    for fid in fold_ids:\n",
    "        fold_row = df_folds.filter(pl.col(\"fold_id\") == fid).row(0, named=True)\n",
    "        is_s, is_e = fold_row[\"IS_start\"], fold_row[\"IS_end\"]\n",
    "        oos_s, oos_e = fold_row[\"OOS_start\"], fold_row[\"OOS_end\"]\n",
    "\n",
    "        for side in (\"LONG\", \"SHORT\"):\n",
    "            rg = df_regime.filter((pl.col(\"symbol\") == sym) & (pl.col(\"fold_id\") == fid) & (pl.col(\"side\") == side))\n",
    "            if rg.is_empty() or rg.row(0, named=True).get(\"thr_er_high\") is None:\n",
    "                continue\n",
    "            rg_row = rg.row(0, named=True)\n",
    "            regime_gate = (pl.col(ER_COL) <= rg_row[\"thr_er_high\"]) & (pl.col(VOL_COL) <= rg_row[\"thr_vol\"])\n",
    "            if side == \"LONG\":\n",
    "                signal = regime_gate & (pl.col(DIST_COL) <= -BAND_K)\n",
    "            else:\n",
    "                signal = regime_gate & (pl.col(DIST_COL) >= BAND_K)\n",
    "\n",
    "            for seg_name, seg_s, seg_e in [(\"IS\", is_s, is_e), (\"OOS\", oos_s, oos_e)]:\n",
    "                df_seg = df_sym.filter(\n",
    "                    (pl.col(\"time_utc\") >= seg_s) & (pl.col(\"time_utc\") <= seg_e)\n",
    "                ).filter(signal)\n",
    "                if df_seg.height < 5:\n",
    "                    continue\n",
    "                for h in HORIZONS:\n",
    "                    vals = df_seg.get_column(f\"fwd_{h}\").drop_nulls().to_list()\n",
    "                    if len(vals) < 5:\n",
    "                        continue\n",
    "                    sign = 1.0 if side == \"LONG\" else -1.0\n",
    "                    rets = [sign * r for r in vals]\n",
    "                    n = len(rets)\n",
    "                    mean_r = sum(rets) / n\n",
    "                    std_r = (sum((r - mean_r)**2 for r in rets) / max(1, n - 1)) ** 0.5\n",
    "                    rows.append({\n",
    "                        \"symbol\": sym, \"fold_id\": fid, \"side\": side, \"segment\": seg_name,\n",
    "                        \"horizon_bars\": h, \"n_trades\": n,\n",
    "                        \"gross_mean\": mean_r, \"net_base_mean\": mean_r - cost_rt,\n",
    "                        \"net_stress_mean\": mean_r - cost_stress_rt,\n",
    "                        \"sharpe_like\": mean_r / std_r if std_r > 1e-12 else 0.0,\n",
    "                        \"win_rate\": sum(1 for r in rets if r > 0) / n,\n",
    "                    })\n",
    "\n",
    "alpha_df = pl.DataFrame(rows).sort([\"symbol\", \"fold_id\", \"side\", \"segment\", \"horizon_bars\"])\n",
    "alpha_df.write_parquet(str(OUT_ALPHA), compression=\"zstd\")\n",
    "\n",
    "snap = {\"created_utc\": _now_utc_iso(), \"version\": \"v1.0.0\", \"horizons\": HORIZONS, \"n_rows\": alpha_df.height}\n",
    "Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, default=str), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"[Celda 09] OUT: {OUT_ALPHA} ({alpha_df.height} rows)\")\n",
    "print(\">>> Celda 09 RANGE v1.0.0 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3f03ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# Celda 10 v1.0.0 — Backtest Engine (RANGE Mean-Reversion)\n",
    "# SL=1.5xATR, TP=2.0xATR, NO TRAIL, time_stop=144, confirm=6, cooldown=12, min_hold=3\n",
    "# BUG FIX: dedup keep=\"last\"\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json, math\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 10 RANGE v1.0.0 :: Backtest Engine (Mean-Reversion)\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "\n",
    "FEATURES_PATH = ARTIFACTS[\"features_m5\"]\n",
    "WFO_PATH = ARTIFACTS[\"wfo_folds\"]\n",
    "REGIME_PATH = ARTIFACTS[\"regime_params_by_fold\"]\n",
    "COST_SNAP_PATH = ARTIFACTS[\"cost_model_snapshot\"]\n",
    "\n",
    "OUT_TRADES = ARTIFACTS[\"trades_engine\"]\n",
    "OUT_SUMMARY = ARTIFACTS[\"summary_engine\"]\n",
    "\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "# --- RANGE Engine Params ---\n",
    "SL_ATR     = 1.5\n",
    "TP_ATR     = 2.0\n",
    "TRAIL_ATR  = None  # NO TRAIL for mean-reversion\n",
    "TIME_STOP  = 144   # 12h (faster for range)\n",
    "ENTRY_CONFIRM = 6\n",
    "EXIT_GATE_OFF = 6\n",
    "MIN_HOLD   = 3\n",
    "COOLDOWN   = 12\n",
    "MON_FRI    = True\n",
    "BAND_K     = 1.5\n",
    "RISK_PER_TRADE = 0.01\n",
    "MIN_POS_SIZE = 0.25\n",
    "MAX_POS_SIZE = 3.00\n",
    "\n",
    "ER_COL = \"er_288\"\n",
    "VOL_COL = \"vol_bps_288\"\n",
    "DIST_COL = \"dist_mean_atr\"\n",
    "ATR_COL = \"atr_bps_96\"\n",
    "\n",
    "print(f\"[Celda 10] SL={SL_ATR}xATR TP={TP_ATR}xATR TRAIL=None TIME_STOP={TIME_STOP}\")\n",
    "\n",
    "df_feat = pl.read_parquet(FEATURES_PATH)\n",
    "df_folds = pl.read_parquet(WFO_PATH)\n",
    "df_regime = pl.read_parquet(REGIME_PATH)\n",
    "cost_snap = json.loads(Path(COST_SNAP_PATH).read_text(encoding=\"utf-8\"))\n",
    "costs_by_sym = cost_snap.get(\"costs_by_symbol\", {})\n",
    "\n",
    "symbols = df_feat.get_column(\"symbol\").unique().sort().to_list()\n",
    "fold_ids = df_folds.get_column(\"fold_id\").unique().sort().to_list()\n",
    "\n",
    "def _is_finite(x):\n",
    "    if x is None: return False\n",
    "    try: return math.isfinite(float(x))\n",
    "    except: return False\n",
    "\n",
    "def _simulate_range(sym, df_j, fold_row, thr_er, thr_vol, cost_base_dec, cost_stress_dec):\n",
    "    is_s = fold_row[\"IS_start\"]; is_e = fold_row[\"IS_end\"]\n",
    "    oos_s = fold_row[\"OOS_start\"]; oos_e = fold_row[\"OOS_end\"]\n",
    "    fid = fold_row[\"fold_id\"]\n",
    "\n",
    "    # BUG FIX: dedup keep=\"last\"\n",
    "    df_j = df_j.unique(subset=[\"time_utc\"], keep=\"last\").sort(\"time_utc\")\n",
    "\n",
    "    # Regime gate\n",
    "    regime_gate = (pl.col(ER_COL) <= thr_er) & (pl.col(VOL_COL) <= thr_vol)\n",
    "    # Signal gates\n",
    "    long_signal = regime_gate & (pl.col(DIST_COL) <= -BAND_K)\n",
    "    short_signal = regime_gate & (pl.col(DIST_COL) >= BAND_K)\n",
    "\n",
    "    df_j = df_j.with_columns([\n",
    "        long_signal.alias(\"_gL\"), short_signal.alias(\"_gS\"),\n",
    "        regime_gate.alias(\"_regime\"),\n",
    "    ])\n",
    "\n",
    "    df_j = df_j.with_columns(pl.col(\"time_utc\").dt.weekday().alias(\"_dow\"))\n",
    "    df_j = df_j.with_columns((pl.col(\"_dow\") >= 6).alias(\"_is_wk\"))\n",
    "\n",
    "    # Confirm\n",
    "    df_j = df_j.with_columns([\n",
    "        (pl.col(\"_gL\").cast(pl.Int8).rolling_sum(ENTRY_CONFIRM, min_samples=ENTRY_CONFIRM).eq(ENTRY_CONFIRM))\n",
    "            .fill_null(False).alias(\"_cfL\"),\n",
    "        (pl.col(\"_gS\").cast(pl.Int8).rolling_sum(ENTRY_CONFIRM, min_samples=ENTRY_CONFIRM).eq(ENTRY_CONFIRM))\n",
    "            .fill_null(False).alias(\"_cfS\"),\n",
    "    ])\n",
    "\n",
    "    t = df_j.get_column(\"time_utc\").to_list()\n",
    "    o = df_j.get_column(\"open\").to_list()\n",
    "    h = df_j.get_column(\"high\").to_list()\n",
    "    lo = df_j.get_column(\"low\").to_list()\n",
    "    c = df_j.get_column(\"close\").to_list()\n",
    "    atr_l = df_j.get_column(ATR_COL).to_list() if ATR_COL in df_j.columns else [None]*df_j.height\n",
    "    gL = df_j.get_column(\"_gL\").to_list()\n",
    "    gS = df_j.get_column(\"_gS\").to_list()\n",
    "    cfL = df_j.get_column(\"_cfL\").to_list()\n",
    "    cfS = df_j.get_column(\"_cfS\").to_list()\n",
    "    regime = df_j.get_column(\"_regime\").to_list()\n",
    "    wk = df_j.get_column(\"_is_wk\").to_list()\n",
    "\n",
    "    n = len(t); trades = []\n",
    "    pos = 0; entry_idx = None; entry_price = None\n",
    "    stop = None; tp_price = None; gate_off = 0; cd = 0\n",
    "\n",
    "    def _seg(et):\n",
    "        if is_s <= et <= is_e: return \"IS\"\n",
    "        if oos_s <= et <= oos_e: return \"OOS\"\n",
    "        return None\n",
    "\n",
    "    for idx in range(n):\n",
    "        if pos != 0 and entry_idx is not None:\n",
    "            bars_held = idx - entry_idx\n",
    "            gn = bool(regime[idx]) if regime[idx] is not None else False\n",
    "            gate_off = 0 if gn else gate_off + 1\n",
    "\n",
    "            hi_v = float(h[idx]) if _is_finite(h[idx]) else float(c[idx])\n",
    "            lo_v = float(lo[idx]) if _is_finite(lo[idx]) else float(c[idx])\n",
    "\n",
    "            exit_reason = None; exit_price = None\n",
    "\n",
    "            if pos == 1:\n",
    "                if stop is not None and lo_v <= stop:\n",
    "                    exit_reason, exit_price = \"SL\", stop\n",
    "                elif tp_price is not None and hi_v >= tp_price:\n",
    "                    exit_reason, exit_price = \"TP\", tp_price\n",
    "            else:\n",
    "                if stop is not None and hi_v >= stop:\n",
    "                    exit_reason, exit_price = \"SL\", stop\n",
    "                elif tp_price is not None and lo_v <= tp_price:\n",
    "                    exit_reason, exit_price = \"TP\", tp_price\n",
    "\n",
    "            if exit_reason is None and bars_held >= TIME_STOP:\n",
    "                exit_reason, exit_price = \"TIME\", float(c[idx])\n",
    "            if exit_reason is None and bars_held >= MIN_HOLD and gate_off >= EXIT_GATE_OFF:\n",
    "                exit_reason, exit_price = \"REGIME_OFF\", float(c[idx])\n",
    "            if exit_reason is None and MON_FRI and bool(wk[idx]):\n",
    "                exit_reason, exit_price = \"WEEKEND\", float(c[idx])\n",
    "\n",
    "            if exit_reason is not None:\n",
    "                sign = 1.0 if pos == 1 else -1.0\n",
    "                gross = sign * (exit_price / entry_price - 1.0)\n",
    "                seg = _seg(t[entry_idx])\n",
    "                trades.append({\n",
    "                    \"symbol\": sym, \"fold_id\": fid, \"segment\": seg,\n",
    "                    \"side\": \"LONG\" if pos == 1 else \"SHORT\",\n",
    "                    \"signal_time_utc\": t[entry_idx],\n",
    "                    \"entry_time_utc\": t[min(entry_idx + 1, n - 1)],\n",
    "                    \"exit_time_utc\": t[idx],\n",
    "                    \"entry_price\": entry_price, \"exit_price\": exit_price,\n",
    "                    \"gross_pnl\": gross,\n",
    "                    \"net_pnl_base\": gross - cost_base_dec,\n",
    "                    \"net_pnl_stress\": gross - cost_stress_dec,\n",
    "                    \"hold_bars\": bars_held, \"exit_reason\": exit_reason,\n",
    "                })\n",
    "                pos = 0; entry_idx = None; entry_price = None\n",
    "                stop = None; tp_price = None; cd = COOLDOWN\n",
    "                continue\n",
    "\n",
    "        if cd > 0:\n",
    "            cd -= 1; continue\n",
    "\n",
    "        if pos == 0 and idx < n - 2:\n",
    "            if MON_FRI and bool(wk[idx]): continue\n",
    "\n",
    "            atr_val = float(atr_l[idx]) / 10_000 * float(c[idx]) if _is_finite(atr_l[idx]) else float(c[idx]) * 0.005\n",
    "            if atr_val <= 0: continue\n",
    "\n",
    "            if bool(cfL[idx]):\n",
    "                entry_price = float(o[idx + 1]) if _is_finite(o[idx + 1]) else float(c[idx])\n",
    "                stop = entry_price - SL_ATR * atr_val\n",
    "                tp_price = entry_price + TP_ATR * atr_val\n",
    "                pos = 1; entry_idx = idx; gate_off = 0\n",
    "            elif bool(cfS[idx]):\n",
    "                entry_price = float(o[idx + 1]) if _is_finite(o[idx + 1]) else float(c[idx])\n",
    "                stop = entry_price + SL_ATR * atr_val\n",
    "                tp_price = entry_price - TP_ATR * atr_val\n",
    "                pos = -1; entry_idx = idx; gate_off = 0\n",
    "\n",
    "    return trades\n",
    "\n",
    "all_trades = []\n",
    "for sym in symbols:\n",
    "    df_sym = df_feat.filter(pl.col(\"symbol\") == sym).sort(\"time_utc\")\n",
    "    cinfo = costs_by_sym.get(sym, {})\n",
    "    cost_base_dec = float(cinfo.get(\"cost_base_bps\", 3.0)) / 10_000\n",
    "    cost_stress_dec = float(cinfo.get(\"cost_stress_bps\", 6.0)) / 10_000\n",
    "\n",
    "    for fid in fold_ids:\n",
    "        fold_row = df_folds.filter(pl.col(\"fold_id\") == fid).row(0, named=True)\n",
    "        rg = df_regime.filter((pl.col(\"symbol\") == sym) & (pl.col(\"fold_id\") == fid))\n",
    "        if rg.is_empty(): continue\n",
    "        rg_row = rg.row(0, named=True)\n",
    "        if rg_row.get(\"thr_er_high\") is None: continue\n",
    "\n",
    "        trades = _simulate_range(sym, df_sym, fold_row,\n",
    "                                  float(rg_row[\"thr_er_high\"]), float(rg_row[\"thr_vol\"]),\n",
    "                                  cost_base_dec, cost_stress_dec)\n",
    "        if trades:\n",
    "            all_trades.extend(trades)\n",
    "            print(f\"[Celda 10] {sym} fold={fid}: {len(trades)} trades\")\n",
    "\n",
    "if all_trades:\n",
    "    trades_df = pl.DataFrame(all_trades).sort([\"symbol\", \"fold_id\", \"signal_time_utc\"])\n",
    "else:\n",
    "    trades_df = pl.DataFrame()\n",
    "    print(\"[Celda 10] WARNING: 0 trades\")\n",
    "\n",
    "trades_df.write_parquet(str(OUT_TRADES), compression=\"zstd\")\n",
    "\n",
    "if trades_df.height > 0:\n",
    "    summary = (\n",
    "        trades_df.group_by([\"symbol\", \"fold_id\", \"segment\", \"side\"])\n",
    "        .agg([pl.len().alias(\"n_trades\"), pl.col(\"net_pnl_base\").mean().alias(\"net_mean\"),\n",
    "              (pl.col(\"net_pnl_base\") > 0).mean().alias(\"win_rate\")])\n",
    "        .sort([\"symbol\", \"fold_id\"])\n",
    "    )\n",
    "else:\n",
    "    summary = pl.DataFrame()\n",
    "summary.write_parquet(str(OUT_SUMMARY), compression=\"zstd\")\n",
    "\n",
    "print(f\"\\n[Celda 10] OUT: {OUT_TRADES} ({trades_df.height} trades)\")\n",
    "print(\">>> Celda 10 RANGE v1.0.0 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf992f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# Celda 11 v1.0.0 — QA Weekend Entries [RANGE]\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 11 RANGE v1.0.0 :: QA Weekend Entries\")\n",
    "\n",
    "TRADES_PATH = RUN[\"ARTIFACTS\"].get(\"trades_engine\")\n",
    "OUT_QA = RUN[\"ARTIFACTS\"][\"engine_qa_report\"]\n",
    "\n",
    "if not Path(TRADES_PATH).exists():\n",
    "    print(\"[Celda 11] WARNING: no trades, skip.\")\n",
    "else:\n",
    "    df = pl.read_parquet(TRADES_PATH)\n",
    "    if df.height == 0:\n",
    "        qa = {\"status\": \"PASS\", \"weekend_entries\": 0}\n",
    "    else:\n",
    "        df = df.with_columns(pl.col(\"entry_time_utc\").dt.weekday().alias(\"_dow\"))\n",
    "        wk = df.filter(pl.col(\"_dow\") >= 6).height\n",
    "        qa = {\"status\": \"PASS\" if wk == 0 else \"FAIL\", \"weekend_entries\": wk, \"total\": df.height}\n",
    "        if wk > 0: print(f\"[Celda 11] FAIL: {wk} weekend entries!\")\n",
    "    Path(OUT_QA).write_text(json.dumps(qa, indent=2), encoding=\"utf-8\")\n",
    "    print(f\"[Celda 11] status={qa['status']}\")\n",
    "\n",
    "print(\">>> Celda 11 RANGE v1.0.0 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d314cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# Celda 12 v1.0.0 — Engine Report: Equity + KPIs + Exit Reasons [RANGE]\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 12 RANGE v1.0.0 :: Engine Report\")\n",
    "\n",
    "RUN_DIR = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS = RUN[\"ARTIFACTS\"]\n",
    "TRADES_PATH = ARTIFACTS[\"trades_engine\"]\n",
    "OUT_EQUITY = ARTIFACTS[\"equity_engine\"]\n",
    "OUT_SNAP = ARTIFACTS[\"engine_report_snapshot\"]\n",
    "\n",
    "def _now_utc_iso(): return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "if not Path(TRADES_PATH).exists() or pl.read_parquet(TRADES_PATH).height == 0:\n",
    "    print(\"[Celda 12] WARNING: 0 trades.\")\n",
    "    snap = {\"created_utc\": _now_utc_iso(), \"status\": \"EMPTY\"}\n",
    "    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2), encoding=\"utf-8\")\n",
    "else:\n",
    "    df = pl.read_parquet(TRADES_PATH)\n",
    "    eq = (\n",
    "        df.sort(\"exit_time_utc\")\n",
    "        .with_columns(pl.col(\"net_pnl_base\").cum_sum().alias(\"cum_ret\"))\n",
    "        .with_columns(pl.col(\"cum_ret\").cum_max().alias(\"peak\"))\n",
    "        .with_columns((pl.col(\"cum_ret\") - pl.col(\"peak\")).alias(\"drawdown\"))\n",
    "        .select([\"symbol\", \"fold_id\", \"segment\", \"side\", \"exit_time_utc\",\n",
    "                 \"net_pnl_base\", \"cum_ret\", \"peak\", \"drawdown\"])\n",
    "    )\n",
    "    eq.write_parquet(str(OUT_EQUITY), compression=\"zstd\")\n",
    "\n",
    "    tot_ret = float(df.get_column(\"net_pnl_base\").sum())\n",
    "    mdd = float(eq.get_column(\"drawdown\").min())\n",
    "    n = df.height\n",
    "    wr = float((df.get_column(\"net_pnl_base\") > 0).mean())\n",
    "    mean_r = float(df.get_column(\"net_pnl_base\").mean())\n",
    "    std_r = float(df.get_column(\"net_pnl_base\").std())\n",
    "    sharpe = mean_r / std_r if std_r > 1e-12 else 0.0\n",
    "\n",
    "    exits = df.group_by(\"exit_reason\").agg(pl.len().alias(\"count\")).sort(\"count\", descending=True)\n",
    "    exit_dict = {r[\"exit_reason\"]: r[\"count\"] for r in exits.to_dicts()}\n",
    "\n",
    "    snap = {\n",
    "        \"created_utc\": _now_utc_iso(), \"version\": \"v1.0.0\",\n",
    "        \"kpis\": {\"total_return\": tot_ret, \"mdd\": mdd, \"n_trades\": n,\n",
    "                 \"sharpe_like\": sharpe, \"win_rate\": wr},\n",
    "        \"exit_reasons\": exit_dict,\n",
    "    }\n",
    "    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, default=str), encoding=\"utf-8\")\n",
    "    print(f\"[Celda 12] ret={tot_ret:.4f} MDD={mdd:.4f} sharpe={sharpe:.3f} WR={wr:.3f}\")\n",
    "\n",
    "print(\">>> Celda 12 RANGE v1.0.0 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57070122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# Celda 13 v1.0.0 — Diagnostics: Edge Alignment [RANGE]\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 13 RANGE v1.0.0 :: Diagnostics\")\n",
    "\n",
    "ARTIFACTS = RUN[\"ARTIFACTS\"]\n",
    "ALPHA_PATH = ARTIFACTS[\"alpha_multi_horizon_report\"]\n",
    "TRADES_PATH = ARTIFACTS[\"trades_engine\"]\n",
    "OUT_DIAG = ARTIFACTS[\"diagnostics\"]\n",
    "OUT_SNAP = ARTIFACTS[\"diagnostics_snapshot\"]\n",
    "\n",
    "def _now_utc_iso(): return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "if not Path(ALPHA_PATH).exists() or not Path(TRADES_PATH).exists():\n",
    "    snap = {\"created_utc\": _now_utc_iso(), \"status\": \"SKIPPED\"}\n",
    "    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2), encoding=\"utf-8\")\n",
    "else:\n",
    "    alpha = pl.read_parquet(ALPHA_PATH)\n",
    "    trades = pl.read_parquet(TRADES_PATH)\n",
    "    diag_rows = []\n",
    "    if trades.height > 0 and alpha.height > 0:\n",
    "        for sym in trades.get_column(\"symbol\").unique().sort().to_list():\n",
    "            t_sym = trades.filter(pl.col(\"symbol\") == sym)\n",
    "            a_is = alpha.filter((pl.col(\"symbol\") == sym) & (pl.col(\"segment\") == \"IS\"))\n",
    "            best = a_is.sort(\"sharpe_like\", descending=True).row(0, named=True) if a_is.height > 0 else None\n",
    "            hold_p50 = float(t_sym.get_column(\"hold_bars\").median()) if t_sym.height > 0 else 0\n",
    "            hold_p90 = float(t_sym.get_column(\"hold_bars\").quantile(0.90, interpolation=\"nearest\")) if t_sym.height > 0 else 0\n",
    "            tp_share = t_sym.filter(pl.col(\"exit_reason\") == \"TP\").height / max(1, t_sym.height)\n",
    "            diag_rows.append({\n",
    "                \"symbol\": sym,\n",
    "                \"best_alpha_side_IS\": best[\"side\"] if best else None,\n",
    "                \"best_alpha_horizon_IS\": best[\"horizon_bars\"] if best else None,\n",
    "                \"engine_hold_p50\": hold_p50, \"engine_hold_p90\": hold_p90,\n",
    "                \"tp_exit_share\": tp_share,\n",
    "                \"note\": \"Mean-rev: high TP share = good (revert to mean target hit)\"\n",
    "            })\n",
    "    diag_df = pl.DataFrame(diag_rows) if diag_rows else pl.DataFrame()\n",
    "    diag_df.write_parquet(str(OUT_DIAG), compression=\"zstd\")\n",
    "    snap = {\"created_utc\": _now_utc_iso(), \"diagnostics\": diag_rows}\n",
    "    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, default=str), encoding=\"utf-8\")\n",
    "    print(f\"[Celda 13] {len(diag_rows)} symbols diagnosed\")\n",
    "\n",
    "print(\">>> Celda 13 RANGE v1.0.0 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41156f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# Celda 14 v1.0.0 — Engine Tuning IS-only [RANGE]\n",
    "# Grid: SL=[1.0,1.5,2.0] TP=[1.5,2.0,3.0] BAND_K=[1.0,1.5,2.0] time_stop=[96,144]\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json, itertools\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 14 RANGE v1.0.0 :: Engine Tuning IS-only\")\n",
    "\n",
    "ARTIFACTS = RUN[\"ARTIFACTS\"]\n",
    "SIGNALS_PATH = ARTIFACTS[\"signals_all\"]\n",
    "OUT_TUNING = ARTIFACTS[\"tuning_results\"]\n",
    "OUT_BEST = ARTIFACTS[\"tuning_best_params\"]\n",
    "OUT_SNAP = ARTIFACTS[\"tuning_snapshot\"]\n",
    "\n",
    "def _now_utc_iso(): return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "SL_GRID = [1.0, 1.5, 2.0]\n",
    "TP_GRID = [1.5, 2.0, 3.0]\n",
    "BAND_K_GRID = [1.0, 1.5, 2.0]\n",
    "TS_GRID = [96, 144]\n",
    "MIN_TRADES = 20\n",
    "\n",
    "combos = list(itertools.product(SL_GRID, TP_GRID, BAND_K_GRID, TS_GRID))[:100]\n",
    "print(f\"[Celda 14] {len(combos)} combos\")\n",
    "\n",
    "if not Path(SIGNALS_PATH).exists():\n",
    "    snap = {\"created_utc\": _now_utc_iso(), \"status\": \"SKIPPED\"}\n",
    "    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2), encoding=\"utf-8\")\n",
    "else:\n",
    "    signals = pl.read_parquet(SIGNALS_PATH)\n",
    "    signals_is = signals.filter(pl.col(\"segment\") == \"IS\")\n",
    "\n",
    "    results = []\n",
    "    for sym in signals_is.get_column(\"symbol\").unique().sort().to_list():\n",
    "        for fid in signals_is.filter(pl.col(\"symbol\") == sym).get_column(\"fold_id\").unique().to_list():\n",
    "            df_sf = signals_is.filter((pl.col(\"symbol\") == sym) & (pl.col(\"fold_id\") == fid))\n",
    "            if df_sf.height < MIN_TRADES: continue\n",
    "            rets = df_sf.get_column(\"net_ret_base\").to_list()\n",
    "            n = len(rets)\n",
    "            mean_r = sum(rets) / n\n",
    "            std_r = (sum((r - mean_r)**2 for r in rets) / max(1, n - 1)) ** 0.5\n",
    "            for sl, tp, bk, ts in combos:\n",
    "                score = sum(rets) / max(1e-12, std_r)\n",
    "                results.append({\"symbol\": sym, \"fold_id\": fid, \"sl\": sl, \"tp\": tp,\n",
    "                                \"band_k\": bk, \"time_stop\": ts, \"n\": n, \"score\": score})\n",
    "\n",
    "    tuning_df = pl.DataFrame(results).sort([\"symbol\", \"fold_id\", \"score\"], descending=[False, False, True])\n",
    "    tuning_df.write_parquet(str(OUT_TUNING), compression=\"zstd\")\n",
    "\n",
    "    best = tuning_df.group_by([\"symbol\", \"fold_id\"]).first().sort([\"symbol\", \"fold_id\"]) if tuning_df.height > 0 else pl.DataFrame()\n",
    "    best.write_parquet(str(OUT_BEST), compression=\"zstd\")\n",
    "\n",
    "    snap = {\"created_utc\": _now_utc_iso(), \"n_combos\": len(combos), \"n_results\": tuning_df.height}\n",
    "    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, default=str), encoding=\"utf-8\")\n",
    "    print(f\"[Celda 14] {tuning_df.height} results, {best.height} best\")\n",
    "\n",
    "print(\">>> Celda 14 RANGE v1.0.0 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a5626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# Celda 15 v1.0.0 — Alpha Design IS-only [RANGE]\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 15 RANGE v1.0.0 :: Alpha Design IS-only\")\n",
    "\n",
    "ARTIFACTS = RUN[\"ARTIFACTS\"]\n",
    "ALPHA_PATH = ARTIFACTS[\"alpha_multi_horizon_report\"]\n",
    "OUT_DESIGN = ARTIFACTS[\"alpha_design\"]\n",
    "OUT_SNAP = ARTIFACTS[\"alpha_design_snapshot\"]\n",
    "\n",
    "def _now_utc_iso(): return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "MIN_TRADES = 80\n",
    "MIN_NET_MEAN = 0.0\n",
    "\n",
    "if not Path(ALPHA_PATH).exists():\n",
    "    snap = {\"created_utc\": _now_utc_iso(), \"status\": \"SKIPPED\"}\n",
    "    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2), encoding=\"utf-8\")\n",
    "else:\n",
    "    alpha = pl.read_parquet(ALPHA_PATH)\n",
    "    a_is = alpha.filter((pl.col(\"segment\") == \"IS\") & (pl.col(\"n_trades\") >= MIN_TRADES) & (pl.col(\"net_base_mean\") >= MIN_NET_MEAN))\n",
    "\n",
    "    if a_is.height == 0:\n",
    "        design_df = pl.DataFrame()\n",
    "    else:\n",
    "        a_is = a_is.with_columns((pl.col(\"sharpe_like\") * pl.col(\"n_trades\").cast(pl.Float64).sqrt()).alias(\"score\"))\n",
    "        design_rows = []\n",
    "        for sym in a_is.get_column(\"symbol\").unique().sort().to_list():\n",
    "            for fid in a_is.filter(pl.col(\"symbol\") == sym).get_column(\"fold_id\").unique().to_list():\n",
    "                cand = a_is.filter((pl.col(\"symbol\") == sym) & (pl.col(\"fold_id\") == fid))\n",
    "                if cand.height == 0: continue\n",
    "                best = cand.sort(\"score\", descending=True).row(0, named=True)\n",
    "                h = best[\"horizon_bars\"]\n",
    "                design_rows.append({\n",
    "                    \"symbol\": sym, \"fold_id\": fid, \"best_side\": best[\"side\"],\n",
    "                    \"best_horizon\": h, \"score\": best[\"score\"],\n",
    "                    \"TIME_STOP_target\": h, \"MIN_HOLD_target\": max(3, int(0.25 * h)),\n",
    "                })\n",
    "        design_df = pl.DataFrame(design_rows) if design_rows else pl.DataFrame()\n",
    "\n",
    "    design_df.write_parquet(str(OUT_DESIGN), compression=\"zstd\")\n",
    "    snap = {\"created_utc\": _now_utc_iso(), \"n_designs\": design_df.height}\n",
    "    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, default=str), encoding=\"utf-8\")\n",
    "    print(f\"[Celda 15] {design_df.height} designs\")\n",
    "\n",
    "print(\">>> Celda 15 RANGE v1.0.0 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cbc797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# Celda 16 v1.0.0 — Execution & Risk Overlay [RANGE]\n",
    "# BUG FIX: Guard contra doble ejecucion\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 16 RANGE v1.0.0 :: Overlay\")\n",
    "\n",
    "# BUG FIX\n",
    "if RUN.get(\"_overlay_applied\"):\n",
    "    raise RuntimeError(\"[Celda 16] Overlay ya aplicado. Re-ejecutar desde Cell 00.\")\n",
    "RUN[\"_overlay_applied\"] = True\n",
    "\n",
    "ARTIFACTS = RUN[\"ARTIFACTS\"]\n",
    "TRADES_PATH = ARTIFACTS[\"trades_engine\"]\n",
    "OUT_OT = ARTIFACTS[\"overlay_trades\"]\n",
    "OUT_OS = ARTIFACTS[\"overlay_summary\"]\n",
    "OUT_SNAP = ARTIFACTS[\"overlay_snapshot\"]\n",
    "\n",
    "DAILY_MAX_LOSS = -0.02; DAILY_MAX_PROFIT = 0.03; MAX_TRADES_DAY = 3\n",
    "\n",
    "def _now_utc_iso(): return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "if not Path(TRADES_PATH).exists():\n",
    "    snap = {\"created_utc\": _now_utc_iso(), \"status\": \"SKIPPED\"}\n",
    "    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2), encoding=\"utf-8\")\n",
    "else:\n",
    "    df = pl.read_parquet(TRADES_PATH)\n",
    "    n_before = df.height\n",
    "    if df.height == 0:\n",
    "        df.write_parquet(str(OUT_OT)); pl.DataFrame().write_parquet(str(OUT_OS))\n",
    "        snap = {\"created_utc\": _now_utc_iso(), \"status\": \"EMPTY\"}\n",
    "    else:\n",
    "        df = df.with_columns([\n",
    "            pl.col(\"entry_time_utc\").cast(pl.Date).alias(\"_date\"),\n",
    "            pl.col(\"entry_time_utc\").dt.weekday().alias(\"_dow\"),\n",
    "        ]).filter(pl.col(\"_dow\") <= 5)\n",
    "\n",
    "        filtered = []\n",
    "        for dt in df.get_column(\"_date\").unique().sort().to_list():\n",
    "            day = df.filter(pl.col(\"_date\") == dt).sort(\"entry_time_utc\")\n",
    "            pnl = 0.0; n_d = 0\n",
    "            for row in day.iter_rows(named=True):\n",
    "                if n_d >= MAX_TRADES_DAY or pnl <= DAILY_MAX_LOSS or pnl >= DAILY_MAX_PROFIT: break\n",
    "                filtered.append(row); pnl += row[\"net_pnl_base\"]; n_d += 1\n",
    "\n",
    "        overlay_df = pl.DataFrame(filtered) if filtered else pl.DataFrame()\n",
    "        n_after = overlay_df.height\n",
    "        overlay_df.write_parquet(str(OUT_OT), compression=\"zstd\")\n",
    "\n",
    "        summary = overlay_df.group_by([\"symbol\", \"segment\"]).agg([\n",
    "            pl.len().alias(\"n\"), pl.col(\"net_pnl_base\").sum().alias(\"tot_ret\"),\n",
    "        ]).sort([\"symbol\", \"segment\"]) if n_after > 0 else pl.DataFrame()\n",
    "        summary.write_parquet(str(OUT_OS), compression=\"zstd\")\n",
    "\n",
    "        snap = {\"created_utc\": _now_utc_iso(), \"n_before\": n_before, \"n_after\": n_after}\n",
    "        print(f\"[Celda 16] {n_before} -> {n_after} trades\")\n",
    "\n",
    "    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, default=str), encoding=\"utf-8\")\n",
    "\n",
    "print(\">>> Celda 16 RANGE v1.0.0 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709ba063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# Celda 17 v1.0.0 — Seleccion Institucional [RANGE]\n",
    "# Adjusted weights: higher win_rate weight for mean-reversion\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 17 RANGE v1.0.0 :: Seleccion\")\n",
    "\n",
    "ARTIFACTS = RUN[\"ARTIFACTS\"]\n",
    "OVERLAY_PATH = ARTIFACTS[\"overlay_trades\"]\n",
    "OUT_SEL = ARTIFACTS[\"selection\"]\n",
    "OUT_SNAP = ARTIFACTS[\"selection_snapshot\"]\n",
    "\n",
    "MIN_OOS_TRADES = 80; MAX_MDD = -0.20; MIN_TOTRET = 0.0; MIN_WR = 0.48\n",
    "\n",
    "def _now_utc_iso(): return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "if not Path(OVERLAY_PATH).exists():\n",
    "    snap = {\"created_utc\": _now_utc_iso(), \"status\": \"SKIPPED\"}\n",
    "    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2), encoding=\"utf-8\")\n",
    "else:\n",
    "    df = pl.read_parquet(OVERLAY_PATH)\n",
    "    df_oos = df.filter(pl.col(\"segment\") == \"OOS\") if df.height > 0 else df\n",
    "    sel_rows = []\n",
    "    if df_oos.height > 0:\n",
    "        for sym in df_oos.get_column(\"symbol\").unique().sort().to_list():\n",
    "            for side in df_oos.filter(pl.col(\"symbol\") == sym).get_column(\"side\").unique().to_list():\n",
    "                sub = df_oos.filter((pl.col(\"symbol\") == sym) & (pl.col(\"side\") == side))\n",
    "                n = sub.height\n",
    "                if n < MIN_OOS_TRADES:\n",
    "                    sel_rows.append({\"symbol\": sym, \"side\": side, \"decision\": \"NO_GO\", \"n_oos\": n, \"score\": 0}); continue\n",
    "                tot_ret = float(sub.get_column(\"net_pnl_base\").sum())\n",
    "                wr = float((sub.get_column(\"net_pnl_base\") > 0).mean())\n",
    "                cum = sub.sort(\"exit_time_utc\").with_columns(pl.col(\"net_pnl_base\").cum_sum().alias(\"_cr\"))\n",
    "                mdd = float((cum.get_column(\"_cr\") - cum.get_column(\"_cr\").cum_max()).min())\n",
    "                sharpe = float(sub.get_column(\"net_pnl_base\").mean()) / max(1e-12, float(sub.get_column(\"net_pnl_base\").std()))\n",
    "                # Higher weight for win_rate in mean-reversion\n",
    "                score = tot_ret + 0.15 * sharpe + 0.10 * (wr - 0.5) - 1.25 * (-mdd)\n",
    "                go = tot_ret >= MIN_TOTRET and mdd >= MAX_MDD and wr >= MIN_WR\n",
    "                sel_rows.append({\"symbol\": sym, \"side\": side, \"decision\": \"GO\" if go else \"NO_GO\",\n",
    "                                 \"score\": score, \"n_oos\": n, \"tot_ret\": tot_ret, \"mdd\": mdd, \"wr\": wr})\n",
    "\n",
    "    sel_df = pl.DataFrame(sel_rows) if sel_rows else pl.DataFrame()\n",
    "    sel_df.write_parquet(str(OUT_SEL), compression=\"zstd\")\n",
    "    snap = {\"created_utc\": _now_utc_iso(), \"selections\": sel_rows}\n",
    "    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, default=str), encoding=\"utf-8\")\n",
    "    n_go = sum(1 for r in sel_rows if r.get(\"decision\") == \"GO\")\n",
    "    print(f\"[Celda 17] {n_go}/{len(sel_rows)} GO\")\n",
    "\n",
    "print(\">>> Celda 17 RANGE v1.0.0 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e59af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# Celda 18 v1.0.0 — Deploy Pack [RANGE]\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 18 RANGE v1.0.0 :: Deploy Pack\")\n",
    "\n",
    "ARTIFACTS = RUN[\"ARTIFACTS\"]\n",
    "RUN_DIR = RUN[\"RUN_DIR\"]\n",
    "SEL_PATH = ARTIFACTS[\"selection\"]\n",
    "REGIME_PATH = ARTIFACTS[\"regime_params_by_fold\"]\n",
    "COST_SNAP_PATH = ARTIFACTS[\"cost_model_snapshot\"]\n",
    "OUT_DP = ARTIFACTS[\"deploy_pack\"]\n",
    "OUT_DP_JSON = ARTIFACTS[\"deploy_pack_json\"]\n",
    "\n",
    "DEPLOY_DIR = RUN_DIR / \"deploy\"\n",
    "DEPLOY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TOPK = 2\n",
    "\n",
    "def _now_utc_iso(): return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "if not Path(SEL_PATH).exists():\n",
    "    print(\"[Celda 18] skip: no selection\")\n",
    "else:\n",
    "    sel = pl.read_parquet(SEL_PATH)\n",
    "    regime = pl.read_parquet(REGIME_PATH)\n",
    "    cost_snap = json.loads(Path(COST_SNAP_PATH).read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    go = sel.filter(pl.col(\"decision\") == \"GO\") if sel.height > 0 and \"decision\" in sel.columns else pl.DataFrame()\n",
    "    if go.height == 0 and sel.height > 0 and \"score\" in sel.columns:\n",
    "        go = sel.sort(\"score\", descending=True).head(TOPK)\n",
    "\n",
    "    deploy_rows = []\n",
    "    for row in go.iter_rows(named=True):\n",
    "        sym, side = row[\"symbol\"], row[\"side\"]\n",
    "        rg = regime.filter((pl.col(\"symbol\") == sym) & (pl.col(\"side\") == side))\n",
    "        config = {\"symbol\": sym, \"side\": side, \"score\": row.get(\"score\", 0),\n",
    "                  \"regime_gates\": rg.to_dicts() if rg.height > 0 else [],\n",
    "                  \"costs\": cost_snap.get(\"costs_by_symbol\", {}).get(sym, {}),\n",
    "                  \"strategy\": \"RANGE_MEAN_REVERSION\", \"created_utc\": _now_utc_iso()}\n",
    "        deploy_rows.append(config)\n",
    "        (DEPLOY_DIR / f\"{sym}_{side}_range_config.json\").write_text(json.dumps(config, indent=2, default=str), encoding=\"utf-8\")\n",
    "\n",
    "    pl.DataFrame(deploy_rows).write_parquet(str(OUT_DP), compression=\"zstd\") if deploy_rows else pl.DataFrame().write_parquet(str(OUT_DP))\n",
    "    Path(OUT_DP_JSON).write_text(json.dumps(deploy_rows, indent=2, default=str), encoding=\"utf-8\")\n",
    "    print(f\"[Celda 18] {len(deploy_rows)} deployed\")\n",
    "\n",
    "print(\">>> Celda 18 RANGE v1.0.0 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c56be5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# Celda 19 v1.0.0 — QA Alpha<->Motor Alignment [RANGE]\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 19 RANGE v1.0.0 :: QA Alignment\")\n",
    "\n",
    "ARTIFACTS = RUN[\"ARTIFACTS\"]\n",
    "ALPHA_PATH = ARTIFACTS[\"alpha_multi_horizon_report\"]\n",
    "TRADES_PATH = ARTIFACTS[\"trades_engine\"]\n",
    "OUT_QA = ARTIFACTS[\"qa_alignment\"]\n",
    "OUT_SNAP = ARTIFACTS[\"qa_alignment_snapshot\"]\n",
    "\n",
    "def _now_utc_iso(): return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "if not Path(ALPHA_PATH).exists() or not Path(TRADES_PATH).exists():\n",
    "    snap = {\"created_utc\": _now_utc_iso(), \"status\": \"SKIPPED\"}\n",
    "    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2), encoding=\"utf-8\")\n",
    "else:\n",
    "    alpha = pl.read_parquet(ALPHA_PATH)\n",
    "    trades = pl.read_parquet(TRADES_PATH)\n",
    "    qa_rows = []\n",
    "    if trades.height > 0 and alpha.height > 0:\n",
    "        a_oos = alpha.filter(pl.col(\"segment\") == \"OOS\")\n",
    "        t_oos = trades.filter(pl.col(\"segment\") == \"OOS\")\n",
    "        for sym in t_oos.get_column(\"symbol\").unique().sort().to_list():\n",
    "            a_sym = a_oos.filter(pl.col(\"symbol\") == sym)\n",
    "            if a_sym.height == 0: continue\n",
    "            best = a_sym.sort(\"sharpe_like\", descending=True).row(0, named=True)\n",
    "            t_sym = t_oos.filter(pl.col(\"symbol\") == sym)\n",
    "            if t_sym.height == 0: continue\n",
    "            eng = t_sym.group_by(\"side\").agg(pl.col(\"net_pnl_base\").sum().alias(\"tot\")).sort(\"tot\", descending=True)\n",
    "            eng_side = eng.row(0, named=True)[\"side\"]\n",
    "            qa_rows.append({\n",
    "                \"symbol\": sym, \"alpha_best_side\": best[\"side\"], \"engine_best_side\": eng_side,\n",
    "                \"side_mismatch\": best[\"side\"] != eng_side,\n",
    "            })\n",
    "    qa_df = pl.DataFrame(qa_rows) if qa_rows else pl.DataFrame()\n",
    "    qa_df.write_parquet(str(OUT_QA), compression=\"zstd\")\n",
    "    snap = {\"created_utc\": _now_utc_iso(), \"alignment\": qa_rows}\n",
    "    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, default=str), encoding=\"utf-8\")\n",
    "    print(f\"[Celda 19] {len(qa_rows)} alignment checks\")\n",
    "\n",
    "print(\">>> Celda 19 RANGE v1.0.0 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e058f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# Celda 20 v1.0.0 — Run Summary + Manifest Final [RANGE]\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 20 RANGE v1.0.0 :: Run Summary\")\n",
    "\n",
    "RUN_DIR = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS = RUN[\"ARTIFACTS\"]\n",
    "\n",
    "def _now_utc_iso(): return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "missing = [k for k, v in ARTIFACTS.items() if not Path(v).exists()]\n",
    "existing = [k for k, v in ARTIFACTS.items() if Path(v).exists()]\n",
    "\n",
    "summary = {\"run_id\": RUN[\"RUN_ID\"], \"strategy\": \"RANGE_MEAN_REVERSION\",\n",
    "           \"completion_utc\": _now_utc_iso(),\n",
    "           \"artifacts_ok\": len(existing), \"artifacts_missing\": len(missing)}\n",
    "\n",
    "sel_path = ARTIFACTS.get(\"selection\")\n",
    "if sel_path and Path(sel_path).exists():\n",
    "    sel = pl.read_parquet(sel_path)\n",
    "    if sel.height > 0 and \"decision\" in sel.columns:\n",
    "        summary[\"symbols_go\"] = sel.filter(pl.col(\"decision\") == \"GO\").height\n",
    "\n",
    "eng_snap_path = ARTIFACTS.get(\"engine_report_snapshot\")\n",
    "if eng_snap_path and Path(eng_snap_path).exists():\n",
    "    kpis = json.loads(Path(eng_snap_path).read_text(encoding=\"utf-8\")).get(\"kpis\", {})\n",
    "    summary.update({f\"kpi_{k}\": v for k, v in kpis.items()})\n",
    "\n",
    "manifest_path = RUN_DIR / \"run_manifest_range_v1.json\"\n",
    "manifest = json.loads(manifest_path.read_text(encoding=\"utf-8\")) if manifest_path.exists() else {}\n",
    "manifest[\"completion_utc\"] = summary[\"completion_utc\"]\n",
    "manifest[\"summary\"] = summary\n",
    "manifest_path.write_text(json.dumps(manifest, indent=2, default=str), encoding=\"utf-8\")\n",
    "\n",
    "latest = RUN_DIR.parent / \"run_manifest_range_v1_latest.json\"\n",
    "latest.write_text(json.dumps(manifest, indent=2, default=str), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"  RUN SUMMARY — RANGE v1 (Mean-Reversion)\")\n",
    "print(f\"{'='*60}\")\n",
    "for k, v in summary.items():\n",
    "    print(f\"  {k:30s}: {v}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(\">>> Celda 20 RANGE v1.0.0 :: OK\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
