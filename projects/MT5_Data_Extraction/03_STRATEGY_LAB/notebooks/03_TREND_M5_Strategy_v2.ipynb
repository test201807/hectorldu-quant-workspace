{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df0cb19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Celda 00 v2.0.3] Manifest CREADO (nuevo run): C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\run_manifest_v2.json\n",
      "\n",
      "--- Celda 00 v2.0.3 | Estado final ---\n",
      "RUN_MODE             : NEW_RUN_DEFAULT\n",
      "PROJECT_ROOT         : C:\\Quant\\projects\\MT5_Data_Extraction\n",
      "WORKDIR              : C:\\Quant\\projects\\MT5_Data_Extraction\\03_STRATEGY_LAB\\notebooks\n",
      "OUTPUTS_ROOT         : C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\n",
      "RUN_ID               : 20260218_000143_164d8480\n",
      "RUN_DIR              : C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\n",
      "RUN_MANIFEST_PATH    : C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\run_manifest_v2.json\n",
      "RUN_MANIFEST_LATEST  : C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_manifest_v2_latest.json\n",
      "LATEST_RUN_MARKER    : C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\_latest_run.txt\n",
      "SCHEMA_VERSION       : v2.0.3\n",
      "ENGINE_VERSION       : v2.0.3\n",
      "\n",
      "--- ARTIFACTS keys ---\n",
      "N_KEYS: 38\n",
      "['alpha_design', 'alpha_design_snapshot', 'alpha_multi_horizon_report', 'alpha_multi_horizon_snapshot', 'cost_model_snapshot', 'data_qa_report', 'deploy_pack', 'deploy_pack_json', 'diagnostics', 'diagnostics_snapshot', 'engine_qa_report', 'engine_report_snapshot', 'equity_engine', 'features_m5', 'instrument_specs', 'instrument_specs_snapshot', 'ohlcv_clean', 'overlay_snapshot', 'overlay_summary', 'overlay_trades', 'qa_alignment', 'qa_alignment_snapshot', 'qa_timing', 'regime_params_by_fold', 'regime_params_snapshot', 'selection', 'selection_snapshot', 'signals_all', 'signals_snapshot', 'summary_baseline', 'summary_engine', 'trades_baseline', 'trades_engine', 'tuning_best_params', 'tuning_results', 'tuning_snapshot', 'wfo_folds', 'wfo_folds_snapshot']\n",
      "\n",
      "--- Dependencias ---\n",
      "polars: 1.35.1\n",
      "pandas: 2.3.3\n",
      "\n",
      "[Celda 00 v2.0.3] OK — NEW_RUN por defecto + RUN listo.\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# Celda 00 v2.0.3 — Run Manifest + Paths + Canonical Schema\n",
    "# Política institucional (FINAL):\n",
    "#   - Por defecto SIEMPRE crea un run nuevo (NEW_RUN_DEFAULT).\n",
    "#   - Solo reutiliza run si:\n",
    "#       A) TREND_M5_RUN_ID está seteado (FORCED_RUN_ID)\n",
    "#       B) TREND_M5_RESUME_LATEST=1 y existe _latest_run.txt (RESUME_LATEST)\n",
    "#\n",
    "# Nota:\n",
    "#   - \"outputs\" NO es \"cargar corridas anteriores\": es el directorio de salida del run.\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import platform\n",
    "import hashlib\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "# --- Unified path contract (single source of truth) ---\n",
    "for _p in [Path.cwd().resolve()] + list(Path.cwd().resolve().parents):\n",
    "    _contract = _p / \"shared\" / \"contracts\" / \"path_contract.py\"\n",
    "    if _contract.exists():\n",
    "        if str(_contract.parent) not in sys.path:\n",
    "            sys.path.insert(0, str(_contract.parent))\n",
    "        break\n",
    "import path_contract  # noqa: E402\n",
    "\n",
    "# ---------------------------\n",
    "# Helpers\n",
    "# ---------------------------\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "def _safe_mkdir(p: Path) -> None:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _write_json(path: Path, obj: Dict[str, Any]) -> None:\n",
    "    _safe_mkdir(path.parent)\n",
    "    path.write_text(json.dumps(obj, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "def _read_json(path: Path) -> Dict[str, Any]:\n",
    "    return json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "def _write_text(path: Path, text: str) -> None:\n",
    "    _safe_mkdir(path.parent)\n",
    "    path.write_text(text, encoding=\"utf-8\")\n",
    "\n",
    "def _read_text(path: Path) -> str:\n",
    "    return path.read_text(encoding=\"utf-8\").strip()\n",
    "\n",
    "def _sha1(s: str) -> str:\n",
    "    return hashlib.sha1(s.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def _env(name: str, default: Optional[str] = None) -> Optional[str]:\n",
    "    v = os.getenv(name)\n",
    "    return v if v not in (None, \"\") else default\n",
    "\n",
    "def _env_bool(name: str, default: bool = False) -> bool:\n",
    "    v = os.getenv(name, \"\")\n",
    "    if v is None or v.strip() == \"\":\n",
    "        return default\n",
    "    return v.strip().lower() in (\"1\", \"true\", \"yes\", \"y\")\n",
    "\n",
    "# ---------------------------\n",
    "# Detectar PROJECT_ROOT (repo raíz) — determinístico\n",
    "# ---------------------------\n",
    "def _detect_project_root() -> Path:\n",
    "    forced = _env(\"TREND_M5_ROOT\")\n",
    "    if forced:\n",
    "        return Path(forced).resolve()\n",
    "    return path_contract.detect_project_root()\n",
    "\n",
    "PROJECT_ROOT = _detect_project_root()\n",
    "\n",
    "# ---------------------------\n",
    "# OUTPUTS_ROOT (salida del strategy notebook)\n",
    "# ---------------------------\n",
    "WORKDIR = Path.cwd().resolve()  # normalmente ...\\ER_STRATEGY_LAB\\notebooks\n",
    "OUTPUTS_ROOT = Path(_env(\"TREND_M5_OUTPUTS_ROOT\", str(path_contract.trend_outputs_dir(PROJECT_ROOT)))).resolve()\n",
    "LATEST_RUN_MARKER = OUTPUTS_ROOT / \"_latest_run.txt\"\n",
    "\n",
    "# ---------------------------\n",
    "# RUN_ID policy (FINAL)\n",
    "# ---------------------------\n",
    "FORCED_RUN_ID = (_env(\"TREND_M5_RUN_ID\") or \"\").strip() or None\n",
    "RESUME_LATEST = _env_bool(\"TREND_M5_RESUME_LATEST\", default=False)\n",
    "\n",
    "def _new_run_id() -> str:\n",
    "    ts = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%S\")\n",
    "    salt = _sha1(f\"{ts}|{platform.node()}|{os.getpid()}\")[:8]\n",
    "    return f\"{ts}_{salt}\"\n",
    "\n",
    "if FORCED_RUN_ID:\n",
    "    RUN_MODE = \"FORCED_RUN_ID\"\n",
    "    RUN_ID = FORCED_RUN_ID\n",
    "elif RESUME_LATEST and LATEST_RUN_MARKER.exists():\n",
    "    RUN_MODE = \"RESUME_LATEST\"\n",
    "    RUN_ID = _read_text(LATEST_RUN_MARKER) or _new_run_id()\n",
    "else:\n",
    "    RUN_MODE = \"NEW_RUN_DEFAULT\"\n",
    "    RUN_ID = _new_run_id()\n",
    "\n",
    "RUN_DIR = OUTPUTS_ROOT / f\"run_{RUN_ID}\"\n",
    "RUN_MANIFEST_PATH = RUN_DIR / \"run_manifest_v2.json\"\n",
    "RUN_MANIFEST_LATEST_PATH = OUTPUTS_ROOT / \"run_manifest_v2_latest.json\"\n",
    "\n",
    "# ---------------------------\n",
    "# Versionado\n",
    "# ---------------------------\n",
    "SCHEMA_VERSION = \"v2.0.3\"\n",
    "ENGINE_VERSION = \"v2.0.3\"\n",
    "COST_MODEL_VERSION = \"v2.0.3\"\n",
    "WFO_VERSION = \"v2.0.3\"\n",
    "\n",
    "# ---------------------------\n",
    "# Canonical Schema (contrato)\n",
    "# ---------------------------\n",
    "CANONICAL_SCHEMA = {\n",
    "    \"ohlcv_m5\": {\n",
    "        \"required_columns\": [\"time_utc\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"spread\", \"symbol\"],\n",
    "        \"notes\": \"UTC. time_utc monotónico por símbolo. M5 = 300s.\"\n",
    "    },\n",
    "    \"engine_trades\": {\n",
    "        \"required_columns\": [\n",
    "            \"symbol\",\"fold_id\",\"segment\",\"side\",\n",
    "            \"signal_time_utc\",\"entry_time_utc\",\"exit_time_utc\",\n",
    "            \"entry_price\",\"exit_price\",\n",
    "            \"gross_pnl\",\"net_pnl_base\",\"net_pnl_stress\",\n",
    "            \"hold_bars\",\"exit_reason\"\n",
    "        ],\n",
    "        \"notes\": \"Mon–Fri se aplica sobre entry_time_utc (t+1).\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# Artifacts (salidas del run)\n",
    "# ---------------------------\n",
    "def _build_artifacts(run_dir: Path) -> Dict[str, str]:\n",
    "    return {\n",
    "        \"instrument_specs\": str(run_dir / \"instrument_specs_v2.parquet\"),\n",
    "        \"instrument_specs_snapshot\": str(run_dir / \"instrument_specs_snapshot_v2.json\"),\n",
    "\n",
    "        \"ohlcv_clean\": str(run_dir / \"ohlcv_clean_m5.parquet\"),\n",
    "        \"data_qa_report\": str(run_dir / \"data_qa_report_v2.json\"),\n",
    "\n",
    "        \"cost_model_snapshot\": str(run_dir / \"cost_model_snapshot_v2.json\"),\n",
    "        \"wfo_folds\": str(run_dir / \"wfo_folds_v2.parquet\"),\n",
    "        \"wfo_folds_snapshot\": str(run_dir / \"wfo_folds_snapshot_v2.json\"),\n",
    "\n",
    "        \"features_m5\": str(run_dir / \"features_m5_v2.parquet\"),\n",
    "        \"regime_params_by_fold\": str(run_dir / \"regime_params_by_fold_v2.parquet\"),\n",
    "        \"regime_params_snapshot\": str(run_dir / \"regime_params_snapshot_v2.json\"),\n",
    "\n",
    "        \"trades_baseline\": str(run_dir / \"trades_baseline_v2.parquet\"),\n",
    "        \"summary_baseline\": str(run_dir / \"summary_baseline_v2.parquet\"),\n",
    "\n",
    "        \"alpha_multi_horizon_report\": str(run_dir / \"alpha_multi_horizon_report_v2.parquet\"),\n",
    "        \"alpha_multi_horizon_snapshot\": str(run_dir / \"alpha_multi_horizon_snapshot_v2.json\"),\n",
    "\n",
    "        \"trades_engine\": str(run_dir / \"trades_engine_v2.parquet\"),\n",
    "        \"summary_engine\": str(run_dir / \"summary_engine_v2.parquet\"),\n",
    "        \"equity_engine\": str(run_dir / \"equity_curve_engine_v2.parquet\"),\n",
    "        \"engine_qa_report\": str(run_dir / \"engine_qa_report_v2.json\"),\n",
    "        \"engine_report_snapshot\": str(run_dir / \"engine_report_snapshot_v2.json\"),\n",
    "        \"signals_all\": str(run_dir / \"signals_all_v2.parquet\"),\n",
    "        \"signals_snapshot\": str(run_dir / \"signals_snapshot_v2.json\"),\n",
    "        \"qa_timing\": str(run_dir / \"qa_timing_v2.parquet\"),\n",
    "        \"tuning_results\": str(run_dir / \"tuning_results_v2.parquet\"),\n",
    "        \"tuning_best_params\": str(run_dir / \"tuning_best_params_v2.parquet\"),\n",
    "        \"tuning_snapshot\": str(run_dir / \"tuning_snapshot_v2.json\"),\n",
    "        \"alpha_design\": str(run_dir / \"alpha_design_v2.parquet\"),\n",
    "        \"alpha_design_snapshot\": str(run_dir / \"alpha_design_snapshot_v2.json\"),\n",
    "        \"selection\": str(run_dir / \"selection_v2.parquet\"),\n",
    "        \"selection_snapshot\": str(run_dir / \"selection_snapshot_v2.json\"),\n",
    "        \"overlay_trades\": str(run_dir / \"overlay_trades_v2.parquet\"),\n",
    "        \"overlay_summary\": str(run_dir / \"overlay_summary_v2.parquet\"),\n",
    "        \"overlay_snapshot\": str(run_dir / \"overlay_snapshot_v2.json\"),\n",
    "        \"deploy_pack\": str(run_dir / \"deploy_pack_v2.parquet\"),\n",
    "        \"deploy_pack_json\": str(run_dir / \"deploy_pack_v2.json\"),\n",
    "        \"qa_alignment\": str(run_dir / \"qa_alignment_v2.parquet\"),\n",
    "        \"qa_alignment_snapshot\": str(run_dir / \"qa_alignment_snapshot_v2.json\"),\n",
    "        \"diagnostics\": str(run_dir / \"diagnostics_v2.parquet\"),\n",
    "        \"diagnostics_snapshot\": str(run_dir / \"diagnostics_snapshot_v2.json\"),\n",
    "    }\n",
    "\n",
    "def _build_manifest() -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"schema_version\": SCHEMA_VERSION,\n",
    "        \"engine_version\": ENGINE_VERSION,\n",
    "        \"cost_model_version\": COST_MODEL_VERSION,\n",
    "        \"wfo_version\": WFO_VERSION,\n",
    "        \"run_mode\": RUN_MODE,\n",
    "        \"run_id\": RUN_ID,\n",
    "        \"created_utc\": _now_utc_iso(),\n",
    "        \"project_root\": str(PROJECT_ROOT),\n",
    "        \"workdir\": str(WORKDIR),\n",
    "        \"outputs_root\": str(OUTPUTS_ROOT),\n",
    "        \"run_dir\": str(RUN_DIR),\n",
    "        \"artifacts\": _build_artifacts(RUN_DIR),\n",
    "        \"canonical_schema\": CANONICAL_SCHEMA,\n",
    "        \"runtime\": {\n",
    "            \"python\": sys.version.replace(\"\\n\", \" \"),\n",
    "            \"platform\": platform.platform(),\n",
    "            \"node\": platform.node(),\n",
    "            \"pid\": os.getpid(),\n",
    "        },\n",
    "    }\n",
    "\n",
    "# ---------------------------\n",
    "# Guardado (solo carga manifest si el modo es RESUME/forced y existe)\n",
    "# ---------------------------\n",
    "_safe_mkdir(RUN_DIR)\n",
    "_safe_mkdir(OUTPUTS_ROOT)\n",
    "\n",
    "manifest: Dict[str, Any]\n",
    "if RUN_MANIFEST_PATH.exists() and RUN_MODE in (\"RESUME_LATEST\", \"FORCED_RUN_ID\"):\n",
    "    manifest = _read_json(RUN_MANIFEST_PATH)\n",
    "    # normaliza/bump versiones\n",
    "    manifest[\"schema_version\"] = SCHEMA_VERSION\n",
    "    manifest[\"engine_version\"] = ENGINE_VERSION\n",
    "    manifest[\"cost_model_version\"] = COST_MODEL_VERSION\n",
    "    manifest[\"wfo_version\"] = WFO_VERSION\n",
    "    manifest[\"run_mode\"] = RUN_MODE\n",
    "    manifest[\"project_root\"] = str(PROJECT_ROOT)\n",
    "    manifest[\"workdir\"] = str(WORKDIR)\n",
    "    manifest[\"outputs_root\"] = str(OUTPUTS_ROOT)\n",
    "    manifest[\"canonical_schema\"] = CANONICAL_SCHEMA\n",
    "    manifest[\"artifacts\"] = _build_artifacts(Path(manifest.get(\"run_dir\", str(RUN_DIR))))\n",
    "    _write_json(RUN_MANIFEST_PATH, manifest)\n",
    "    print(f\"[Celda 00 v2.0.3] Manifest CARGADO (resume/forced) y normalizado: {RUN_MANIFEST_PATH}\")\n",
    "else:\n",
    "    manifest = _build_manifest()\n",
    "    _write_json(RUN_MANIFEST_PATH, manifest)\n",
    "    print(f\"[Celda 00 v2.0.3] Manifest CREADO (nuevo run): {RUN_MANIFEST_PATH}\")\n",
    "\n",
    "# latest pointers\n",
    "_write_text(LATEST_RUN_MARKER, RUN_ID)\n",
    "_write_json(RUN_MANIFEST_LATEST_PATH, manifest)\n",
    "\n",
    "# RUN object (downstream)\n",
    "RUN: Dict[str, Any] = {\n",
    "    \"RUN_ID\": manifest[\"run_id\"],\n",
    "    \"RUN_MODE\": manifest[\"run_mode\"],\n",
    "    \"RUN_DIR\": Path(manifest[\"run_dir\"]),\n",
    "    \"PROJECT_ROOT\": Path(manifest[\"project_root\"]),\n",
    "    \"WORKDIR\": Path(manifest[\"workdir\"]),\n",
    "    \"OUTPUTS_ROOT\": Path(manifest[\"outputs_root\"]),\n",
    "    \"ARTIFACTS\": {k: Path(v) for k, v in manifest[\"artifacts\"].items()},\n",
    "    \"SCHEMA_VERSION\": manifest[\"schema_version\"],\n",
    "    \"ENGINE_VERSION\": manifest[\"engine_version\"],\n",
    "    \"CANONICAL_SCHEMA\": manifest[\"canonical_schema\"],\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# PRINTS exhaustivos\n",
    "# ---------------------------\n",
    "print(\"\\n--- Celda 00 v2.0.3 | Estado final ---\")\n",
    "print(\"RUN_MODE             :\", RUN[\"RUN_MODE\"])\n",
    "print(\"PROJECT_ROOT         :\", RUN[\"PROJECT_ROOT\"])\n",
    "print(\"WORKDIR              :\", RUN[\"WORKDIR\"])\n",
    "print(\"OUTPUTS_ROOT         :\", RUN[\"OUTPUTS_ROOT\"])\n",
    "print(\"RUN_ID               :\", RUN[\"RUN_ID\"])\n",
    "print(\"RUN_DIR              :\", RUN[\"RUN_DIR\"])\n",
    "print(\"RUN_MANIFEST_PATH    :\", RUN_MANIFEST_PATH)\n",
    "print(\"RUN_MANIFEST_LATEST  :\", RUN_MANIFEST_LATEST_PATH)\n",
    "print(\"LATEST_RUN_MARKER    :\", LATEST_RUN_MARKER)\n",
    "print(\"SCHEMA_VERSION       :\", RUN[\"SCHEMA_VERSION\"])\n",
    "print(\"ENGINE_VERSION       :\", RUN[\"ENGINE_VERSION\"])\n",
    "\n",
    "keys = sorted(RUN[\"ARTIFACTS\"].keys())\n",
    "print(\"\\n--- ARTIFACTS keys ---\")\n",
    "print(\"N_KEYS:\", len(keys))\n",
    "print(keys)\n",
    "\n",
    "critical = [\"instrument_specs\",\"instrument_specs_snapshot\",\"ohlcv_clean\",\"data_qa_report\"]\n",
    "missing_critical = [k for k in critical if k not in RUN[\"ARTIFACTS\"]]\n",
    "if missing_critical:\n",
    "    raise RuntimeError(f\"[Celda 00 v2.0.3] ERROR: faltan artifacts críticos: {missing_critical}\")\n",
    "\n",
    "print(\"\\n--- Dependencias ---\")\n",
    "import polars as pl\n",
    "print(\"polars:\", pl.__version__)\n",
    "try:\n",
    "    import pandas as pd\n",
    "    print(\"pandas:\", pd.__version__)\n",
    "except Exception as e:\n",
    "    print(\"pandas: no disponible:\", e)\n",
    "\n",
    "print(\"\\n[Celda 00 v2.0.3] OK — NEW_RUN por defecto + RUN listo.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c4695e",
   "metadata": {},
   "outputs": [],
   "source": "# ======================================================================================\n# Celda 01 v2.1.0 — Universe & Instrument Specs (por simbolo)\n# CAMBIO v2.1.0: Lee universe desde NB2 basket_trend_core.parquet via path_contract.\n# Fallback: FALLBACK_UNIVERSE hardcodeado (legacy).\n#\n# Inputs:  RUN (Celda 00)\n# Outputs: instrument_specs parquet + snapshot JSON\n# ======================================================================================\n\nfrom __future__ import annotations\n\nimport json\nfrom datetime import datetime, timezone\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional\n\nimport polars as pl\n\nif \"RUN\" not in globals():\n    raise RuntimeError(\"[Celda 01 v2.1.0] ERROR: No existe RUN. Ejecuta Celda 00 primero.\")\n\nARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n\nprint(\"\\n--- Celda 01 v2.1.0 | Basket Integration ---\")\nprint(\"RUN_ID   :\", RUN[\"RUN_ID\"])\nprint(\"RUN_MODE :\", RUN[\"RUN_MODE\"])\nprint(\"RUN_DIR  :\", RUN[\"RUN_DIR\"])\n\nOUT_SPECS_PARQUET = ARTIFACTS[\"instrument_specs\"]\nOUT_SPECS_SNAPSHOT = ARTIFACTS[\"instrument_specs_snapshot\"]\n\n# --- Cargar universe desde NB2 basket ---\nFALLBACK_UNIVERSE = [\"BNBUSD\", \"BTCUSD\", \"LVMH\", \"XAUAUD\"]\n\nbasket_path = path_contract.nb2_basket(\"trend\", PROJECT_ROOT)\n\n# Fallback: legacy location\nif basket_path is None:\n    _legacy = path_contract.nb2_outputs_dir(PROJECT_ROOT) / \"basket_trend_core.parquet\"\n    if _legacy.exists():\n        basket_path = _legacy\n\nif basket_path is not None and basket_path.exists():\n    basket_df = pl.read_parquet(basket_path)\n    if \"symbol\" in basket_df.columns:\n        symbols = basket_df.get_column(\"symbol\").unique().sort().to_list()\n        universe_source = \"nb2_basket_trend\"\n    else:\n        symbols = FALLBACK_UNIVERSE\n        universe_source = \"fallback_basket_no_symbol_col\"\n        print(\"[Celda 01] WARNING: basket sin columna 'symbol', usando fallback.\")\nelse:\n    symbols = FALLBACK_UNIVERSE\n    universe_source = \"fallback_hardcoded\"\n    basket_path = None\n    print(f\"[Celda 01] WARNING: basket_trend_core no encontrado, usando fallback: {symbols}\")\n\nsymbols = [s.upper().strip() for s in symbols]\n\nprint(f\"[Celda 01] UNIVERSE_SOURCE   : {universe_source}\")\nprint(f\"[Celda 01] UNIVERSE_EFFECTIVE : {symbols}\")\nprint(f\"[Celda 01] basket_path       : {basket_path}\")\n\n# --- Guardar en RUN ---\nRUN[\"UNIVERSE_EFFECTIVE\"] = symbols\nRUN[\"UNIVERSE_SOURCE\"] = universe_source\nRUN[\"INPUTS\"] = RUN.get(\"INPUTS\", {})\nRUN[\"INPUTS\"][\"basket_path\"] = str(basket_path) if basket_path else None\n\n# --- Instrument Specs (defaults + overrides por simbolo) ---\ndef _t(h: int, m: int = 0) -> str:\n    return f\"{h:02d}:{m:02d}\"\n\nDEFAULT_SPEC: Dict[str, Any] = {\n    \"asset_class\": \"forex\",\n    \"base_cost_bps\": 3.0,\n    \"stress_cost_bps\": 6.0,\n    \"entry_weekdays_only\": True,\n    \"flatten_before_weekend\": False,\n    \"session_weekdays_only\": True,\n    \"session_windows_utc_json\": \"[]\",\n    \"research_only\": False,\n    \"research_reason\": None,\n    \"tick_size_hint\": None,\n    \"contract_hint\": None,\n}\n\nOVERRIDES: Dict[str, Dict[str, Any]] = {\n    \"BNBUSD\": {\"asset_class\": \"crypto\", \"base_cost_bps\": 8.0, \"stress_cost_bps\": 16.0},\n    \"BTCUSD\": {\"asset_class\": \"crypto\", \"base_cost_bps\": 8.0, \"stress_cost_bps\": 16.0},\n    \"ETHUSD\": {\"asset_class\": \"crypto\", \"base_cost_bps\": 3.0, \"stress_cost_bps\": 6.0},\n    \"LVMH\":   {\"asset_class\": \"equity\", \"base_cost_bps\": 12.0, \"stress_cost_bps\": 25.0,\n               \"flatten_before_weekend\": True,\n               \"session_windows_utc_json\": json.dumps([{\"start\": _t(8, 0), \"end\": _t(16, 30)}])},\n    \"XAUAUD\": {\"asset_class\": \"fx_metal\", \"base_cost_bps\": 4.0, \"stress_cost_bps\": 8.0,\n               \"flatten_before_weekend\": True},\n    \"XAUUSD\": {\"asset_class\": \"fx_metal\", \"base_cost_bps\": 5.0, \"stress_cost_bps\": 10.0,\n               \"flatten_before_weekend\": True},\n}\n\nrows: List[Dict[str, Any]] = []\nfor sym in symbols:\n    spec = dict(DEFAULT_SPEC)\n    spec.update(OVERRIDES.get(sym, {}))\n    spec[\"symbol\"] = sym\n    rows.append(spec)\n\nspecs = pl.DataFrame(rows)\n\nprint(f\"\\n[Celda 01] specs shape: {specs.shape}\")\nprint(specs)\n\n# Gates duros\nbad_costs = specs.filter(\n    (pl.col(\"base_cost_bps\") <= 0) |\n    (pl.col(\"stress_cost_bps\") <= 0) |\n    (pl.col(\"stress_cost_bps\") < pl.col(\"base_cost_bps\"))\n)\nif bad_costs.height > 0:\n    raise RuntimeError(f\"[Celda 01] ERROR: costos invalidos:\\n{bad_costs}\")\n\nn_unique = specs.select(pl.col(\"symbol\").n_unique()).item()\nif n_unique != specs.height:\n    raise RuntimeError(\"[Celda 01] ERROR: simbolos duplicados en instrument_specs.\")\n\n# Persistencia\nOUT_SPECS_PARQUET.parent.mkdir(parents=True, exist_ok=True)\nspecs.write_parquet(OUT_SPECS_PARQUET)\n\nsnapshot = {\n    \"cell\": \"01 v2.1.0\",\n    \"created_utc\": datetime.now(timezone.utc).isoformat(timespec=\"seconds\"),\n    \"run_id\": RUN[\"RUN_ID\"],\n    \"run_mode\": RUN[\"RUN_MODE\"],\n    \"universe_source\": universe_source,\n    \"universe_effective\": symbols,\n    \"basket_path\": str(basket_path) if basket_path else None,\n    \"n_symbols\": len(symbols),\n    \"rows\": specs.to_dicts(),\n}\nOUT_SPECS_SNAPSHOT.write_text(\n    json.dumps(snapshot, indent=2, ensure_ascii=False), encoding=\"utf-8\"\n)\n\nprint(f\"\\n[Celda 01 v2.1.0] OK — {len(symbols)} symbols desde {universe_source}\")\nprint(f\"  parquet : {OUT_SPECS_PARQUET}\")\nprint(f\"  snapshot: {OUT_SPECS_SNAPSHOT}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b2fd714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Celda 02 v2.0.4 | Preflight ---\n",
      "RUN_ID     : 20260218_000143_164d8480\n",
      "RUN_MODE   : NEW_RUN_DEFAULT\n",
      "PROJECT_ROOT: C:\\Quant\\projects\\MT5_Data_Extraction\n",
      "RUN_DIR    : C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\n",
      "SPECS_PATH : C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\instrument_specs_v2.parquet\n",
      "OUT_OHLCV  : C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\ohlcv_clean_m5.parquet\n",
      "OUT_QA     : C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\data_qa_report_v2.json\n",
      "\n",
      "[Celda 02 v2.0.4] Candidatos M5 probados (exist/parquets):\n",
      "  - C:\\Quant\\projects\\MT5_Data_Extraction\\data\\historical_data\\m5_clean | exists=True | parquet_count~=2000\n",
      "  - C:\\Quant\\projects\\MT5_Data_Extraction\\data\\bulk_data\\m5_raw | exists=True | parquet_count~=2000\n",
      "\n",
      "[Celda 02 v2.0.4] M5_DIR seleccionado: C:\\Quant\\projects\\MT5_Data_Extraction\\data\\historical_data\\m5_clean\n",
      "[Celda 02 v2.0.4] M5_DIR_MODE       : AUTO_CANDIDATE\n",
      "\n",
      "[Celda 02 v2.0.4] Universe: ['BNBUSD', 'BTCUSD', 'LVMH', 'XAUAUD']\n",
      "\n",
      "[Celda 02 v2.0.4] Layout detectado:\n",
      "  IS_HIVE(symbol=...): True\n",
      "  sample partitions: ['symbol=AAPL', 'symbol=AAVUSD', 'symbol=ADAUSD', 'symbol=AIRF', 'symbol=ALGUSD']\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Celda 02 v2.0.4] Loading symbol=BNBUSD\n",
      "[Celda 02 v2.0.4] Columns(sample): ['timestamp_utc', 'timestamp_gye', 'symbol', 'open', 'high', 'low', 'close', 'tick_volume', 'real_volume', 'spread_points', 'broker', 'server_tz'] \n",
      "[Celda 02 v2.0.4] Loaded rows (raw): 430323\n",
      "[Celda 02 v2.0.4] After dedup rows: 430323 | dup_removed: 0\n",
      "[Celda 02 v2.0.4] start_utc: 2021-11-19 00:00:00\n",
      "[Celda 02 v2.0.4] end_utc  : 2026-02-16 23:50:00\n",
      "[Celda 02 v2.0.4] intraday share_300s: 0.9997644457712186\n",
      "[Celda 02 v2.0.4] coverage_intraday_pct: 99.60%\n",
      "[Celda 02 v2.0.4] gaps_total   : {'gap_count': 443, 'gap_rate': 0.0010294616589437678, 'missing_bars_est': 16364, 'max_gap_seconds': 125100}\n",
      "[Celda 02 v2.0.4] gaps_intraday: {'gap_count': 101, 'gap_rate': 0.00023555422878146165, 'missing_bars_est': 1735, 'max_gap_seconds': 54300, 'share_300s': 0.9997644457712186}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Celda 02 v2.0.4] Loading symbol=BTCUSD\n",
      "[Celda 02 v2.0.4] Columns(sample): ['timestamp_utc', 'timestamp_gye', 'symbol', 'open', 'high', 'low', 'close', 'tick_volume', 'real_volume', 'spread_points', 'broker', 'server_tz'] \n",
      "[Celda 02 v2.0.4] Loaded rows (raw): 358028\n",
      "[Celda 02 v2.0.4] After dedup rows: 358028 | dup_removed: 0\n",
      "[Celda 02 v2.0.4] start_utc: 2021-11-19 00:00:00\n",
      "[Celda 02 v2.0.4] end_utc  : 2026-02-16 23:50:00\n",
      "[Celda 02 v2.0.4] intraday share_300s: 0.9905605596900834\n",
      "[Celda 02 v2.0.4] coverage_intraday_pct: 89.49%\n",
      "[Celda 02 v2.0.4] gaps_total   : {'gap_count': 4907, 'gap_rate': 0.013705670242747055, 'missing_bars_est': 88659, 'max_gap_seconds': 172800}\n",
      "[Celda 02 v2.0.4] gaps_intraday: {'gap_count': 3365, 'gap_rate': 0.009439440309916601, 'missing_bars_est': 42063, 'max_gap_seconds': 61500, 'share_300s': 0.9905605596900834}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Celda 02 v2.0.4] Loading symbol=LVMH\n",
      "[Celda 02 v2.0.4] Columns(sample): ['timestamp_utc', 'timestamp_gye', 'symbol', 'open', 'high', 'low', 'close', 'tick_volume', 'real_volume', 'spread_points', 'broker', 'server_tz'] \n",
      "[Celda 02 v2.0.4] Loaded rows (raw): 109289\n",
      "[Celda 02 v2.0.4] After dedup rows: 109289 | dup_removed: 0\n",
      "[Celda 02 v2.0.4] start_utc: 2021-11-19 10:00:00\n",
      "[Celda 02 v2.0.4] end_utc  : 2026-02-16 18:25:00\n",
      "[Celda 02 v2.0.4] intraday share_300s: 0.9998983439302085\n",
      "[Celda 02 v2.0.4] coverage_intraday_pct: 99.96%\n",
      "[Celda 02 v2.0.4] gaps_total   : {'gap_count': 1091, 'gap_rate': 0.009982797745406632, 'missing_bars_est': 337213, 'max_gap_seconds': 488400}\n",
      "[Celda 02 v2.0.4] gaps_intraday: {'gap_count': 11, 'gap_rate': 0.00010165606979151265, 'missing_bars_est': 39, 'max_gap_seconds': 3000, 'share_300s': 0.9998983439302085}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Celda 02 v2.0.4] Loading symbol=XAUAUD\n",
      "[Celda 02 v2.0.4] Columns(sample): ['timestamp_utc', 'timestamp_gye', 'symbol', 'open', 'high', 'low', 'close', 'tick_volume', 'real_volume', 'spread_points', 'broker', 'server_tz'] \n",
      "[Celda 02 v2.0.4] Loaded rows (raw): 297135\n",
      "[Celda 02 v2.0.4] After dedup rows: 297135 | dup_removed: 0\n",
      "[Celda 02 v2.0.4] start_utc: 2021-11-19 01:05:00\n",
      "[Celda 02 v2.0.4] end_utc  : 2026-02-16 21:25:00\n",
      "[Celda 02 v2.0.4] intraday share_300s: 0.9999898662685236\n",
      "[Celda 02 v2.0.4] coverage_intraday_pct: 100.00%\n",
      "[Celda 02 v2.0.4] gaps_total   : {'gap_count': 1096, 'gap_rate': 0.003688571486265456, 'missing_bars_est': 149510, 'max_gap_seconds': 264000}\n",
      "[Celda 02 v2.0.4] gaps_intraday: {'gap_count': 3, 'gap_rate': 1.013373147638334e-05, 'missing_bars_est': 7, 'max_gap_seconds': 1800, 'share_300s': 0.9999898662685236}\n",
      "\n",
      "[Celda 02 v2.0.4] OK — ohlcv_clean creado: C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\ohlcv_clean_m5.parquet | exists: True\n",
      "[Celda 02 v2.0.4] OK — data_qa_report creado: C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\data_qa_report_v2.json | exists: True\n",
      "\n",
      "--- Preview (head) ---\n",
      "shape: (5, 8)\n",
      "┌─────────────────────┬────────┬────────┬────────┬────────┬────────┬────────┬────────┐\n",
      "│ time_utc            ┆ open   ┆ high   ┆ low    ┆ close  ┆ volume ┆ spread ┆ symbol │\n",
      "│ ---                 ┆ ---    ┆ ---    ┆ ---    ┆ ---    ┆ ---    ┆ ---    ┆ ---    │\n",
      "│ datetime[ms]        ┆ f64    ┆ f64    ┆ f64    ┆ f64    ┆ f64    ┆ f64    ┆ str    │\n",
      "╞═════════════════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╡\n",
      "│ 2021-11-19 00:00:00 ┆ 537.88 ┆ 540.08 ┆ 537.88 ┆ 539.68 ┆ 90.0   ┆ 254.0  ┆ BNBUSD │\n",
      "│ 2021-11-19 00:05:00 ┆ 539.68 ┆ 540.08 ┆ 538.08 ┆ 538.08 ┆ 58.0   ┆ 254.0  ┆ BNBUSD │\n",
      "│ 2021-11-19 00:10:00 ┆ 538.08 ┆ 540.48 ┆ 538.08 ┆ 539.48 ┆ 66.0   ┆ 254.0  ┆ BNBUSD │\n",
      "│ 2021-11-19 00:15:00 ┆ 539.48 ┆ 539.78 ┆ 537.98 ┆ 538.08 ┆ 69.0   ┆ 254.0  ┆ BNBUSD │\n",
      "│ 2021-11-19 00:20:00 ┆ 538.08 ┆ 538.38 ┆ 536.78 ┆ 536.88 ┆ 64.0   ┆ 254.0  ┆ BNBUSD │\n",
      "└─────────────────────┴────────┴────────┴────────┴────────┴────────┴────────┴────────┘\n",
      "\n",
      "--- QA (resumen) ---\n",
      "shape: (4, 4)\n",
      "┌────────┬────────┬─────────────┬───────────────────────┐\n",
      "│ symbol ┆ rows   ┆ dup_removed ┆ coverage_intraday_pct │\n",
      "│ ---    ┆ ---    ┆ ---         ┆ ---                   │\n",
      "│ str    ┆ i64    ┆ i64         ┆ f64                   │\n",
      "╞════════╪════════╪═════════════╪═══════════════════════╡\n",
      "│ BNBUSD ┆ 430323 ┆ 0           ┆ 99.598434             │\n",
      "│ BTCUSD ┆ 358028 ┆ 0           ┆ 89.486642             │\n",
      "│ LVMH   ┆ 109289 ┆ 0           ┆ 99.964328             │\n",
      "│ XAUAUD ┆ 297135 ┆ 0           ┆ 99.997644             │\n",
      "└────────┴────────┴─────────────┴───────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# Celda 02 v2.0.4 — Load M5 (m5_clean) + Canonicalize + QA (AUTO-RUTAS estilo v1)\n",
    "# Propósito:\n",
    "#   - Construir ohlcv_clean_m5.parquet (schema canónico) desde tu M5 limpio REAL (v1).\n",
    "#   - QA mínimo institucional: dedup, monotonic, gaps total + intraday, share_300s.\n",
    "#\n",
    "# Inputs:\n",
    "#   - RUN (Celda 00 v2.0.3)\n",
    "#   - instrument_specs (Celda 01)\n",
    "#\n",
    "# Política de rutas (FINAL):\n",
    "#   - Si defines TREND_M5_M5_CLEAN_DIR -> usa esa (prioridad absoluta).\n",
    "#   - Si no, autodetecta en candidatos reales (como v1):\n",
    "#       * <PROJECT_ROOT>/data/historical_data/m5_clean\n",
    "#       * <PROJECT_ROOT>/data/rates_5m\n",
    "#       * <PROJECT_ROOT>/data/historical_data/rates_5m\n",
    "#       * <PROJECT_ROOT>/data/bulk_data/m5_raw   (último fallback)\n",
    "#\n",
    "# Outputs:\n",
    "#   - RUN[\"ARTIFACTS\"][\"ohlcv_clean\"]\n",
    "#   - RUN[\"ARTIFACTS\"][\"data_qa_report\"]\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "import itertools\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "if \"RUN\" not in globals():\n",
    "    raise RuntimeError(\"[Celda 02 v2.0.4] ERROR: No existe RUN. Ejecuta Celda 00 v2.0.3 primero.\")\n",
    "\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "PROJECT_ROOT: Path = RUN[\"PROJECT_ROOT\"]\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "\n",
    "SPECS_PATH = ARTIFACTS[\"instrument_specs\"]\n",
    "OUT_OHLCV = ARTIFACTS[\"ohlcv_clean\"]\n",
    "OUT_QA = ARTIFACTS[\"data_qa_report\"]\n",
    "\n",
    "print(\"\\n--- Celda 02 v2.0.4 | Preflight ---\")\n",
    "print(\"RUN_ID     :\", RUN[\"RUN_ID\"])\n",
    "print(\"RUN_MODE   :\", RUN.get(\"RUN_MODE\"))\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"RUN_DIR    :\", RUN_DIR)\n",
    "print(\"SPECS_PATH :\", SPECS_PATH)\n",
    "print(\"OUT_OHLCV  :\", OUT_OHLCV)\n",
    "print(\"OUT_QA     :\", OUT_QA)\n",
    "\n",
    "if not SPECS_PATH.exists():\n",
    "    raise RuntimeError(f\"[Celda 02 v2.0.4] ERROR: Falta instrument_specs: {SPECS_PATH}. Ejecuta Celda 01 primero.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Config / constants\n",
    "# -----------------------------\n",
    "EXPECTED_BAR_SECONDS = 300  # M5\n",
    "FORCED_M5_DIR = os.getenv(\"TREND_M5_M5_CLEAN_DIR\", \"\").strip()\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "TIME_CANDS = [\"time_utc\", \"timestamp_utc\", \"datetime\", \"timestamp\", \"time\", \"date\"]\n",
    "O_CANDS = [\"open\", \"o\"]\n",
    "H_CANDS = [\"high\", \"h\"]\n",
    "L_CANDS = [\"low\", \"l\"]\n",
    "C_CANDS = [\"close\", \"c\"]\n",
    "V_CANDS = [\"volume\", \"vol\", \"tick_volume\"]\n",
    "\n",
    "def _pick_col(cols: List[str], cands: List[str]) -> Optional[str]:\n",
    "    m = {c.lower(): c for c in cols}\n",
    "    for x in cands:\n",
    "        if x.lower() in m:\n",
    "            return m[x.lower()]\n",
    "    return None\n",
    "\n",
    "def _count_parquets_quick(p: Path, limit: int = 2000) -> int:\n",
    "    if not p.exists():\n",
    "        return 0\n",
    "    it = p.rglob(\"*.parquet\")\n",
    "    return sum(1 for _ in itertools.islice(it, limit))\n",
    "\n",
    "def _detect_m5_clean_dir() -> Tuple[Path, str]:\n",
    "    \"\"\"\n",
    "    Retorna: (dir, mode)\n",
    "      mode:\n",
    "        - FORCED_ENV\n",
    "        - AUTO_CANDIDATE\n",
    "    \"\"\"\n",
    "    if FORCED_M5_DIR:\n",
    "        d = Path(FORCED_M5_DIR).resolve()\n",
    "        return d, \"FORCED_ENV\"\n",
    "\n",
    "    candidates = [\n",
    "        path_contract.m5_clean_dir(PROJECT_ROOT),   # data/historical_data/m5_clean\n",
    "        path_contract.m5_raw_dir(PROJECT_ROOT),      # data/bulk_data/m5_raw\n",
    "    ]\n",
    "\n",
    "    print(\"\\n[Celda 02 v2.0.4] Candidatos M5 probados (exist/parquets):\")\n",
    "    best = None\n",
    "    best_n = -1\n",
    "    for c in candidates:\n",
    "        n = _count_parquets_quick(c)\n",
    "        print(f\"  - {c} | exists={c.exists()} | parquet_count~={n}\")\n",
    "        if c.exists() and n > best_n:\n",
    "            best = c\n",
    "            best_n = n\n",
    "\n",
    "    if best is None or not best.exists() or best_n <= 0:\n",
    "        raise RuntimeError(\n",
    "            \"[Celda 02 v2.0.4] ERROR: No pude detectar el directorio real de datos M5.\\n\"\n",
    "            \"Solución: define TREND_M5_M5_CLEAN_DIR apuntando a tu carpeta m5_clean.\\n\"\n",
    "            \"Ejemplo (PowerShell):\\n\"\n",
    "            \"  $env:TREND_M5_M5_CLEAN_DIR = '<PROJECT_ROOT>\\\\data\\\\historical_data\\\\m5_clean'\\n\"\n",
    "        )\n",
    "    return best, \"AUTO_CANDIDATE\"\n",
    "\n",
    "def _coerce_time_expr(col: str, dtype: pl.DataType) -> pl.Expr:\n",
    "    if dtype in (pl.Int64, pl.Int32, pl.UInt64, pl.UInt32):\n",
    "        # epoch detect (best-effort)\n",
    "        return pl.when(pl.col(col) > 10**17).then(pl.from_epoch(pl.col(col), time_unit=\"ns\")) \\\n",
    "                 .when(pl.col(col) > 10**14).then(pl.from_epoch(pl.col(col), time_unit=\"us\")) \\\n",
    "                 .when(pl.col(col) > 10**11).then(pl.from_epoch(pl.col(col), time_unit=\"ms\")) \\\n",
    "                 .otherwise(pl.from_epoch(pl.col(col), time_unit=\"s\")) \\\n",
    "                 .alias(\"time_utc\")\n",
    "    return pl.col(col).cast(pl.Datetime, strict=False).alias(\"time_utc\")\n",
    "\n",
    "def _gap_stats_total(times: pl.Series) -> Dict[str, Any]:\n",
    "    if times.len() < 2:\n",
    "        return {\"gap_count\": 0, \"gap_rate\": 0.0, \"missing_bars_est\": 0, \"max_gap_seconds\": 0}\n",
    "    dt = times.diff().dt.total_seconds().drop_nulls()\n",
    "    if dt.len() == 0:\n",
    "        return {\"gap_count\": 0, \"gap_rate\": 0.0, \"missing_bars_est\": 0, \"max_gap_seconds\": 0}\n",
    "    gap_count = int((dt > EXPECTED_BAR_SECONDS).sum())\n",
    "    max_gap = int(dt.max() or 0)\n",
    "    missing = ((dt // EXPECTED_BAR_SECONDS) - 1).clip(lower_bound=0)\n",
    "    missing_est = int(missing.sum() or 0)\n",
    "    gap_rate = float(gap_count / max(dt.len(), 1))\n",
    "    return {\"gap_count\": gap_count, \"gap_rate\": gap_rate, \"missing_bars_est\": missing_est, \"max_gap_seconds\": max_gap}\n",
    "\n",
    "def _gap_stats_intraday(df_times: pl.DataFrame) -> Dict[str, Any]:\n",
    "    if df_times.height < 2:\n",
    "        return {\"gap_count\": 0, \"gap_rate\": 0.0, \"missing_bars_est\": 0, \"max_gap_seconds\": 0, \"share_300s\": 1.0}\n",
    "    tmp = (\n",
    "        df_times\n",
    "        .with_columns(pl.col(\"time_utc\").dt.truncate(\"1d\").alias(\"_day\"))\n",
    "        .select(((pl.col(\"time_utc\").diff().dt.total_seconds()).over(\"_day\")).alias(\"dt_sec\"))\n",
    "        .drop_nulls()\n",
    "    )\n",
    "    if tmp.height == 0:\n",
    "        return {\"gap_count\": 0, \"gap_rate\": 0.0, \"missing_bars_est\": 0, \"max_gap_seconds\": 0, \"share_300s\": 1.0}\n",
    "    dt = tmp[\"dt_sec\"]\n",
    "    gap_count = int((dt > EXPECTED_BAR_SECONDS).sum())\n",
    "    max_gap = int(dt.max() or 0)\n",
    "    missing = ((dt // EXPECTED_BAR_SECONDS) - 1).clip(lower_bound=0)\n",
    "    missing_est = int(missing.sum() or 0)\n",
    "    gap_rate = float(gap_count / max(dt.len(), 1))\n",
    "    share_300s = float((dt == EXPECTED_BAR_SECONDS).sum() / max(dt.len(), 1))\n",
    "    return {\"gap_count\": gap_count, \"gap_rate\": gap_rate, \"missing_bars_est\": missing_est, \"max_gap_seconds\": max_gap, \"share_300s\": share_300s}\n",
    "\n",
    "def _expected_bars_data_driven(df_times: pl.DataFrame) -> int:\n",
    "    if df_times.height == 0:\n",
    "        return 0\n",
    "    per_day = (\n",
    "        df_times\n",
    "        .with_columns(pl.col(\"time_utc\").dt.truncate(\"1d\").alias(\"_day\"))\n",
    "        .group_by(\"_day\")\n",
    "        .agg([pl.min(\"time_utc\").alias(\"t0\"), pl.max(\"time_utc\").alias(\"t1\")])\n",
    "        .with_columns(((pl.col(\"t1\") - pl.col(\"t0\")).dt.total_seconds() // EXPECTED_BAR_SECONDS + 1).cast(pl.Int64).alias(\"exp\"))\n",
    "    )\n",
    "    return int(per_day.select(pl.col(\"exp\").sum()).item() or 0)\n",
    "\n",
    "# -----------------------------\n",
    "# Detect M5 dir\n",
    "# -----------------------------\n",
    "M5_DIR, M5_DIR_MODE = _detect_m5_clean_dir()\n",
    "print(\"\\n[Celda 02 v2.0.4] M5_DIR seleccionado:\", M5_DIR)\n",
    "print(\"[Celda 02 v2.0.4] M5_DIR_MODE       :\", M5_DIR_MODE)\n",
    "\n",
    "# -----------------------------\n",
    "# Universe\n",
    "# -----------------------------\n",
    "specs = pl.read_parquet(SPECS_PATH)\n",
    "universe = specs.select(\"symbol\").to_series().to_list()\n",
    "print(\"\\n[Celda 02 v2.0.4] Universe:\", universe)\n",
    "\n",
    "# -----------------------------\n",
    "# Detect layout: hive partition symbol=...\n",
    "# -----------------------------\n",
    "symbol_partitions = [d for d in M5_DIR.iterdir() if d.is_dir() and d.name.lower().startswith(\"symbol=\")]\n",
    "IS_HIVE = len(symbol_partitions) > 0\n",
    "print(\"\\n[Celda 02 v2.0.4] Layout detectado:\")\n",
    "print(\"  IS_HIVE(symbol=...):\", IS_HIVE)\n",
    "if IS_HIVE:\n",
    "    print(\"  sample partitions:\", [d.name for d in symbol_partitions[:5]])\n",
    "\n",
    "# -----------------------------\n",
    "# Cargar por símbolo + canonicalizar\n",
    "# -----------------------------\n",
    "required_cols = [\"time_utc\",\"open\",\"high\",\"low\",\"close\",\"volume\",\"spread\",\"symbol\"]\n",
    "dfs: List[pl.DataFrame] = []\n",
    "qa_rows: List[Dict[str, Any]] = []\n",
    "\n",
    "for sym in universe:\n",
    "    print(\"\\n\" + \"-\"*100)\n",
    "    print(f\"[Celda 02 v2.0.4] Loading symbol={sym}\")\n",
    "\n",
    "    if IS_HIVE:\n",
    "        sym_dir = M5_DIR / f\"symbol={sym}\"\n",
    "        if not sym_dir.exists():\n",
    "            raise RuntimeError(f\"[Celda 02 v2.0.4] ERROR: No existe partición {sym_dir}\")\n",
    "        glob = str(sym_dir / \"**\" / \"*.parquet\")\n",
    "        lf = pl.scan_parquet(glob)\n",
    "    else:\n",
    "        glob = str(M5_DIR / \"**\" / \"*.parquet\")\n",
    "        lf = pl.scan_parquet(glob)\n",
    "\n",
    "    schema = lf.collect_schema()\n",
    "    cols = schema.names()\n",
    "    print(\"[Celda 02 v2.0.4] Columns(sample):\", cols[:20], (\"...\" if len(cols) > 20 else \"\"))\n",
    "\n",
    "    tcol = _pick_col(cols, TIME_CANDS)\n",
    "    ocol = _pick_col(cols, O_CANDS)\n",
    "    hcol = _pick_col(cols, H_CANDS)\n",
    "    lcol = _pick_col(cols, L_CANDS)\n",
    "    ccol = _pick_col(cols, C_CANDS)\n",
    "    vcol = _pick_col(cols, V_CANDS)\n",
    "\n",
    "    if tcol is None or ocol is None or hcol is None or lcol is None or ccol is None:\n",
    "        raise RuntimeError(\n",
    "            f\"[Celda 02 v2.0.4] ERROR: columnas OHLCV faltantes en {sym}. \"\n",
    "            f\"time={tcol}, open={ocol}, high={hcol}, low={lcol}, close={ccol}. cols={cols}\"\n",
    "        )\n",
    "\n",
    "    spread_col = next((c for c in cols if c.lower() in (\"spread\", \"spread_points\")), None)\n",
    "    sym_col = next((c for c in cols if c.lower() == \"symbol\"), None)\n",
    "\n",
    "    # construir select canónico\n",
    "    time_expr = _coerce_time_expr(tcol, schema[tcol])\n",
    "\n",
    "    volume_expr = (pl.col(vcol).cast(pl.Float64).alias(\"volume\")) if vcol else pl.lit(0.0).cast(pl.Float64).alias(\"volume\")\n",
    "\n",
    "    if spread_col:\n",
    "        spread_expr = pl.col(spread_col).cast(pl.Float64).alias(\"spread\")\n",
    "    else:\n",
    "        spread_expr = pl.lit(0.0).cast(pl.Float64).alias(\"spread\")\n",
    "\n",
    "    if IS_HIVE:\n",
    "        # en hive particionado, puede no existir 'symbol' dentro del parquet\n",
    "        sym_expr = (pl.col(sym_col).cast(pl.Utf8).alias(\"symbol\")) if sym_col else pl.lit(sym).cast(pl.Utf8).alias(\"symbol\")\n",
    "    else:\n",
    "        # si no es hive, debería existir symbol o filtramos por columna si existe\n",
    "        sym_expr = (pl.col(sym_col).cast(pl.Utf8).alias(\"symbol\")) if sym_col else pl.lit(sym).cast(pl.Utf8).alias(\"symbol\")\n",
    "\n",
    "    lf2 = lf.select([\n",
    "        time_expr,\n",
    "        pl.col(ocol).cast(pl.Float64).alias(\"open\"),\n",
    "        pl.col(hcol).cast(pl.Float64).alias(\"high\"),\n",
    "        pl.col(lcol).cast(pl.Float64).alias(\"low\"),\n",
    "        pl.col(ccol).cast(pl.Float64).alias(\"close\"),\n",
    "        volume_expr,\n",
    "        spread_expr,\n",
    "        sym_expr,\n",
    "    ]).drop_nulls([\"time_utc\"])\n",
    "\n",
    "    if (not IS_HIVE) and sym_col:\n",
    "        lf2 = lf2.filter(pl.col(\"symbol\") == sym)\n",
    "    elif IS_HIVE:\n",
    "        lf2 = lf2.with_columns(pl.lit(sym).alias(\"symbol\"))\n",
    "\n",
    "    df = lf2.collect()\n",
    "    print(\"[Celda 02 v2.0.4] Loaded rows (raw):\", df.height)\n",
    "\n",
    "    # sort + dedup\n",
    "    n_before = df.height\n",
    "    df = df.sort(\"time_utc\").unique(subset=[\"time_utc\"], keep=\"last\")\n",
    "    n_after = df.height\n",
    "    dup_removed = n_before - n_after\n",
    "    print(\"[Celda 02 v2.0.4] After dedup rows:\", n_after, \"| dup_removed:\", dup_removed)\n",
    "\n",
    "    if n_after == 0:\n",
    "        raise RuntimeError(f\"[Celda 02 v2.0.4] ERROR: {sym} quedó vacío tras limpiar.\")\n",
    "\n",
    "    # monotonic sanity\n",
    "    min_dt = df.select(pl.col(\"time_utc\").diff().dt.total_seconds().min()).item()\n",
    "    if min_dt is not None and float(min_dt) < 0:\n",
    "        raise RuntimeError(f\"[Celda 02 v2.0.4] ERROR: {sym} no es monotónico (dt_min={min_dt}).\")\n",
    "\n",
    "    times = df[\"time_utc\"]\n",
    "    start = times.min()\n",
    "    end = times.max()\n",
    "\n",
    "    total_gaps = _gap_stats_total(times)\n",
    "    intraday_gaps = _gap_stats_intraday(df.select([\"time_utc\"]))\n",
    "\n",
    "    expected_intraday = _expected_bars_data_driven(df.select([\"time_utc\"]))\n",
    "    coverage_intraday_pct = float(n_after / expected_intraday * 100.0) if expected_intraday > 0 else 0.0\n",
    "\n",
    "    print(\"[Celda 02 v2.0.4] start_utc:\", start)\n",
    "    print(\"[Celda 02 v2.0.4] end_utc  :\", end)\n",
    "    print(\"[Celda 02 v2.0.4] intraday share_300s:\", intraday_gaps[\"share_300s\"])\n",
    "    print(\"[Celda 02 v2.0.4] coverage_intraday_pct:\", f\"{coverage_intraday_pct:.2f}%\")\n",
    "    print(\"[Celda 02 v2.0.4] gaps_total   :\", total_gaps)\n",
    "    print(\"[Celda 02 v2.0.4] gaps_intraday:\", intraday_gaps)\n",
    "\n",
    "    # Gate duro: intraday M5 consistente\n",
    "    if float(intraday_gaps[\"share_300s\"]) < 0.90:\n",
    "        raise RuntimeError(\n",
    "            f\"[Celda 02 v2.0.4] ERROR: {sym} intraday share_300s={intraday_gaps['share_300s']:.3f} < 0.90. \"\n",
    "            \"Tu dataset NO es M5 consistente intradía.\"\n",
    "        )\n",
    "\n",
    "    qa_rows.append({\n",
    "        \"symbol\": sym,\n",
    "        \"m5_dir\": str(M5_DIR),\n",
    "        \"layout_hive\": bool(IS_HIVE),\n",
    "        \"rows\": int(n_after),\n",
    "        \"dup_removed\": int(dup_removed),\n",
    "        \"start_utc\": str(start),\n",
    "        \"end_utc\": str(end),\n",
    "        \"coverage_intraday_pct\": float(coverage_intraday_pct),\n",
    "        \"gaps_total\": total_gaps,\n",
    "        \"gaps_intraday\": intraday_gaps,\n",
    "    })\n",
    "\n",
    "    dfs.append(df.select(required_cols))\n",
    "\n",
    "# Concatenar todo (schema canónico)\n",
    "ohlcv = pl.concat(dfs, how=\"vertical\").sort([\"symbol\", \"time_utc\"])\n",
    "\n",
    "missing_cols = [c for c in required_cols if c not in ohlcv.columns]\n",
    "if missing_cols:\n",
    "    raise RuntimeError(f\"[Celda 02 v2.0.4] ERROR: dataset no canónico, faltan columnas: {missing_cols}\")\n",
    "\n",
    "# Persistir\n",
    "OUT_OHLCV.parent.mkdir(parents=True, exist_ok=True)\n",
    "ohlcv.write_parquet(OUT_OHLCV)\n",
    "\n",
    "qa_report = {\n",
    "    \"cell\": \"02 v2.0.4\",\n",
    "    \"created_utc\": datetime.now(timezone.utc).isoformat(timespec=\"seconds\"),\n",
    "    \"run_id\": RUN[\"RUN_ID\"],\n",
    "    \"run_dir\": str(RUN_DIR),\n",
    "    \"project_root\": str(PROJECT_ROOT),\n",
    "    \"m5_dir\": str(M5_DIR),\n",
    "    \"m5_dir_mode\": M5_DIR_MODE,\n",
    "    \"layout_hive\": bool(IS_HIVE),\n",
    "    \"expected_bar_seconds\": EXPECTED_BAR_SECONDS,\n",
    "    \"n_rows_total\": int(ohlcv.height),\n",
    "    \"n_symbols\": int(ohlcv.select(pl.col(\"symbol\").n_unique()).item()),\n",
    "    \"per_symbol\": qa_rows,\n",
    "    \"notes\": [\n",
    "        \"QA intraday evita penalizar overnight/weekend.\",\n",
    "        \"Gate duro: share_300s >= 0.90 para consistencia M5 intradía.\",\n",
    "        \"Si no detecta M5_DIR, setea TREND_M5_M5_CLEAN_DIR explícitamente.\"\n",
    "    ],\n",
    "}\n",
    "OUT_QA.write_text(json.dumps(qa_report, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"\\n[Celda 02 v2.0.4] OK — ohlcv_clean creado: {OUT_OHLCV} | exists: {OUT_OHLCV.exists()}\")\n",
    "print(f\"[Celda 02 v2.0.4] OK — data_qa_report creado: {OUT_QA} | exists: {OUT_QA.exists()}\")\n",
    "\n",
    "print(\"\\n--- Preview (head) ---\")\n",
    "print(ohlcv.head(5))\n",
    "\n",
    "print(\"\\n--- QA (resumen) ---\")\n",
    "print(pl.DataFrame(qa_rows).select([\"symbol\",\"rows\",\"dup_removed\",\"coverage_intraday_pct\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efc2e9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Celda 03 v2.0.1] QA detected: True | QA path: C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\data_qa_report_v2.json\n",
      "\n",
      "--- Sanity order/spacing (time_utc diff stats) ---\n",
      "shape: (4, 4)\n",
      "┌────────┬────────────┬────────────┬────────┐\n",
      "│ symbol ┆ min_dt_sec ┆ max_dt_sec ┆ n_rows │\n",
      "│ ---    ┆ ---        ┆ ---        ┆ ---    │\n",
      "│ str    ┆ i64        ┆ i64        ┆ u32    │\n",
      "╞════════╪════════════╪════════════╪════════╡\n",
      "│ BNBUSD ┆ 300        ┆ 125100     ┆ 430323 │\n",
      "│ BTCUSD ┆ 300        ┆ 172800     ┆ 358028 │\n",
      "│ LVMH   ┆ 300        ┆ 488400     ┆ 109289 │\n",
      "│ XAUAUD ┆ 300        ┆ 264000     ┆ 297135 │\n",
      "└────────┴────────────┴────────────┴────────┘\n",
      "\n",
      "--- Microstructure proxies (from OHLCV clean) ---\n",
      "shape: (4, 7)\n",
      "┌────────┬────────┬────────────────┬───────────────┬───────────────┬───────────────┬───────────────┐\n",
      "│ symbol ┆ n_rows ┆ n_spread_nonnu ┆ spread_med_bp ┆ spread_p95_bp ┆ vol_med_absre ┆ vol_p95_absre │\n",
      "│ ---    ┆ ---    ┆ ll             ┆ s             ┆ s             ┆ t_bps         ┆ t_bps         │\n",
      "│ str    ┆ u32    ┆ ---            ┆ ---           ┆ ---           ┆ ---           ┆ ---           │\n",
      "│        ┆        ┆ u32            ┆ f64           ┆ f64           ┆ f64           ┆ f64           │\n",
      "╞════════╪════════╪════════════════╪═══════════════╪═══════════════╪═══════════════╪═══════════════╡\n",
      "│ BNBUSD ┆ 430323 ┆ 430323         ┆ 34.421631     ┆ 139.056271    ┆ 7.744125      ┆ 37.043054     │\n",
      "│ BTCUSD ┆ 358028 ┆ 358028         ┆ 365.964191    ┆ 523.409489    ┆ 6.137622      ┆ 30.537179     │\n",
      "│ LVMH   ┆ 109289 ┆ 109289         ┆ 187.295596    ┆ 582.940188    ┆ 7.50531       ┆ 30.779175     │\n",
      "│ XAUAUD ┆ 297135 ┆ 297135         ┆ 66.738076     ┆ 128.748366    ┆ 2.692074      ┆ 11.472395     │\n",
      "└────────┴────────┴────────────────┴───────────────┴───────────────┴───────────────┴───────────────┘\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Celda 03 v2.0.1] BNBUSD | asset_class=crypto\n",
      "  base_cost_bps=8.00 | stress_cost_bps=16.00\n",
      "  slippage_method=spread_bps_proxy | spread_coverage_pct=100.00%\n",
      "  spread_med_bps=34.42163055263928 | spread_p95_bps=139.05627143784184\n",
      "  vol_med_absret_bps=7.744124732045887 | vol_p95_absret_bps=37.043054427294834\n",
      "  slippage_base_bps=17.211 | slippage_stress_bps=104.292\n",
      "  gap_base_bps=0.00 | gap_stress_bps=0.00\n",
      "  >>> TOTAL_BASE_BPS=25.211 | TOTAL_STRESS_BPS=120.292\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Celda 03 v2.0.1] BTCUSD | asset_class=crypto\n",
      "  base_cost_bps=8.00 | stress_cost_bps=16.00\n",
      "  slippage_method=spread_bps_proxy | spread_coverage_pct=100.00%\n",
      "  spread_med_bps=365.9641912581016 | spread_p95_bps=523.409489414043\n",
      "  vol_med_absret_bps=6.137622114816832 | vol_p95_absret_bps=30.53717858405358\n",
      "  slippage_base_bps=182.982 | slippage_stress_bps=392.557\n",
      "  gap_base_bps=0.00 | gap_stress_bps=0.00\n",
      "  >>> TOTAL_BASE_BPS=190.982 | TOTAL_STRESS_BPS=408.557\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Celda 03 v2.0.1] LVMH | asset_class=equity\n",
      "  base_cost_bps=12.00 | stress_cost_bps=25.00\n",
      "  slippage_method=spread_bps_proxy | spread_coverage_pct=100.00%\n",
      "  spread_med_bps=187.295595672031 | spread_p95_bps=582.9401876254\n",
      "  vol_med_absret_bps=7.505310007251964 | vol_p95_absret_bps=30.77917481032366\n",
      "  slippage_base_bps=93.648 | slippage_stress_bps=437.205\n",
      "  gap_base_bps=2.00 | gap_stress_bps=6.00\n",
      "  >>> TOTAL_BASE_BPS=107.648 | TOTAL_STRESS_BPS=468.205\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Celda 03 v2.0.1] XAUAUD | asset_class=fx_metal\n",
      "  base_cost_bps=4.00 | stress_cost_bps=8.00\n",
      "  slippage_method=spread_bps_proxy | spread_coverage_pct=100.00%\n",
      "  spread_med_bps=66.73807640842368 | spread_p95_bps=128.74836561102543\n",
      "  vol_med_absret_bps=2.69207432418761 | vol_p95_absret_bps=11.472394916185458\n",
      "  slippage_base_bps=33.369 | slippage_stress_bps=96.561\n",
      "  gap_base_bps=1.00 | gap_stress_bps=3.00\n",
      "  >>> TOTAL_BASE_BPS=38.369 | TOTAL_STRESS_BPS=107.561\n",
      "\n",
      "[Celda 03 v2.0.1] OK — cost model guardado:\n",
      "  - C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\cost_model_snapshot_v2.json\n",
      "  - C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\cost_model_v2.parquet\n",
      "\n",
      "--- Cost Model Table (v2.0.1) ---\n",
      "shape: (4, 16)\n",
      "┌────────┬────────────┬────────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ symbol ┆ asset_clas ┆ base_cost_ ┆ stress_co ┆ … ┆ spread_p9 ┆ vol_med_a ┆ vol_p95_a ┆ spread_co │\n",
      "│ ---    ┆ s          ┆ bps        ┆ st_bps    ┆   ┆ 5_bps     ┆ bsret_bps ┆ bsret_bps ┆ verage_pc │\n",
      "│ str    ┆ ---        ┆ ---        ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ t         │\n",
      "│        ┆ str        ┆ f64        ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ ---       │\n",
      "│        ┆            ┆            ┆           ┆   ┆           ┆           ┆           ┆ f64       │\n",
      "╞════════╪════════════╪════════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ BNBUSD ┆ crypto     ┆ 8.0        ┆ 16.0      ┆ … ┆ 139.05627 ┆ 7.744125  ┆ 37.043054 ┆ 100.0     │\n",
      "│        ┆            ┆            ┆           ┆   ┆ 1         ┆           ┆           ┆           │\n",
      "│ BTCUSD ┆ crypto     ┆ 8.0        ┆ 16.0      ┆ … ┆ 523.40948 ┆ 6.137622  ┆ 30.537179 ┆ 100.0     │\n",
      "│        ┆            ┆            ┆           ┆   ┆ 9         ┆           ┆           ┆           │\n",
      "│ LVMH   ┆ equity     ┆ 12.0       ┆ 25.0      ┆ … ┆ 582.94018 ┆ 7.50531   ┆ 30.779175 ┆ 100.0     │\n",
      "│        ┆            ┆            ┆           ┆   ┆ 8         ┆           ┆           ┆           │\n",
      "│ XAUAUD ┆ fx_metal   ┆ 4.0        ┆ 8.0       ┆ … ┆ 128.74836 ┆ 2.692074  ┆ 11.472395 ┆ 100.0     │\n",
      "│        ┆            ┆            ┆           ┆   ┆ 6         ┆           ┆           ┆           │\n",
      "└────────┴────────────┴────────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘\n",
      "\n",
      "[Celda 03 v2.0.1] OK — costos listos para net-of-costs en baseline/alpha/engine.\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# Celda 03 v2.0.1 — Cost Model (base/stress + slippage proxy + gap proxy) [RETURNS POR SÍMBOLO OK]\n",
    "# Propósito:\n",
    "#   - Costos reproducibles net-of-costs:\n",
    "#       * base_cost_bps / stress_cost_bps (instrument_specs)\n",
    "#       * slippage proxy: spread (si existe) o proxy por volatilidad (abs-return) POR SÍMBOLO\n",
    "#       * gap proxy (equity/fx) como add-on conservador\n",
    "#   - Prints explícitos por símbolo (componentes y totales).\n",
    "#\n",
    "# Inputs:\n",
    "#   - RUN (Celda 00)\n",
    "#   - instrument_specs_v2.parquet (Celda 01)\n",
    "#   - ohlcv_clean_m5.parquet (Celda 02)\n",
    "#   - data_qa_report.json (Celda 02) [preferible v2.0.4]\n",
    "#\n",
    "# Outputs:\n",
    "#   - cost_model_snapshot.json\n",
    "#   - cost_model_v2.parquet\n",
    "#\n",
    "# ENV:\n",
    "#   - TREND_M5_FORCE_REBUILD_COST_MODEL=1 => fuerza rebuild\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# -----------------------------\n",
    "# Preflight\n",
    "# -----------------------------\n",
    "if \"RUN\" not in globals():\n",
    "    raise RuntimeError(\"[Celda 03 v2.0.1] ERROR: No existe RUN en memoria. Ejecuta primero Celda 00 v2.0.\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "\n",
    "INSTRUMENT_SPECS_PATH = RUN_DIR / \"instrument_specs_v2.parquet\"\n",
    "OHLCV_CLEAN_PATH = ARTIFACTS[\"ohlcv_clean\"]\n",
    "QA_REPORT_PATH = ARTIFACTS[\"data_qa_report\"]\n",
    "\n",
    "if not INSTRUMENT_SPECS_PATH.exists():\n",
    "    raise RuntimeError(\"[Celda 03 v2.0.1] ERROR: Falta instrument_specs_v2.parquet. Ejecuta Celda 01 v2.0.\")\n",
    "if not OHLCV_CLEAN_PATH.exists():\n",
    "    raise RuntimeError(\"[Celda 03 v2.0.1] ERROR: Falta ohlcv_clean_m5.parquet. Ejecuta Celda 02.\")\n",
    "\n",
    "OUT_COST_SNAPSHOT = ARTIFACTS[\"cost_model_snapshot\"]\n",
    "OUT_COST_TABLE = RUN_DIR / \"cost_model_v2.parquet\"\n",
    "\n",
    "FORCE_REBUILD_COST = os.getenv(\"TREND_M5_FORCE_REBUILD_COST_MODEL\", \"\").strip().lower() in (\"1\", \"true\", \"yes\")\n",
    "\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "# -----------------------------\n",
    "# Cache\n",
    "# -----------------------------\n",
    "if OUT_COST_SNAPSHOT.exists() and OUT_COST_TABLE.exists() and (not FORCE_REBUILD_COST):\n",
    "    print(f\"[Celda 03 v2.0.1] Cache detectado. Usando cost model existente:\\n  - {OUT_COST_SNAPSHOT}\\n  - {OUT_COST_TABLE}\")\n",
    "    snap = json.loads(OUT_COST_SNAPSHOT.read_text(encoding=\"utf-8\"))\n",
    "    print(\"\\n--- Cost Model Snapshot (resumen) ---\")\n",
    "    for r in snap.get(\"per_symbol\", []):\n",
    "        print(f\"  {r['symbol']}: total_base_bps={r['total_base_bps']:.2f}, total_stress_bps={r['total_stress_bps']:.2f} \"\n",
    "              f\"(slip_base={r['slippage_base_bps']:.2f}, slip_stress={r['slippage_stress_bps']:.2f}, gap_base={r['gap_base_bps']:.2f}, gap_stress={r['gap_stress_bps']:.2f})\")\n",
    "    print(\"\\n[Celda 03 v2.0.1] OK — cost model listo.\")\n",
    "else:\n",
    "    specs = pl.read_parquet(INSTRUMENT_SPECS_PATH)\n",
    "\n",
    "    # QA flag (no bloquea, solo imprime)\n",
    "    qa_session_aware = False\n",
    "    if QA_REPORT_PATH.exists():\n",
    "        try:\n",
    "            qa = json.loads(QA_REPORT_PATH.read_text(encoding=\"utf-8\"))\n",
    "            qa_session_aware = bool(qa.get(\"cell\", \"\").startswith(\"02 v2.\"))\n",
    "        except Exception:\n",
    "            qa_session_aware = False\n",
    "    print(f\"[Celda 03 v2.0.1] QA detected: {qa_session_aware} | QA path: {QA_REPORT_PATH}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Microstructure proxies (POR SÍMBOLO)\n",
    "    # -----------------------------\n",
    "    # Nota institucional:\n",
    "    # - spread_bps proxy depende de que spread exista.\n",
    "    # - abs_ret_bps proxy usa retornos close-to-close POR SÍMBOLO.\n",
    "    # - Si el archivo no estuviera ordenado por symbol/time, esto debería fallar en QA previo. Aquí imprimimos sanity.\n",
    "    sanity = (\n",
    "        pl.scan_parquet(OHLCV_CLEAN_PATH)\n",
    "        .select([\"symbol\", \"time_utc\"])\n",
    "        .group_by(\"symbol\")\n",
    "        .agg([\n",
    "            (pl.col(\"time_utc\").diff().dt.total_seconds().min()).alias(\"min_dt_sec\"),\n",
    "            (pl.col(\"time_utc\").diff().dt.total_seconds().max()).alias(\"max_dt_sec\"),\n",
    "            pl.len().alias(\"n_rows\"),\n",
    "        ])\n",
    "        .collect()\n",
    "        .sort(\"symbol\")\n",
    "    )\n",
    "    print(\"\\n--- Sanity order/spacing (time_utc diff stats) ---\")\n",
    "    print(sanity)\n",
    "    bad_order = sanity.filter(pl.col(\"min_dt_sec\") < 0)\n",
    "    if bad_order.height > 0:\n",
    "        raise RuntimeError(f\"[Celda 03 v2.0.1] ERROR: time_utc no está ordenado (min_dt_sec<0) en: {bad_order.select('symbol').to_series().to_list()}\")\n",
    "\n",
    "    df_stats = (\n",
    "        pl.scan_parquet(OHLCV_CLEAN_PATH)\n",
    "        .select([\"symbol\", \"time_utc\", \"close\", \"spread\"])\n",
    "        .with_columns([\n",
    "            pl.col(\"close\").shift(1).over(\"symbol\").alias(\"close_prev\"),\n",
    "        ])\n",
    "        .with_columns([\n",
    "            pl.when(pl.col(\"close_prev\").is_not_null() & (pl.col(\"close_prev\") > 0))\n",
    "              .then((pl.col(\"close\") / pl.col(\"close_prev\") - 1.0).abs())\n",
    "              .otherwise(None)\n",
    "              .alias(\"abs_ret\"),\n",
    "        ])\n",
    "        .with_columns([\n",
    "            (pl.col(\"abs_ret\") * 10_000).alias(\"abs_ret_bps\"),\n",
    "            pl.when(pl.col(\"spread\").is_not_null() & (pl.col(\"close\") > 0))\n",
    "              .then((pl.col(\"spread\") / pl.col(\"close\")) * 10_000)\n",
    "              .otherwise(None)\n",
    "              .alias(\"spread_bps\"),\n",
    "        ])\n",
    "        .group_by(\"symbol\")\n",
    "        .agg([\n",
    "            pl.len().alias(\"n_rows\"),\n",
    "            pl.col(\"spread_bps\").drop_nulls().len().alias(\"n_spread_nonnull\"),\n",
    "            pl.col(\"spread_bps\").median().alias(\"spread_med_bps\"),\n",
    "            pl.col(\"spread_bps\").quantile(0.95, \"nearest\").alias(\"spread_p95_bps\"),\n",
    "            pl.col(\"abs_ret_bps\").median().alias(\"vol_med_absret_bps\"),\n",
    "            pl.col(\"abs_ret_bps\").quantile(0.95, \"nearest\").alias(\"vol_p95_absret_bps\"),\n",
    "        ])\n",
    "        .collect()\n",
    "        .sort(\"symbol\")\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Microstructure proxies (from OHLCV clean) ---\")\n",
    "    print(df_stats)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Construir cost model por símbolo (con prints explícitos)\n",
    "    # -----------------------------\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "\n",
    "    for r in specs.to_dicts():\n",
    "        sym = r[\"symbol\"]\n",
    "        asset_class = r[\"asset_class\"]\n",
    "        base_bps = float(r[\"base_cost_bps\"])\n",
    "        stress_bps = float(r[\"stress_cost_bps\"])\n",
    "\n",
    "        s = df_stats.filter(pl.col(\"symbol\") == sym)\n",
    "        if s.height != 1:\n",
    "            raise RuntimeError(f\"[Celda 03 v2.0.1] ERROR: no encuentro stats para {sym} en OHLCV clean.\")\n",
    "        srow = s.row(0, named=True)\n",
    "\n",
    "        n_spread_nonnull = int(srow[\"n_spread_nonnull\"])\n",
    "        n_rows = int(srow[\"n_rows\"])\n",
    "        spread_med = srow[\"spread_med_bps\"]\n",
    "        spread_p95 = srow[\"spread_p95_bps\"]\n",
    "        vol_med = srow[\"vol_med_absret_bps\"]\n",
    "        vol_p95 = srow[\"vol_p95_absret_bps\"]\n",
    "\n",
    "        spread_usable = (n_spread_nonnull / max(n_rows, 1)) >= 0.10\n",
    "\n",
    "        if spread_usable and (spread_med is not None):\n",
    "            slip_base = float(max(spread_med, 0.0)) * 0.50\n",
    "            slip_stress = float(max(spread_p95 or spread_med, 0.0)) * 0.75\n",
    "            slip_method = \"spread_bps_proxy\"\n",
    "        else:\n",
    "            slip_base = float(max(vol_med or 0.0, 0.0)) * 0.10\n",
    "            slip_stress = float(max(vol_p95 or vol_med or 0.0, 0.0)) * 0.15\n",
    "            slip_method = \"vol_absret_bps_proxy\"\n",
    "\n",
    "        if asset_class == \"equity\":\n",
    "            gap_base = 2.0\n",
    "            gap_stress = 6.0\n",
    "        elif asset_class == \"fx_metal\":\n",
    "            gap_base = 1.0\n",
    "            gap_stress = 3.0\n",
    "        else:\n",
    "            gap_base = 0.0\n",
    "            gap_stress = 0.0\n",
    "\n",
    "        total_base = base_bps + slip_base + gap_base\n",
    "        total_stress = stress_bps + slip_stress + gap_stress\n",
    "\n",
    "        # Print explícito por símbolo\n",
    "        print(\"\\n\" + \"-\" * 100)\n",
    "        print(f\"[Celda 03 v2.0.1] {sym} | asset_class={asset_class}\")\n",
    "        print(f\"  base_cost_bps={base_bps:.2f} | stress_cost_bps={stress_bps:.2f}\")\n",
    "        print(f\"  slippage_method={slip_method} | spread_coverage_pct={(n_spread_nonnull/max(n_rows,1))*100.0:.2f}%\")\n",
    "        print(f\"  spread_med_bps={spread_med} | spread_p95_bps={spread_p95}\")\n",
    "        print(f\"  vol_med_absret_bps={vol_med} | vol_p95_absret_bps={vol_p95}\")\n",
    "        print(f\"  slippage_base_bps={slip_base:.3f} | slippage_stress_bps={slip_stress:.3f}\")\n",
    "        print(f\"  gap_base_bps={gap_base:.2f} | gap_stress_bps={gap_stress:.2f}\")\n",
    "        print(f\"  >>> TOTAL_BASE_BPS={total_base:.3f} | TOTAL_STRESS_BPS={total_stress:.3f}\")\n",
    "\n",
    "        rows.append({\n",
    "            \"symbol\": sym,\n",
    "            \"asset_class\": asset_class,\n",
    "            \"base_cost_bps\": base_bps,\n",
    "            \"stress_cost_bps\": stress_bps,\n",
    "            \"slippage_base_bps\": slip_base,\n",
    "            \"slippage_stress_bps\": slip_stress,\n",
    "            \"gap_base_bps\": gap_base,\n",
    "            \"gap_stress_bps\": gap_stress,\n",
    "            \"total_base_bps\": total_base,\n",
    "            \"total_stress_bps\": total_stress,\n",
    "            \"slippage_method\": slip_method,\n",
    "            \"spread_med_bps\": float(spread_med) if spread_med is not None else None,\n",
    "            \"spread_p95_bps\": float(spread_p95) if spread_p95 is not None else None,\n",
    "            \"vol_med_absret_bps\": float(vol_med) if vol_med is not None else None,\n",
    "            \"vol_p95_absret_bps\": float(vol_p95) if vol_p95 is not None else None,\n",
    "            \"spread_coverage_pct\": float(n_spread_nonnull / max(n_rows, 1) * 100.0),\n",
    "        })\n",
    "\n",
    "    cost_table = pl.DataFrame(rows).sort(\"symbol\")\n",
    "\n",
    "    # Gates\n",
    "    bad = cost_table.filter(\n",
    "        (pl.col(\"total_base_bps\") <= 0) |\n",
    "        (pl.col(\"total_stress_bps\") <= 0) |\n",
    "        (pl.col(\"total_stress_bps\") < pl.col(\"total_base_bps\"))\n",
    "    )\n",
    "    if bad.height > 0:\n",
    "        raise RuntimeError(f\"[Celda 03 v2.0.1] ERROR: cost model inválido:\\n{bad}\")\n",
    "\n",
    "    OUT_COST_TABLE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    cost_table.write_parquet(OUT_COST_TABLE)\n",
    "\n",
    "    snapshot = {\n",
    "        \"cell\": \"03 v2.0.1\",\n",
    "        \"created_utc\": _now_utc_iso(),\n",
    "        \"qa_detected\": qa_session_aware,\n",
    "        \"notes\": [\n",
    "            \"total_*_bps = base/stress (spec) + slippage proxy + gap proxy.\",\n",
    "            \"slippage proxy: usa spread si existe; caso contrario, proxy por abs-return POR SÍMBOLO.\",\n",
    "            \"gap proxy es add-on conservador; se refina más adelante si se requiere.\",\n",
    "        ],\n",
    "        \"per_symbol\": cost_table.to_dicts(),\n",
    "    }\n",
    "\n",
    "    OUT_COST_SNAPSHOT.parent.mkdir(parents=True, exist_ok=True)\n",
    "    OUT_COST_SNAPSHOT.write_text(json.dumps(snapshot, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"\\n[Celda 03 v2.0.1] OK — cost model guardado:\")\n",
    "    print(f\"  - {OUT_COST_SNAPSHOT}\")\n",
    "    print(f\"  - {OUT_COST_TABLE}\")\n",
    "\n",
    "    print(\"\\n--- Cost Model Table (v2.0.1) ---\")\n",
    "    print(cost_table)\n",
    "\n",
    "    warn = cost_table.filter(pl.col(\"slippage_method\") == \"vol_absret_bps_proxy\")\n",
    "    if warn.height > 0:\n",
    "        print(\"\\n[Celda 03 v2.0.1] AVISO: spread no utilizable; slippage estimado por proxy de volatilidad:\")\n",
    "        print(warn.select([\"symbol\", \"slippage_method\", \"spread_coverage_pct\", \"vol_med_absret_bps\", \"slippage_base_bps\", \"slippage_stress_bps\", \"total_base_bps\", \"total_stress_bps\"]))\n",
    "\n",
    "    print(\"\\n[Celda 03 v2.0.1] OK — costos listos para net-of-costs en baseline/alpha/engine.\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06c249f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Celda 04 v2.0.1] Universe: ['BNBUSD', 'BTCUSD', 'LVMH', 'XAUAUD']\n",
      "\n",
      "--- Data ranges (ohlcv_clean) ---\n",
      "shape: (4, 4)\n",
      "┌────────┬─────────────────────┬─────────────────────┬────────┐\n",
      "│ symbol ┆ start_utc           ┆ end_utc             ┆ n_rows │\n",
      "│ ---    ┆ ---                 ┆ ---                 ┆ ---    │\n",
      "│ str    ┆ datetime[ms]        ┆ datetime[ms]        ┆ u32    │\n",
      "╞════════╪═════════════════════╪═════════════════════╪════════╡\n",
      "│ BNBUSD ┆ 2021-11-19 00:00:00 ┆ 2026-02-16 23:50:00 ┆ 430323 │\n",
      "│ BTCUSD ┆ 2021-11-19 00:00:00 ┆ 2026-02-16 23:50:00 ┆ 358028 │\n",
      "│ LVMH   ┆ 2021-11-19 10:00:00 ┆ 2026-02-16 18:25:00 ┆ 109289 │\n",
      "│ XAUAUD ┆ 2021-11-19 01:05:00 ┆ 2026-02-16 21:25:00 ┆ 297135 │\n",
      "└────────┴─────────────────────┴─────────────────────┴────────┘\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Celda 04 v2.0.1] BNBUSD | asset_class=crypto\n",
      "  data: start=2021-11-19 00:00:00  end=2026-02-16 23:50:00  n_rows=430,323\n",
      "  chosen_cfg: IS=18m  OOS=3m  STEP=3m\n",
      "  embargo_days=7.00 | folds_possible=10 | mode=expanding\n",
      "  fold=01 | IS bars=151,744 days=546 | OOS bars=25,623 days=92\n",
      "  fold=02 | IS bars=177,367 days=638 | OOS bars=25,628 days=92\n",
      "  fold=03 | IS bars=202,995 days=730 | OOS bars=25,635 days=92\n",
      "  fold=04 | IS bars=228,630 days=822 | OOS bars=25,049 days=90\n",
      "  fold=05 | IS bars=253,681 days=912 | OOS bars=25,619 days=92\n",
      "  fold=06 | IS bars=279,298 days=1004 | OOS bars=25,632 days=92\n",
      "  fold=07 | IS bars=304,930 days=1096 | OOS bars=25,625 days=92\n",
      "  fold=08 | IS bars=330,555 days=1188 | OOS bars=24,793 days=89\n",
      "  fold=09 | IS bars=355,374 days=1277 | OOS bars=25,276 days=90\n",
      "  fold=10 | IS bars=380,733 days=1367 | OOS bars=24,906 days=90\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Celda 04 v2.0.1] BTCUSD | asset_class=crypto\n",
      "  data: start=2021-11-19 00:00:00  end=2026-02-16 23:50:00  n_rows=358,028\n",
      "  chosen_cfg: IS=18m  OOS=3m  STEP=3m\n",
      "  embargo_days=7.00 | folds_possible=10 | mode=expanding\n",
      "  fold=01 | IS bars=80,036 days=544 | OOS bars=25,865 days=92\n",
      "  fold=02 | IS bars=105,913 days=636 | OOS bars=25,696 days=92\n",
      "  fold=03 | IS bars=131,537 days=728 | OOS bars=25,700 days=92\n",
      "  fold=04 | IS bars=157,297 days=820 | OOS bars=25,164 days=90\n",
      "  fold=05 | IS bars=182,476 days=910 | OOS bars=25,091 days=92\n",
      "  fold=06 | IS bars=207,587 days=1002 | OOS bars=25,586 days=92\n",
      "  fold=07 | IS bars=233,138 days=1094 | OOS bars=25,772 days=92\n",
      "  fold=08 | IS bars=258,850 days=1186 | OOS bars=24,559 days=89\n",
      "  fold=09 | IS bars=283,421 days=1275 | OOS bars=24,731 days=90\n",
      "  fold=10 | IS bars=308,223 days=1365 | OOS bars=24,904 days=90\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Celda 04 v2.0.1] LVMH | asset_class=equity\n",
      "  data: start=2021-11-19 10:00:00  end=2026-02-16 18:25:00  n_rows=109,289\n",
      "  chosen_cfg: IS=18m  OOS=3m  STEP=3m\n",
      "  embargo_days=7.00 | folds_possible=10 | mode=expanding\n",
      "  fold=01 | IS bars=38,915 days=384 | OOS bars=6,732 days=66\n",
      "  fold=02 | IS bars=45,647 days=450 | OOS bars=6,559 days=65\n",
      "  fold=03 | IS bars=52,206 days=515 | OOS bars=6,283 days=62\n",
      "  fold=04 | IS bars=58,489 days=577 | OOS bars=6,267 days=62\n",
      "  fold=05 | IS bars=64,761 days=639 | OOS bars=6,452 days=64\n",
      "  fold=06 | IS bars=71,213 days=703 | OOS bars=6,656 days=66\n",
      "  fold=07 | IS bars=77,869 days=769 | OOS bars=6,070 days=61\n",
      "  fold=08 | IS bars=83,939 days=830 | OOS bars=6,060 days=60\n",
      "  fold=09 | IS bars=89,999 days=890 | OOS bars=6,666 days=66\n",
      "  fold=10 | IS bars=96,665 days=956 | OOS bars=6,666 days=66\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Celda 04 v2.0.1] XAUAUD | asset_class=fx_metal\n",
      "  data: start=2021-11-19 01:05:00  end=2026-02-16 21:25:00  n_rows=297,135\n",
      "  chosen_cfg: IS=18m  OOS=3m  STEP=3m\n",
      "  embargo_days=7.00 | folds_possible=10 | mode=expanding\n",
      "  fold=01 | IS bars=104,611 days=385 | OOS bars=17,919 days=66\n",
      "  fold=02 | IS bars=122,530 days=451 | OOS bars=17,652 days=65\n",
      "  fold=03 | IS bars=140,247 days=516 | OOS bars=17,124 days=63\n",
      "  fold=04 | IS bars=157,338 days=579 | OOS bars=17,472 days=64\n",
      "  fold=05 | IS bars=174,778 days=643 | OOS bars=17,661 days=65\n",
      "  fold=06 | IS bars=192,439 days=708 | OOS bars=17,978 days=66\n",
      "  fold=07 | IS bars=210,417 days=774 | OOS bars=17,324 days=64\n",
      "  fold=08 | IS bars=227,741 days=838 | OOS bars=16,925 days=62\n",
      "  fold=09 | IS bars=244,666 days=900 | OOS bars=17,916 days=66\n",
      "  fold=10 | IS bars=262,582 days=966 | OOS bars=17,989 days=66\n",
      "\n",
      "--- Folds por símbolo ---\n",
      "shape: (4, 2)\n",
      "┌────────┬─────────┐\n",
      "│ symbol ┆ n_folds │\n",
      "│ ---    ┆ ---     │\n",
      "│ str    ┆ u32     │\n",
      "╞════════╪═════════╡\n",
      "│ BNBUSD ┆ 10      │\n",
      "│ BTCUSD ┆ 10      │\n",
      "│ LVMH   ┆ 10      │\n",
      "│ XAUAUD ┆ 10      │\n",
      "└────────┴─────────┘\n",
      "\n",
      "[Celda 04 v2.0.1] OK — WFO folds guardados:\n",
      "  - C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\wfo_folds_v2.parquet\n",
      "  - C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\wfo_folds_snapshot_v2.json\n",
      "\n",
      "--- WFO Folds (preview) ---\n",
      "shape: (12, 18)\n",
      "┌────────┬─────────┬────────────┬───────────┬───┬────────────┬────────────┬────────────┬───────────┐\n",
      "│ symbol ┆ fold_id ┆ asset_clas ┆ wfo_mode  ┆ … ┆ cfg_is_mon ┆ cfg_oos_mo ┆ cfg_step_m ┆ embargo_b │\n",
      "│ ---    ┆ ---     ┆ s          ┆ ---       ┆   ┆ ths        ┆ nths       ┆ onths      ┆ ars       │\n",
      "│ str    ┆ i64     ┆ ---        ┆ str       ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---       │\n",
      "│        ┆         ┆ str        ┆           ┆   ┆ i64        ┆ i64        ┆ i64        ┆ i64       │\n",
      "╞════════╪═════════╪════════════╪═══════════╪═══╪════════════╪════════════╪════════════╪═══════════╡\n",
      "│ BNBUSD ┆ 1       ┆ crypto     ┆ expanding ┆ … ┆ 18         ┆ 3          ┆ 3          ┆ 2016      │\n",
      "│ BNBUSD ┆ 2       ┆ crypto     ┆ expanding ┆ … ┆ 18         ┆ 3          ┆ 3          ┆ 2016      │\n",
      "│ BNBUSD ┆ 3       ┆ crypto     ┆ expanding ┆ … ┆ 18         ┆ 3          ┆ 3          ┆ 2016      │\n",
      "│ BNBUSD ┆ 4       ┆ crypto     ┆ expanding ┆ … ┆ 18         ┆ 3          ┆ 3          ┆ 2016      │\n",
      "│ BNBUSD ┆ 5       ┆ crypto     ┆ expanding ┆ … ┆ 18         ┆ 3          ┆ 3          ┆ 2016      │\n",
      "│ …      ┆ …       ┆ …          ┆ …         ┆ … ┆ …          ┆ …          ┆ …          ┆ …         │\n",
      "│ BNBUSD ┆ 8       ┆ crypto     ┆ expanding ┆ … ┆ 18         ┆ 3          ┆ 3          ┆ 2016      │\n",
      "│ BNBUSD ┆ 9       ┆ crypto     ┆ expanding ┆ … ┆ 18         ┆ 3          ┆ 3          ┆ 2016      │\n",
      "│ BNBUSD ┆ 10      ┆ crypto     ┆ expanding ┆ … ┆ 18         ┆ 3          ┆ 3          ┆ 2016      │\n",
      "│ BTCUSD ┆ 1       ┆ crypto     ┆ expanding ┆ … ┆ 18         ┆ 3          ┆ 3          ┆ 2016      │\n",
      "│ BTCUSD ┆ 2       ┆ crypto     ┆ expanding ┆ … ┆ 18         ┆ 3          ┆ 3          ┆ 2016      │\n",
      "└────────┴─────────┴────────────┴───────────┴───┴────────────┴────────────┴────────────┴───────────┘\n",
      "\n",
      "[Celda 04 v2.0.1] OK — Se permite avanzar a Celda 05.\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# Celda 04 v2.0.1 — WFO Builder (≥6 folds + embargo/purge) [SESSION-AWARE GATES]\n",
    "# Fix vs v2.0:\n",
    "#   - Gate de tamaño ahora es por asset_class y además por \"trading days\" (más defendible).\n",
    "#   - Evita bloquear equities session-only (LVMH) con thresholds 24/7.\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import json\n",
    "import calendar\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Tuple, Optional\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# -----------------------------\n",
    "# Preflight\n",
    "# -----------------------------\n",
    "if \"RUN\" not in globals():\n",
    "    raise RuntimeError(\"[Celda 04 v2.0.1] ERROR: No existe RUN en memoria. Ejecuta primero Celda 00 v2.0.\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "\n",
    "INSTRUMENT_SPECS_PATH = RUN_DIR / \"instrument_specs_v2.parquet\"\n",
    "OHLCV_CLEAN_PATH = ARTIFACTS[\"ohlcv_clean\"]\n",
    "QA_REPORT_PATH = ARTIFACTS[\"data_qa_report\"]\n",
    "\n",
    "if not INSTRUMENT_SPECS_PATH.exists():\n",
    "    raise RuntimeError(\"[Celda 04 v2.0.1] ERROR: Falta instrument_specs_v2.parquet. Ejecuta Celda 01 v2.0.\")\n",
    "if not OHLCV_CLEAN_PATH.exists():\n",
    "    raise RuntimeError(\"[Celda 04 v2.0.1] ERROR: Falta ohlcv_clean_m5.parquet. Ejecuta Celda 02.\")\n",
    "\n",
    "OUT_WFO_FOLDS = ARTIFACTS[\"wfo_folds\"]\n",
    "OUT_WFO_SNAPSHOT = ARTIFACTS[\"wfo_folds_snapshot\"]\n",
    "\n",
    "FORCE_REBUILD = os.getenv(\"TREND_M5_FORCE_REBUILD_WFO\", \"1\").strip().lower() in (\"1\", \"true\", \"yes\")  # default=1 aquí\n",
    "WFO_MODE = os.getenv(\"TREND_M5_WFO_MODE\", \"expanding\").strip().lower()\n",
    "if WFO_MODE not in (\"expanding\", \"rolling\"):\n",
    "    raise ValueError(\"[Celda 04 v2.0.1] ERROR: TREND_M5_WFO_MODE debe ser 'expanding' o 'rolling'.\")\n",
    "\n",
    "MIN_FOLDS = int(os.getenv(\"TREND_M5_MIN_FOLDS\", \"6\"))\n",
    "MAX_HOLD_BARS = int(os.getenv(\"TREND_M5_MAX_HOLD_BARS\", \"2016\"))  # ~1 semana\n",
    "EXPECTED_BAR_SECONDS = 300  # M5\n",
    "EMBARGO = timedelta(seconds=MAX_HOLD_BARS * EXPECTED_BAR_SECONDS)\n",
    "\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "def add_months(dt: datetime, months: int) -> datetime:\n",
    "    y = dt.year\n",
    "    m = dt.month + months\n",
    "    while m > 12:\n",
    "        y += 1\n",
    "        m -= 12\n",
    "    while m < 1:\n",
    "        y -= 1\n",
    "        m += 12\n",
    "    last_day = calendar.monthrange(y, m)[1]\n",
    "    d = min(dt.day, last_day)\n",
    "    return dt.replace(year=y, month=m, day=d)\n",
    "\n",
    "@dataclass\n",
    "class WFOConfig:\n",
    "    is_months: int\n",
    "    oos_months: int\n",
    "    step_months: int\n",
    "\n",
    "CANDIDATE_CONFIGS_BY_ASSET = {\n",
    "    \"crypto\": [\n",
    "        WFOConfig(18, 3, 3),\n",
    "        WFOConfig(12, 3, 3),\n",
    "        WFOConfig(12, 2, 2),\n",
    "    ],\n",
    "    \"equity\": [\n",
    "        WFOConfig(18, 3, 3),  # se mantiene; el gate ahora es session-aware\n",
    "        WFOConfig(12, 3, 3),\n",
    "        WFOConfig(12, 2, 2),\n",
    "    ],\n",
    "    \"fx_metal\": [\n",
    "        WFOConfig(18, 3, 3),\n",
    "        WFOConfig(12, 3, 3),\n",
    "        WFOConfig(12, 2, 2),\n",
    "    ],\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Gates session-aware (por asset_class)\n",
    "# -----------------------------\n",
    "# Días son el gate principal (defendible). Barras son sanity.\n",
    "GATES = {\n",
    "    \"crypto\":   {\"min_is_days\": 365, \"min_oos_days\": 60, \"min_is_bars\": 70_000, \"min_oos_bars\": 20_000},\n",
    "    \"fx_metal\": {\"min_is_days\": 365, \"min_oos_days\": 60, \"min_is_bars\": 80_000, \"min_oos_bars\": 12_000},\n",
    "    \"equity\":   {\"min_is_days\": 250, \"min_oos_days\": 60, \"min_is_bars\": 35_000, \"min_oos_bars\": 6_000},\n",
    "    \"unknown\":  {\"min_is_days\": 250, \"min_oos_days\": 60, \"min_is_bars\": 35_000, \"min_oos_bars\": 6_000},\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Construcción (sin cache por defecto)\n",
    "# -----------------------------\n",
    "specs = pl.read_parquet(INSTRUMENT_SPECS_PATH)\n",
    "universe = specs.select(\"symbol\").to_series().to_list()\n",
    "spec_map = {r[\"symbol\"]: r for r in specs.to_dicts()}\n",
    "\n",
    "df_ranges = (\n",
    "    pl.scan_parquet(OHLCV_CLEAN_PATH)\n",
    "    .group_by(\"symbol\")\n",
    "    .agg([\n",
    "        pl.min(\"time_utc\").alias(\"start_utc\"),\n",
    "        pl.max(\"time_utc\").alias(\"end_utc\"),\n",
    "        pl.len().alias(\"n_rows\"),\n",
    "    ])\n",
    "    .collect()\n",
    "    .sort(\"symbol\")\n",
    ")\n",
    "\n",
    "print(\"[Celda 04 v2.0.1] Universe:\", universe)\n",
    "print(\"\\n--- Data ranges (ohlcv_clean) ---\")\n",
    "print(df_ranges)\n",
    "\n",
    "qa_cell = None\n",
    "if QA_REPORT_PATH.exists():\n",
    "    try:\n",
    "        qa_cell = json.loads(QA_REPORT_PATH.read_text(encoding=\"utf-8\")).get(\"cell\")\n",
    "    except Exception:\n",
    "        qa_cell = None\n",
    "\n",
    "# Precompute daily calendar por símbolo (más eficiente que re-scan por fold)\n",
    "daily = (\n",
    "    pl.scan_parquet(OHLCV_CLEAN_PATH)\n",
    "    .select([\n",
    "        pl.col(\"symbol\"),\n",
    "        pl.col(\"time_utc\").dt.truncate(\"1d\").alias(\"day\"),\n",
    "    ])\n",
    "    .unique()\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "def count_bars(sym: str, t0: datetime, t1: datetime) -> int:\n",
    "    return int(\n",
    "        pl.scan_parquet(OHLCV_CLEAN_PATH)\n",
    "        .filter((pl.col(\"symbol\") == sym) & (pl.col(\"time_utc\") >= t0) & (pl.col(\"time_utc\") < t1))\n",
    "        .select(pl.len())\n",
    "        .collect()\n",
    "        .item()\n",
    "    )\n",
    "\n",
    "def count_days(sym: str, t0: datetime, t1: datetime) -> int:\n",
    "    return int(\n",
    "        daily.filter((pl.col(\"symbol\") == sym) & (pl.col(\"day\") >= t0.replace(hour=0, minute=0, second=0, microsecond=0))\n",
    "                     & (pl.col(\"day\") <  t1.replace(hour=0, minute=0, second=0, microsecond=0)))\n",
    "        .select(pl.len())\n",
    "        .item()\n",
    "    )\n",
    "\n",
    "def possible_fold_count(start: datetime, end: datetime, cfg: WFOConfig, embargo: timedelta) -> int:\n",
    "    is_start = start\n",
    "    is_end = add_months(is_start, cfg.is_months)\n",
    "    n = 0\n",
    "    while True:\n",
    "        oos_start = is_end + embargo\n",
    "        oos_end = add_months(oos_start, cfg.oos_months)\n",
    "        if oos_end > end:\n",
    "            break\n",
    "        n += 1\n",
    "        is_end = add_months(is_end, cfg.step_months)\n",
    "        if is_end >= end:\n",
    "            break\n",
    "    return n\n",
    "\n",
    "all_folds_rows: List[Dict[str, Any]] = []\n",
    "snapshot_per_symbol: List[Dict[str, Any]] = []\n",
    "\n",
    "for sym in universe:\n",
    "    r = df_ranges.filter(pl.col(\"symbol\") == sym)\n",
    "    start_dt = r.select(\"start_utc\").item()\n",
    "    end_dt = r.select(\"end_utc\").item()\n",
    "    n_rows = int(r.select(\"n_rows\").item())\n",
    "\n",
    "    asset_class = spec_map[sym].get(\"asset_class\", \"unknown\")\n",
    "    cfg_candidates = CANDIDATE_CONFIGS_BY_ASSET.get(asset_class, [WFOConfig(12, 3, 3)])\n",
    "\n",
    "    chosen_cfg: Optional[WFOConfig] = None\n",
    "    chosen_count = 0\n",
    "\n",
    "    for cfg in cfg_candidates:\n",
    "        cnt = possible_fold_count(start_dt, end_dt, cfg, EMBARGO)\n",
    "        if cnt >= MIN_FOLDS:\n",
    "            chosen_cfg = cfg\n",
    "            chosen_count = cnt\n",
    "            break\n",
    "        if cnt > chosen_count:\n",
    "            chosen_cfg = cfg\n",
    "            chosen_count = cnt\n",
    "\n",
    "    if chosen_cfg is None or chosen_count < 3:\n",
    "        raise RuntimeError(f\"[Celda 04 v2.0.1] ERROR: WFO indefendible para {sym}. folds_possible={chosen_count}\")\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 100)\n",
    "    print(f\"[Celda 04 v2.0.1] {sym} | asset_class={asset_class}\")\n",
    "    print(f\"  data: start={start_dt}  end={end_dt}  n_rows={n_rows:,}\")\n",
    "    print(f\"  chosen_cfg: IS={chosen_cfg.is_months}m  OOS={chosen_cfg.oos_months}m  STEP={chosen_cfg.step_months}m\")\n",
    "    print(f\"  embargo_days={EMBARGO.total_seconds()/86400.0:.2f} | folds_possible={chosen_count} | mode={WFO_MODE}\")\n",
    "\n",
    "    fold_id = 1\n",
    "    is_start = start_dt\n",
    "    is_end = add_months(is_start, chosen_cfg.is_months)\n",
    "\n",
    "    while True:\n",
    "        embargo_start = is_end\n",
    "        embargo_end = is_end + EMBARGO\n",
    "        oos_start = embargo_end\n",
    "        oos_end = add_months(oos_start, chosen_cfg.oos_months)\n",
    "\n",
    "        if oos_end > end_dt:\n",
    "            break\n",
    "\n",
    "        if WFO_MODE == \"rolling\":\n",
    "            is_start_eff = add_months(is_start, (fold_id - 1) * chosen_cfg.step_months)\n",
    "            is_end_eff = is_end\n",
    "        else:\n",
    "            is_start_eff = is_start\n",
    "            is_end_eff = is_end\n",
    "\n",
    "        is_bars = count_bars(sym, is_start_eff, is_end_eff)\n",
    "        oos_bars = count_bars(sym, oos_start, oos_end)\n",
    "\n",
    "        is_days = count_days(sym, is_start_eff, is_end_eff)\n",
    "        oos_days = count_days(sym, oos_start, oos_end)\n",
    "\n",
    "        all_folds_rows.append({\n",
    "            \"symbol\": sym,\n",
    "            \"fold_id\": int(fold_id),\n",
    "            \"asset_class\": asset_class,\n",
    "            \"wfo_mode\": WFO_MODE,\n",
    "            \"is_start_utc\": is_start_eff,\n",
    "            \"is_end_utc\": is_end_eff,\n",
    "            \"embargo_start_utc\": embargo_start,\n",
    "            \"embargo_end_utc\": embargo_end,\n",
    "            \"oos_start_utc\": oos_start,\n",
    "            \"oos_end_utc\": oos_end,\n",
    "            \"is_bars\": int(is_bars),\n",
    "            \"oos_bars\": int(oos_bars),\n",
    "            \"is_days\": int(is_days),\n",
    "            \"oos_days\": int(oos_days),\n",
    "            \"cfg_is_months\": int(chosen_cfg.is_months),\n",
    "            \"cfg_oos_months\": int(chosen_cfg.oos_months),\n",
    "            \"cfg_step_months\": int(chosen_cfg.step_months),\n",
    "            \"embargo_bars\": int(MAX_HOLD_BARS),\n",
    "        })\n",
    "\n",
    "        print(f\"  fold={fold_id:02d} | IS bars={is_bars:,} days={is_days} | OOS bars={oos_bars:,} days={oos_days}\")\n",
    "\n",
    "        fold_id += 1\n",
    "        is_end = add_months(is_end, chosen_cfg.step_months)\n",
    "        if is_end >= end_dt:\n",
    "            break\n",
    "\n",
    "    snapshot_per_symbol.append({\n",
    "        \"symbol\": sym,\n",
    "        \"asset_class\": asset_class,\n",
    "        \"config\": {\"is_months\": chosen_cfg.is_months, \"oos_months\": chosen_cfg.oos_months, \"step_months\": chosen_cfg.step_months},\n",
    "        \"wfo_mode\": WFO_MODE,\n",
    "        \"n_folds\": int(fold_id - 1),\n",
    "        \"embargo_bars\": int(MAX_HOLD_BARS),\n",
    "        \"embargo_days\": float(EMBARGO.total_seconds() / 86400.0),\n",
    "        \"data_start_utc\": str(start_dt),\n",
    "        \"data_end_utc\": str(end_dt),\n",
    "        \"n_rows\": int(n_rows),\n",
    "    })\n",
    "\n",
    "wfo_df = pl.DataFrame(all_folds_rows).sort([\"symbol\", \"fold_id\"])\n",
    "\n",
    "# Gate A: folds por símbolo\n",
    "folds_by_sym = wfo_df.group_by(\"symbol\").agg(pl.len().alias(\"n_folds\")).sort(\"symbol\")\n",
    "print(\"\\n--- Folds por símbolo ---\")\n",
    "print(folds_by_sym)\n",
    "\n",
    "too_few = folds_by_sym.filter(pl.col(\"n_folds\") < 3)\n",
    "if too_few.height > 0:\n",
    "    raise RuntimeError(f\"[Celda 04 v2.0.1] ERROR: símbolos con <3 folds: {too_few}\")\n",
    "\n",
    "# Gate B: session-aware (por asset_class)\n",
    "def gate_row(asset_class: str) -> Dict[str, int]:\n",
    "    g = GATES.get(asset_class, GATES[\"unknown\"])\n",
    "    return {k: int(v) for k, v in g.items()}\n",
    "\n",
    "bad_rows = []\n",
    "for row in wfo_df.iter_rows(named=True):\n",
    "    g = gate_row(row[\"asset_class\"])\n",
    "    if (row[\"is_days\"] < g[\"min_is_days\"]) or (row[\"oos_days\"] < g[\"min_oos_days\"]) or (row[\"is_bars\"] < g[\"min_is_bars\"]) or (row[\"oos_bars\"] < g[\"min_oos_bars\"]):\n",
    "        bad_rows.append({\n",
    "            \"symbol\": row[\"symbol\"],\n",
    "            \"fold_id\": row[\"fold_id\"],\n",
    "            \"asset_class\": row[\"asset_class\"],\n",
    "            \"is_bars\": row[\"is_bars\"], \"oos_bars\": row[\"oos_bars\"],\n",
    "            \"is_days\": row[\"is_days\"], \"oos_days\": row[\"oos_days\"],\n",
    "            **{f\"gate_{k}\": v for k, v in g.items()}\n",
    "        })\n",
    "\n",
    "if bad_rows:\n",
    "    bad_df = pl.DataFrame(bad_rows).sort([\"symbol\", \"fold_id\"])\n",
    "    print(\"\\n[Celda 04 v2.0.1] Detalle folds que NO pasan gates session-aware (se detiene):\")\n",
    "    print(bad_df)\n",
    "    raise RuntimeError(\n",
    "        \"[Celda 04 v2.0.1] ERROR: Hay folds que no cumplen mínimos day-aware y bar-aware por asset_class. \"\n",
    "        \"Si esto pasa, tu data o tus ventanas son insuficientes para WFO defendible.\"\n",
    "    )\n",
    "\n",
    "# Gate C: no OOS overlap por símbolo\n",
    "bad_overlap = []\n",
    "for sym in wfo_df.select(\"symbol\").unique().to_series().to_list():\n",
    "    s = wfo_df.filter(pl.col(\"symbol\") == sym).sort(\"fold_id\")\n",
    "    prev_end = None\n",
    "    for row in s.iter_rows(named=True):\n",
    "        if prev_end is not None and row[\"oos_start_utc\"] < prev_end:\n",
    "            bad_overlap.append((sym, row[\"fold_id\"]))\n",
    "        prev_end = row[\"oos_end_utc\"]\n",
    "if bad_overlap:\n",
    "    raise RuntimeError(f\"[Celda 04 v2.0.1] ERROR: OOS overlap detectado: {bad_overlap}\")\n",
    "\n",
    "# Persistir\n",
    "OUT_WFO_FOLDS.parent.mkdir(parents=True, exist_ok=True)\n",
    "wfo_df.write_parquet(OUT_WFO_FOLDS)\n",
    "\n",
    "snapshot = {\n",
    "    \"cell\": \"04 v2.0.1\",\n",
    "    \"created_utc\": _now_utc_iso(),\n",
    "    \"qa_cell_detected\": qa_cell,\n",
    "    \"wfo_mode\": WFO_MODE,\n",
    "    \"min_folds_target\": MIN_FOLDS,\n",
    "    \"max_hold_bars\": MAX_HOLD_BARS,\n",
    "    \"embargo_days\": float(EMBARGO.total_seconds() / 86400.0),\n",
    "    \"gates\": GATES,\n",
    "    \"notes\": [\n",
    "        \"Gates cambiados a day-aware + bar-aware por asset_class (session-aware).\",\n",
    "        \"Esto evita bloquear equities session-only con umbrales 24/7.\",\n",
    "    ],\n",
    "    \"per_symbol\": snapshot_per_symbol,\n",
    "    \"folds_path\": str(OUT_WFO_FOLDS),\n",
    "}\n",
    "\n",
    "OUT_WFO_SNAPSHOT.parent.mkdir(parents=True, exist_ok=True)\n",
    "OUT_WFO_SNAPSHOT.write_text(json.dumps(snapshot, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"\\n[Celda 04 v2.0.1] OK — WFO folds guardados:\")\n",
    "print(f\"  - {OUT_WFO_FOLDS}\")\n",
    "print(f\"  - {OUT_WFO_SNAPSHOT}\")\n",
    "\n",
    "print(\"\\n--- WFO Folds (preview) ---\")\n",
    "print(wfo_df.head(12))\n",
    "\n",
    "print(\"\\n[Celda 04 v2.0.1] OK — Se permite avanzar a Celda 05.\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70da23dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Celda 05 v2.0.3] OK — features guardados:\n",
      "  - C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\features_m5_v2.parquet\n",
      "  - C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\features_snapshot_v2.json\n",
      "\n",
      "--- Features preview ---\n",
      "shape: (8, 19)\n",
      "┌────────┬──────────────┬────────┬────────┬───┬────────────┬───────────┬─────────────┬─────────────┐\n",
      "│ symbol ┆ time_utc     ┆ open   ┆ high   ┆ … ┆ ema_600    ┆ trend_dir ┆ trend_stren ┆ trend_slope │\n",
      "│ ---    ┆ ---          ┆ ---    ┆ ---    ┆   ┆ ---        ┆ ---       ┆ gth_bps     ┆ _bps_50     │\n",
      "│ str    ┆ datetime[ms] ┆ f64    ┆ f64    ┆   ┆ f64        ┆ i32       ┆ ---         ┆ ---         │\n",
      "│        ┆              ┆        ┆        ┆   ┆            ┆           ┆ f64         ┆ f64         │\n",
      "╞════════╪══════════════╪════════╪════════╪═══╪════════════╪═══════════╪═════════════╪═════════════╡\n",
      "│ BNBUSD ┆ 2021-11-19   ┆ 537.88 ┆ 540.08 ┆ … ┆ 539.68     ┆ 0         ┆ 0.0         ┆ null        │\n",
      "│        ┆ 00:00:00     ┆        ┆        ┆   ┆            ┆           ┆             ┆             │\n",
      "│ BNBUSD ┆ 2021-11-19   ┆ 539.68 ┆ 540.08 ┆ … ┆ 539.674676 ┆ -1        ┆ 0.196921    ┆ null        │\n",
      "│        ┆ 00:05:00     ┆        ┆        ┆   ┆            ┆           ┆             ┆             │\n",
      "│ BNBUSD ┆ 2021-11-19   ┆ 538.08 ┆ 540.48 ┆ … ┆ 539.674028 ┆ -1        ┆ 0.218354    ┆ null        │\n",
      "│        ┆ 00:10:00     ┆        ┆        ┆   ┆            ┆           ┆             ┆             │\n",
      "│ BNBUSD ┆ 2021-11-19   ┆ 539.48 ┆ 539.78 ┆ … ┆ 539.668723 ┆ -1        ┆ 0.41293     ┆ null        │\n",
      "│        ┆ 00:15:00     ┆        ┆        ┆   ┆            ┆           ┆             ┆             │\n",
      "│ BNBUSD ┆ 2021-11-19   ┆ 538.08 ┆ 538.38 ┆ … ┆ 539.659443 ┆ -1        ┆ 0.753726    ┆ null        │\n",
      "│        ┆ 00:20:00     ┆        ┆        ┆   ┆            ┆           ┆             ┆             │\n",
      "│ BNBUSD ┆ 2021-11-19   ┆ 536.88 ┆ 537.08 ┆ … ┆ 539.649528 ┆ -1        ┆ 1.114158    ┆ null        │\n",
      "│        ┆ 00:25:00     ┆        ┆        ┆   ┆            ┆           ┆             ┆             │\n",
      "│ BNBUSD ┆ 2021-11-19   ┆ 536.68 ┆ 537.78 ┆ … ┆ 539.639979 ┆ -1        ┆ 1.456891    ┆ null        │\n",
      "│        ┆ 00:30:00     ┆        ┆        ┆   ┆            ┆           ┆             ┆             │\n",
      "│ BNBUSD ┆ 2021-11-19   ┆ 536.78 ┆ 537.38 ┆ … ┆ 539.627466 ┆ -1        ┆ 1.909479    ┆ null        │\n",
      "│        ┆ 00:35:00     ┆        ┆        ┆   ┆            ┆           ┆             ┆             │\n",
      "└────────┴──────────────┴────────┴────────┴───┴────────────┴───────────┴─────────────┴─────────────┘\n",
      "\n",
      "--- Monotonicidad time_utc por símbolo ---\n",
      "shape: (4, 2)\n",
      "┌────────┬───────────┐\n",
      "│ symbol ┆ is_sorted │\n",
      "│ ---    ┆ ---       │\n",
      "│ str    ┆ bool      │\n",
      "╞════════╪═══════════╡\n",
      "│ BNBUSD ┆ true      │\n",
      "│ BTCUSD ┆ true      │\n",
      "│ LVMH   ┆ true      │\n",
      "│ XAUAUD ┆ true      │\n",
      "└────────┴───────────┘\n",
      "\n",
      "--- Null% (warmup) en features clave ---\n",
      "shape: (4, 7)\n",
      "┌────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┐\n",
      "│ symbol ┆ null_pct_er_ ┆ null_pct_vol ┆ null_pct_atr ┆ null_pct_mom ┆ null_pct_ema ┆ null_pct_ema │\n",
      "│ ---    ┆ 288          ┆ _bps_288     ┆ _bps_96      ┆ _bps_288     ┆ _200         ┆ _600         │\n",
      "│ str    ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          │\n",
      "│        ┆ f64          ┆ f64          ┆ f64          ┆ f64          ┆ f64          ┆ f64          │\n",
      "╞════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╡\n",
      "│ BNBUSD ┆ 0.066926     ┆ 0.066926     ┆ 0.022076     ┆ 0.066926     ┆ 0.0          ┆ 0.0          │\n",
      "│ BTCUSD ┆ 0.080441     ┆ 0.080441     ┆ 0.026534     ┆ 0.080441     ┆ 0.0          ┆ 0.0          │\n",
      "│ LVMH   ┆ 0.263521     ┆ 0.263521     ┆ 0.086925     ┆ 0.263521     ┆ 0.0          ┆ 0.0          │\n",
      "│ XAUAUD ┆ 0.096926     ┆ 0.096926     ┆ 0.031972     ┆ 0.096926     ┆ 0.0          ┆ 0.0          │\n",
      "└────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┘\n",
      "\n",
      "--- Distribución trend_dir (sanity) ---\n",
      "shape: (12, 3)\n",
      "┌────────┬───────────┬────────┐\n",
      "│ symbol ┆ trend_dir ┆ n      │\n",
      "│ ---    ┆ ---       ┆ ---    │\n",
      "│ str    ┆ i32       ┆ u32    │\n",
      "╞════════╪═══════════╪════════╡\n",
      "│ BNBUSD ┆ -1        ┆ 207400 │\n",
      "│ BNBUSD ┆ 0         ┆ 1      │\n",
      "│ BNBUSD ┆ 1         ┆ 222922 │\n",
      "│ BTCUSD ┆ -1        ┆ 173540 │\n",
      "│ BTCUSD ┆ 0         ┆ 1      │\n",
      "│ …      ┆ …         ┆ …      │\n",
      "│ LVMH   ┆ 0         ┆ 1      │\n",
      "│ LVMH   ┆ 1         ┆ 51565  │\n",
      "│ XAUAUD ┆ -1        ┆ 125587 │\n",
      "│ XAUAUD ┆ 0         ┆ 1      │\n",
      "│ XAUAUD ┆ 1         ┆ 171547 │\n",
      "└────────┴───────────┴────────┘\n",
      "\n",
      "[Celda 05 v2.0.3] OK — Se permite avanzar a Celda 06 (Regime Gate ON/OFF + hysteresis).\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# Celda 05 v2.0.3 — Feature Set (Causal): Trendiness + Direction [FIX nested windows]\n",
    "# Fix vs v2.0.2:\n",
    "#   - Elimina \"window dentro de rolling/window\": primero materializa columnas base (ret, true_range, abs_diff),\n",
    "#     luego aplica rollings/EMAs usando pl.col(\"...\") (sin anidar ventanas).\n",
    "#   - Mantiene Lazy-friendly y sin ColumnNotFound.\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# -----------------------------\n",
    "# Preflight\n",
    "# -----------------------------\n",
    "if \"RUN\" not in globals():\n",
    "    raise RuntimeError(\"[Celda 05 v2.0.3] ERROR: No existe RUN en memoria. Ejecuta primero Celda 00 v2.0.\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "\n",
    "OHLCV_CLEAN_PATH = ARTIFACTS.get(\"ohlcv_clean\", RUN_DIR / \"ohlcv_clean_m5.parquet\")\n",
    "QA_REPORT_PATH = ARTIFACTS.get(\"data_qa_report\", RUN_DIR / \"data_qa_report.json\")\n",
    "WFO_FOLDS_PATH = ARTIFACTS.get(\"wfo_folds\", RUN_DIR / \"wfo_folds.parquet\")\n",
    "\n",
    "if not OHLCV_CLEAN_PATH.exists():\n",
    "    raise RuntimeError(\"[Celda 05 v2.0.3] ERROR: Falta ohlcv_clean_m5.parquet. Ejecuta Celda 02.\")\n",
    "if not WFO_FOLDS_PATH.exists():\n",
    "    raise RuntimeError(\"[Celda 05 v2.0.3] ERROR: Falta wfo_folds.parquet. Ejecuta Celda 04.\")\n",
    "\n",
    "OUT_FEATURES = RUN_DIR / \"features_m5_v2.parquet\"\n",
    "OUT_SNAPSHOT = RUN_DIR / \"features_snapshot_v2.json\"\n",
    "\n",
    "RUN[\"ARTIFACTS\"][\"features_m5\"] = OUT_FEATURES\n",
    "RUN[\"ARTIFACTS\"][\"features_snapshot\"] = OUT_SNAPSHOT\n",
    "\n",
    "FORCE_REBUILD = os.getenv(\"TREND_M5_FORCE_REBUILD_FEATURES\", \"\").strip().lower() in (\"1\", \"true\", \"yes\")\n",
    "\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "# -----------------------------\n",
    "# Parámetros\n",
    "# -----------------------------\n",
    "EXPECTED_BAR_SECONDS = 300\n",
    "\n",
    "ER_WIN = int(os.getenv(\"TREND_M5_ER_WIN\", \"288\"))\n",
    "VOL_WIN = int(os.getenv(\"TREND_M5_VOL_WIN\", \"288\"))\n",
    "MOM_WIN = int(os.getenv(\"TREND_M5_MOM_WIN\", \"288\"))\n",
    "ATR_WIN = int(os.getenv(\"TREND_M5_ATR_WIN\", \"96\"))\n",
    "\n",
    "EMA_FAST = int(os.getenv(\"TREND_M5_EMA_FAST\", \"200\"))\n",
    "EMA_SLOW = int(os.getenv(\"TREND_M5_EMA_SLOW\", \"600\"))\n",
    "SLOPE_WIN = int(os.getenv(\"TREND_M5_SLOPE_WIN\", \"50\"))\n",
    "\n",
    "EPS = 1e-12\n",
    "\n",
    "# -----------------------------\n",
    "# Cache\n",
    "# -----------------------------\n",
    "if OUT_FEATURES.exists() and OUT_SNAPSHOT.exists() and (not FORCE_REBUILD):\n",
    "    print(f\"[Celda 05 v2.0.3] Cache detectado. Usando features existentes:\\n  - {OUT_FEATURES}\\n  - {OUT_SNAPSHOT}\")\n",
    "    snap = json.loads(OUT_SNAPSHOT.read_text(encoding=\"utf-8\"))\n",
    "    print(\"\\n--- Features Snapshot (resumen) ---\")\n",
    "    print(\"  params:\", snap.get(\"params\", {}))\n",
    "    print(\"  symbols:\", snap.get(\"symbols\", []))\n",
    "    print(\"  schema_cols(sample):\", snap.get(\"schema_cols\", [])[:20], \"...\")\n",
    "    print(\"\\n[Celda 05 v2.0.3] OK — features listos.\")\n",
    "else:\n",
    "    lf0 = (\n",
    "        pl.scan_parquet(OHLCV_CLEAN_PATH)\n",
    "        .select([\"symbol\", \"time_utc\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"spread\"])\n",
    "        .sort([\"symbol\", \"time_utc\"])\n",
    "    )\n",
    "\n",
    "    cols = lf0.collect_schema().names()\n",
    "    required = [\"symbol\", \"time_utc\", \"open\", \"high\", \"low\", \"close\"]\n",
    "    missing = [c for c in required if c not in cols]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"[Celda 05 v2.0.3] ERROR: faltan columnas en ohlcv_clean: {missing}\")\n",
    "\n",
    "    # ============================================================\n",
    "    # Stage 1: columnas base (permitido usar .over aquí)\n",
    "    #   - IMPORTANT: no usar estas expresiones dentro de rolling posteriormente.\n",
    "    # ============================================================\n",
    "    close_prev = pl.col(\"close\").shift(1).over(\"symbol\")\n",
    "\n",
    "    ret_expr = (\n",
    "        pl.when(close_prev.is_not_null() & (close_prev > 0))\n",
    "        .then(pl.col(\"close\") / close_prev - 1.0)\n",
    "        .otherwise(None)\n",
    "    )\n",
    "\n",
    "    # abs_diff por símbolo (evita diff().over, y evita nested windows)\n",
    "    abs_diff_expr = (pl.col(\"close\") - pl.col(\"close\").shift(1).over(\"symbol\")).abs()\n",
    "\n",
    "    # true range base (por símbolo)\n",
    "    tr_expr = pl.max_horizontal([\n",
    "        (pl.col(\"high\") - pl.col(\"low\")),\n",
    "        (pl.col(\"high\") - pl.col(\"close\").shift(1).over(\"symbol\")).abs(),\n",
    "        (pl.col(\"low\")  - pl.col(\"close\").shift(1).over(\"symbol\")).abs(),\n",
    "    ])\n",
    "\n",
    "    lf1 = (\n",
    "        lf0.with_columns([\n",
    "            close_prev.alias(\"close_prev\"),\n",
    "            ret_expr.alias(\"ret\"),\n",
    "            ret_expr.abs().alias(\"abs_ret\"),\n",
    "            abs_diff_expr.alias(\"abs_diff\"),\n",
    "            tr_expr.alias(\"true_range\"),\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    # ============================================================\n",
    "    # Stage 2: rollings sobre columnas materializadas (NO nested windows)\n",
    "    # ============================================================\n",
    "    lf2 = (\n",
    "        lf1.with_columns([\n",
    "            (pl.col(\"ret\").rolling_std(window_size=VOL_WIN, min_samples=VOL_WIN).over(\"symbol\") * 10_000)\n",
    "                .alias(f\"vol_bps_{VOL_WIN}\"),\n",
    "\n",
    "            (pl.col(\"true_range\").rolling_mean(window_size=ATR_WIN, min_samples=ATR_WIN).over(\"symbol\") / pl.col(\"close\") * 10_000)\n",
    "                .alias(f\"atr_bps_{ATR_WIN}\"),\n",
    "\n",
    "            ((pl.col(\"close\") / pl.col(\"close\").shift(MOM_WIN).over(\"symbol\") - 1.0) * 10_000)\n",
    "                .alias(f\"mom_bps_{MOM_WIN}\"),\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    lf3 = (\n",
    "        lf2.with_columns([\n",
    "            (pl.col(f\"mom_bps_{MOM_WIN}\").abs() / (pl.col(f\"vol_bps_{VOL_WIN}\") + EPS))\n",
    "                .alias(f\"mom_eff_{MOM_WIN}\"),\n",
    "\n",
    "            ((pl.col(\"close\") - pl.col(\"close\").shift(ER_WIN).over(\"symbol\")).abs() /\n",
    "             (pl.col(\"abs_diff\").rolling_sum(window_size=ER_WIN, min_samples=ER_WIN).over(\"symbol\") + EPS))\n",
    "                .alias(f\"er_{ER_WIN}\"),\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    # ============================================================\n",
    "    # Stage 3: EMAs y dirección (columnas materializadas => combinaciones seguras)\n",
    "    # ============================================================\n",
    "    lf4 = (\n",
    "        lf3.with_columns([\n",
    "            pl.col(\"close\").ewm_mean(span=EMA_FAST, adjust=False).over(\"symbol\").alias(f\"ema_{EMA_FAST}\"),\n",
    "            pl.col(\"close\").ewm_mean(span=EMA_SLOW, adjust=False).over(\"symbol\").alias(f\"ema_{EMA_SLOW}\"),\n",
    "        ])\n",
    "        .with_columns([\n",
    "            pl.when(pl.col(f\"ema_{EMA_FAST}\") > pl.col(f\"ema_{EMA_SLOW}\")).then(1)\n",
    "              .when(pl.col(f\"ema_{EMA_FAST}\") < pl.col(f\"ema_{EMA_SLOW}\")).then(-1)\n",
    "              .otherwise(0)\n",
    "              .alias(\"trend_dir\"),\n",
    "\n",
    "            (((pl.col(f\"ema_{EMA_FAST}\") - pl.col(f\"ema_{EMA_SLOW}\")).abs() / pl.col(\"close\")) * 10_000)\n",
    "              .alias(\"trend_strength_bps\"),\n",
    "\n",
    "            (((pl.col(f\"ema_{EMA_SLOW}\") / pl.col(f\"ema_{EMA_SLOW}\").shift(SLOPE_WIN).over(\"symbol\")) - 1.0) * 10_000)\n",
    "              .alias(f\"trend_slope_bps_{SLOPE_WIN}\"),\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Final select (canónico)\n",
    "    # -----------------------------\n",
    "    lf_feat = (\n",
    "        lf4.select([\n",
    "            \"symbol\",\n",
    "            \"time_utc\",\n",
    "            \"open\", \"high\", \"low\", \"close\",\n",
    "            \"volume\", \"spread\",\n",
    "            \"ret\",\n",
    "            f\"vol_bps_{VOL_WIN}\",\n",
    "            f\"atr_bps_{ATR_WIN}\",\n",
    "            f\"mom_bps_{MOM_WIN}\",\n",
    "            f\"mom_eff_{MOM_WIN}\",\n",
    "            f\"er_{ER_WIN}\",\n",
    "            f\"ema_{EMA_FAST}\",\n",
    "            f\"ema_{EMA_SLOW}\",\n",
    "            \"trend_dir\",\n",
    "            \"trend_strength_bps\",\n",
    "            f\"trend_slope_bps_{SLOPE_WIN}\",\n",
    "        ])\n",
    "        .sort([\"symbol\", \"time_utc\"])\n",
    "    )\n",
    "\n",
    "    df_feat = lf_feat.collect()\n",
    "\n",
    "    # -----------------------------\n",
    "    # QA / sanity\n",
    "    # -----------------------------\n",
    "    mono = (\n",
    "        df_feat.group_by(\"symbol\")\n",
    "        .agg((pl.col(\"time_utc\").diff().drop_nulls().min() >= 0).alias(\"is_sorted\"))\n",
    "        .sort(\"symbol\")\n",
    "    )\n",
    "    if mono.filter(pl.col(\"is_sorted\") == False).height > 0:\n",
    "        raise RuntimeError(f\"[Celda 05 v2.0.3] ERROR: time_utc no está ordenado en features:\\n{mono}\")\n",
    "\n",
    "    key_cols = [\n",
    "        f\"er_{ER_WIN}\",\n",
    "        f\"vol_bps_{VOL_WIN}\",\n",
    "        f\"atr_bps_{ATR_WIN}\",\n",
    "        f\"mom_bps_{MOM_WIN}\",\n",
    "        f\"ema_{EMA_FAST}\",\n",
    "        f\"ema_{EMA_SLOW}\",\n",
    "    ]\n",
    "    null_report = (\n",
    "        df_feat.group_by(\"symbol\")\n",
    "        .agg([(pl.col(c).is_null().mean() * 100.0).alias(f\"null_pct_{c}\") for c in key_cols])\n",
    "        .sort(\"symbol\")\n",
    "    )\n",
    "\n",
    "    OUT_FEATURES.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_feat.write_parquet(OUT_FEATURES)\n",
    "\n",
    "    qa_cell = None\n",
    "    if QA_REPORT_PATH.exists():\n",
    "        try:\n",
    "            qa_cell = json.loads(QA_REPORT_PATH.read_text(encoding=\"utf-8\")).get(\"cell\")\n",
    "        except Exception:\n",
    "            qa_cell = None\n",
    "\n",
    "    snapshot = {\n",
    "        \"cell\": \"05 v2.0.3\",\n",
    "        \"created_utc\": _now_utc_iso(),\n",
    "        \"qa_cell_detected\": qa_cell,\n",
    "        \"params\": {\n",
    "            \"ER_WIN\": ER_WIN,\n",
    "            \"VOL_WIN\": VOL_WIN,\n",
    "            \"MOM_WIN\": MOM_WIN,\n",
    "            \"ATR_WIN\": ATR_WIN,\n",
    "            \"EMA_FAST\": EMA_FAST,\n",
    "            \"EMA_SLOW\": EMA_SLOW,\n",
    "            \"SLOPE_WIN\": SLOPE_WIN,\n",
    "            \"EXPECTED_BAR_SECONDS\": EXPECTED_BAR_SECONDS,\n",
    "        },\n",
    "        \"schema_cols\": df_feat.columns,\n",
    "        \"symbols\": df_feat.select(\"symbol\").unique().to_series().to_list(),\n",
    "        \"notes\": [\n",
    "            \"Fix nested windows: primero columnas base, luego rollings/EMAs sobre pl.col(...) materializadas.\",\n",
    "            \"Features causales (<=t) alineadas con entrada t+1.\",\n",
    "        ],\n",
    "    }\n",
    "    OUT_SNAPSHOT.write_text(json.dumps(snapshot, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"[Celda 05 v2.0.3] OK — features guardados:\")\n",
    "    print(f\"  - {OUT_FEATURES}\")\n",
    "    print(f\"  - {OUT_SNAPSHOT}\")\n",
    "\n",
    "    print(\"\\n--- Features preview ---\")\n",
    "    print(df_feat.head(8))\n",
    "\n",
    "    print(\"\\n--- Monotonicidad time_utc por símbolo ---\")\n",
    "    print(mono)\n",
    "\n",
    "    print(\"\\n--- Null% (warmup) en features clave ---\")\n",
    "    print(null_report)\n",
    "\n",
    "    dist = (\n",
    "        df_feat.group_by([\"symbol\", \"trend_dir\"])\n",
    "        .agg(pl.len().alias(\"n\"))\n",
    "        .sort([\"symbol\", \"trend_dir\"])\n",
    "    )\n",
    "    print(\"\\n--- Distribución trend_dir (sanity) ---\")\n",
    "    print(dist)\n",
    "\n",
    "    print(\"\\n[Celda 05 v2.0.3] OK — Se permite avanzar a Celda 06 (Regime Gate ON/OFF + hysteresis).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3122ccc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Celda 06 v2.0.1 :: Regime Gate por Fold (TREND, M5)\n",
      "[Celda 06] BNBUSD fold=1 LONG :: scheme=BASE cov_IS=0.179 cov_OOS=0.129\n",
      "[Celda 06] BNBUSD fold=1 SHORT :: scheme=BASE cov_IS=0.166 cov_OOS=0.189\n",
      "[Celda 06] BNBUSD fold=2 LONG :: scheme=BASE cov_IS=0.173 cov_OOS=0.176\n",
      "[Celda 06] BNBUSD fold=2 SHORT :: scheme=BASE cov_IS=0.171 cov_OOS=0.134\n",
      "[Celda 06] BNBUSD fold=3 LONG :: scheme=BASE cov_IS=0.175 cov_OOS=0.206\n",
      "[Celda 06] BNBUSD fold=3 SHORT :: scheme=BASE cov_IS=0.168 cov_OOS=0.131\n",
      "[Celda 06] BNBUSD fold=4 LONG :: scheme=BASE cov_IS=0.178 cov_OOS=0.207\n",
      "[Celda 06] BNBUSD fold=4 SHORT :: scheme=BASE cov_IS=0.165 cov_OOS=0.089\n",
      "[Celda 06] BNBUSD fold=5 LONG :: scheme=BASE cov_IS=0.185 cov_OOS=0.203\n",
      "[Celda 06] BNBUSD fold=5 SHORT :: scheme=BASE cov_IS=0.159 cov_OOS=0.174\n",
      "[Celda 06] BNBUSD fold=6 LONG :: scheme=BASE cov_IS=0.184 cov_OOS=0.233\n",
      "[Celda 06] BNBUSD fold=6 SHORT :: scheme=BASE cov_IS=0.160 cov_OOS=0.150\n",
      "[Celda 06] BNBUSD fold=7 LONG :: scheme=BASE cov_IS=0.187 cov_OOS=0.176\n",
      "[Celda 06] BNBUSD fold=7 SHORT :: scheme=BASE cov_IS=0.157 cov_OOS=0.153\n",
      "[Celda 06] BNBUSD fold=8 LONG :: scheme=BASE cov_IS=0.188 cov_OOS=0.204\n",
      "[Celda 06] BNBUSD fold=8 SHORT :: scheme=BASE cov_IS=0.157 cov_OOS=0.160\n",
      "[Celda 06] BNBUSD fold=9 LONG :: scheme=BASE cov_IS=0.188 cov_OOS=0.268\n",
      "[Celda 06] BNBUSD fold=9 SHORT :: scheme=BASE cov_IS=0.157 cov_OOS=0.154\n",
      "[Celda 06] BNBUSD fold=10 LONG :: scheme=BASE cov_IS=0.191 cov_OOS=0.207\n",
      "[Celda 06] BNBUSD fold=10 SHORT :: scheme=BASE cov_IS=0.155 cov_OOS=0.136\n",
      "[Celda 06] BTCUSD fold=1 LONG :: scheme=BASE cov_IS=0.181 cov_OOS=0.165\n",
      "[Celda 06] BTCUSD fold=1 SHORT :: scheme=BASE cov_IS=0.170 cov_OOS=0.164\n",
      "[Celda 06] BTCUSD fold=2 LONG :: scheme=BASE cov_IS=0.176 cov_OOS=0.191\n",
      "[Celda 06] BTCUSD fold=2 SHORT :: scheme=BASE cov_IS=0.172 cov_OOS=0.125\n",
      "[Celda 06] BTCUSD fold=3 LONG :: scheme=BASE cov_IS=0.180 cov_OOS=0.258\n",
      "[Celda 06] BTCUSD fold=3 SHORT :: scheme=BASE cov_IS=0.167 cov_OOS=0.116\n",
      "[Celda 06] BTCUSD fold=4 LONG :: scheme=BASE cov_IS=0.190 cov_OOS=0.202\n",
      "[Celda 06] BTCUSD fold=4 SHORT :: scheme=BASE cov_IS=0.156 cov_OOS=0.121\n",
      "[Celda 06] BTCUSD fold=5 LONG :: scheme=BASE cov_IS=0.194 cov_OOS=0.202\n",
      "[Celda 06] BTCUSD fold=5 SHORT :: scheme=BASE cov_IS=0.153 cov_OOS=0.202\n",
      "[Celda 06] BTCUSD fold=6 LONG :: scheme=BASE cov_IS=0.191 cov_OOS=0.239\n",
      "[Celda 06] BTCUSD fold=6 SHORT :: scheme=BASE cov_IS=0.156 cov_OOS=0.148\n",
      "[Celda 06] BTCUSD fold=7 LONG :: scheme=BASE cov_IS=0.195 cov_OOS=0.185\n",
      "[Celda 06] BTCUSD fold=7 SHORT :: scheme=BASE cov_IS=0.153 cov_OOS=0.173\n",
      "[Celda 06] BTCUSD fold=8 LONG :: scheme=BASE cov_IS=0.195 cov_OOS=0.191\n",
      "[Celda 06] BTCUSD fold=8 SHORT :: scheme=BASE cov_IS=0.154 cov_OOS=0.130\n",
      "[Celda 06] BTCUSD fold=9 LONG :: scheme=BASE cov_IS=0.194 cov_OOS=0.226\n",
      "[Celda 06] BTCUSD fold=9 SHORT :: scheme=BASE cov_IS=0.154 cov_OOS=0.190\n",
      "[Celda 06] BTCUSD fold=10 LONG :: scheme=BASE cov_IS=0.196 cov_OOS=0.197\n",
      "[Celda 06] BTCUSD fold=10 SHORT :: scheme=BASE cov_IS=0.152 cov_OOS=0.195\n",
      "[Celda 06] LVMH fold=1 LONG :: scheme=BASE cov_IS=0.200 cov_OOS=0.240\n",
      "[Celda 06] LVMH fold=1 SHORT :: scheme=BASE cov_IS=0.149 cov_OOS=0.276\n",
      "[Celda 06] LVMH fold=2 LONG :: scheme=BASE cov_IS=0.192 cov_OOS=0.148\n",
      "[Celda 06] LVMH fold=2 SHORT :: scheme=BASE cov_IS=0.159 cov_OOS=0.213\n",
      "[Celda 06] LVMH fold=3 LONG :: scheme=BASE cov_IS=0.186 cov_OOS=0.236\n",
      "[Celda 06] LVMH fold=3 SHORT :: scheme=BASE cov_IS=0.163 cov_OOS=0.142\n",
      "[Celda 06] LVMH fold=4 LONG :: scheme=BASE cov_IS=0.188 cov_OOS=0.109\n",
      "[Celda 06] LVMH fold=4 SHORT :: scheme=BASE cov_IS=0.160 cov_OOS=0.245\n",
      "[Celda 06] LVMH fold=5 LONG :: scheme=BASE cov_IS=0.187 cov_OOS=0.221\n",
      "[Celda 06] LVMH fold=5 SHORT :: scheme=BASE cov_IS=0.163 cov_OOS=0.262\n",
      "[Celda 06] LVMH fold=6 LONG :: scheme=BASE cov_IS=0.179 cov_OOS=0.049\n",
      "[Celda 06] LVMH fold=6 SHORT :: scheme=BASE cov_IS=0.170 cov_OOS=0.242\n",
      "[Celda 06] LVMH fold=7 LONG :: scheme=BASE cov_IS=0.172 cov_OOS=0.268\n",
      "[Celda 06] LVMH fold=7 SHORT :: scheme=BASE cov_IS=0.176 cov_OOS=0.099\n",
      "[Celda 06] LVMH fold=8 LONG :: scheme=BASE cov_IS=0.177 cov_OOS=0.018\n",
      "[Celda 06] LVMH fold=8 SHORT :: scheme=BASE cov_IS=0.168 cov_OOS=0.309\n",
      "[Celda 06] LVMH fold=9 LONG :: scheme=BASE cov_IS=0.166 cov_OOS=0.158\n",
      "[Celda 06] LVMH fold=9 SHORT :: scheme=BASE cov_IS=0.177 cov_OOS=0.214\n",
      "[Celda 06] LVMH fold=10 LONG :: scheme=BASE cov_IS=0.162 cov_OOS=0.284\n",
      "[Celda 06] LVMH fold=10 SHORT :: scheme=BASE cov_IS=0.182 cov_OOS=0.129\n",
      "[Celda 06] XAUAUD fold=1 LONG :: scheme=BASE cov_IS=0.179 cov_OOS=0.177\n",
      "[Celda 06] XAUAUD fold=1 SHORT :: scheme=BASE cov_IS=0.170 cov_OOS=0.201\n",
      "[Celda 06] XAUAUD fold=2 LONG :: scheme=BASE cov_IS=0.174 cov_OOS=0.229\n",
      "[Celda 06] XAUAUD fold=2 SHORT :: scheme=BASE cov_IS=0.175 cov_OOS=0.274\n",
      "[Celda 06] XAUAUD fold=3 LONG :: scheme=BASE cov_IS=0.174 cov_OOS=0.162\n",
      "[Celda 06] XAUAUD fold=3 SHORT :: scheme=BASE cov_IS=0.176 cov_OOS=0.163\n",
      "[Celda 06] XAUAUD fold=4 LONG :: scheme=BASE cov_IS=0.175 cov_OOS=0.250\n",
      "[Celda 06] XAUAUD fold=4 SHORT :: scheme=BASE cov_IS=0.175 cov_OOS=0.128\n",
      "[Celda 06] XAUAUD fold=5 LONG :: scheme=BASE cov_IS=0.182 cov_OOS=0.234\n",
      "[Celda 06] XAUAUD fold=5 SHORT :: scheme=BASE cov_IS=0.167 cov_OOS=0.119\n",
      "[Celda 06] XAUAUD fold=6 LONG :: scheme=BASE cov_IS=0.185 cov_OOS=0.320\n",
      "[Celda 06] XAUAUD fold=6 SHORT :: scheme=BASE cov_IS=0.164 cov_OOS=0.122\n",
      "[Celda 06] XAUAUD fold=7 LONG :: scheme=BASE cov_IS=0.191 cov_OOS=0.301\n",
      "[Celda 06] XAUAUD fold=7 SHORT :: scheme=BASE cov_IS=0.158 cov_OOS=0.125\n",
      "[Celda 06] XAUAUD fold=8 LONG :: scheme=BASE cov_IS=0.198 cov_OOS=0.138\n",
      "[Celda 06] XAUAUD fold=8 SHORT :: scheme=BASE cov_IS=0.151 cov_OOS=0.056\n",
      "[Celda 06] XAUAUD fold=9 LONG :: scheme=BASE cov_IS=0.200 cov_OOS=0.156\n",
      "[Celda 06] XAUAUD fold=9 SHORT :: scheme=BASE cov_IS=0.152 cov_OOS=0.116\n",
      "[Celda 06] XAUAUD fold=10 LONG :: scheme=BASE cov_IS=0.199 cov_OOS=0.246\n",
      "[Celda 06] XAUAUD fold=10 SHORT :: scheme=BASE cov_IS=0.152 cov_OOS=0.021\n",
      "\n",
      "[Celda 06] OUT: C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\regime_params_by_fold_v2.parquet (80 rows)\n",
      "[Celda 06] OUT: C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\regime_params_snapshot_v2.json\n",
      ">>> Celda 06 v2.0.1 :: OK\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# Celda 06 v2.0.1 — Regime Gate por Fold (TREND, M5) [IS-only, no leakage]\n",
    "# BUG FIX vs v1: SHORT gate calibrado independientemente (thr_mom_short separado)\n",
    "# Guardrails de cobertura: 5% <= coverage_IS <= 80% (cada side por separado)\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json, math\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 06 v2.0.1 :: Regime Gate por Fold (TREND, M5)\")\n",
    "\n",
    "# ---------- Preflight ----------\n",
    "if \"RUN\" not in globals():\n",
    "    raise RuntimeError(\"[Celda 06] ERROR: RUN no existe. Ejecuta Celda 00.\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "\n",
    "FEATURES_PATH = ARTIFACTS.get(\"features_m5\", RUN_DIR / \"features_m5_v2.parquet\")\n",
    "WFO_FOLDS_PATH = ARTIFACTS.get(\"wfo_folds\", RUN_DIR / \"wfo_folds_v2.parquet\")\n",
    "\n",
    "if not FEATURES_PATH.exists():\n",
    "    raise RuntimeError(f\"[Celda 06] ERROR: features no encontradas: {FEATURES_PATH}\")\n",
    "if not WFO_FOLDS_PATH.exists():\n",
    "    raise RuntimeError(f\"[Celda 06] ERROR: wfo_folds no encontrados: {WFO_FOLDS_PATH}\")\n",
    "\n",
    "OUT_REGIME = ARTIFACTS.get(\"regime_params_by_fold\", RUN_DIR / \"regime_params_by_fold_v2.parquet\")\n",
    "OUT_SNAP = ARTIFACTS.get(\"regime_params_snapshot\", RUN_DIR / \"regime_params_snapshot_v2.json\")\n",
    "\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "# ---------- Parametros ----------\n",
    "ER_COL = \"er_288\"\n",
    "MOM_COL = \"mom_bps_288\"\n",
    "VOL_COL = \"vol_bps_288\"\n",
    "\n",
    "Q_SCHEMES = [\n",
    "    {\"name\": \"BASE\",   \"q_er\": 0.60, \"q_mom\": 0.55, \"q_vol\": 0.90},\n",
    "    {\"name\": \"RELAX1\", \"q_er\": 0.50, \"q_mom\": 0.50, \"q_vol\": 0.95},\n",
    "    {\"name\": \"RELAX2\", \"q_er\": 0.40, \"q_mom\": 0.50, \"q_vol\": 0.99},\n",
    "    {\"name\": \"TIGHT1\", \"q_er\": 0.70, \"q_mom\": 0.60, \"q_vol\": 0.85},\n",
    "]\n",
    "COV_IS_MIN = 0.05\n",
    "COV_IS_MAX = 0.80\n",
    "MIN_IS_ROWS = 5_000\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def _q_safe(s: pl.Series, q: float):\n",
    "    s2 = s.drop_nulls()\n",
    "    if s2.len() == 0:\n",
    "        return None\n",
    "    v = s2.quantile(q, interpolation=\"nearest\")\n",
    "    if v is None:\n",
    "        return None\n",
    "    fv = float(v)\n",
    "    return fv if math.isfinite(fv) else None\n",
    "\n",
    "def _calibrate_side(df_is: pl.DataFrame, side: str) -> dict:\n",
    "    \"\"\"Calibrar thresholds para un side (LONG o SHORT) independientemente.\"\"\"\n",
    "    er_s = df_is.get_column(ER_COL)\n",
    "    mom_s = df_is.get_column(MOM_COL)\n",
    "    vol_s = df_is.get_column(VOL_COL)\n",
    "\n",
    "    best = None\n",
    "    for sch in Q_SCHEMES:\n",
    "        thr_er = _q_safe(er_s, sch[\"q_er\"])\n",
    "        thr_vol = _q_safe(vol_s, sch[\"q_vol\"])\n",
    "        if thr_er is None or thr_vol is None:\n",
    "            continue\n",
    "\n",
    "        # BUG FIX: LONG usa percentil positivo de mom, SHORT usa percentil negativo\n",
    "        if side == \"LONG\":\n",
    "            thr_mom = _q_safe(mom_s, sch[\"q_mom\"])\n",
    "            if thr_mom is None:\n",
    "                continue\n",
    "            thr_mom = max(0.0, thr_mom)\n",
    "            gate = (\n",
    "                (pl.col(ER_COL) >= thr_er) &\n",
    "                (pl.col(MOM_COL) >= thr_mom) &\n",
    "                (pl.col(VOL_COL) <= thr_vol)\n",
    "            )\n",
    "        else:  # SHORT\n",
    "            # percentil bajo de momentum (valores negativos)\n",
    "            thr_mom_short = _q_safe(mom_s, 1.0 - sch[\"q_mom\"])\n",
    "            if thr_mom_short is None:\n",
    "                continue\n",
    "            thr_mom_short = min(0.0, thr_mom_short)\n",
    "            thr_mom = thr_mom_short\n",
    "            gate = (\n",
    "                (pl.col(ER_COL) >= thr_er) &\n",
    "                (pl.col(MOM_COL) <= thr_mom) &\n",
    "                (pl.col(VOL_COL) <= thr_vol)\n",
    "            )\n",
    "\n",
    "        cov = float(df_is.select(gate.mean()).item())\n",
    "        payload = {\n",
    "            \"scheme\": sch[\"name\"], \"side\": side,\n",
    "            \"thr_er\": float(thr_er), \"thr_mom\": float(thr_mom), \"thr_vol\": float(thr_vol),\n",
    "            \"cov_is\": float(cov),\n",
    "        }\n",
    "        if COV_IS_MIN <= cov <= COV_IS_MAX:\n",
    "            return payload\n",
    "        score = abs(cov - 0.30)\n",
    "        if best is None or score < best[0]:\n",
    "            best = (score, payload)\n",
    "\n",
    "    if best is not None:\n",
    "        return best[1]\n",
    "    return {\"scheme\": \"FAIL\", \"side\": side, \"thr_er\": None, \"thr_mom\": None, \"thr_vol\": None, \"cov_is\": 0.0}\n",
    "\n",
    "# ---------- Main ----------\n",
    "df_feat = pl.read_parquet(FEATURES_PATH)\n",
    "df_folds = pl.read_parquet(WFO_FOLDS_PATH)\n",
    "\n",
    "symbols = df_feat.get_column(\"symbol\").unique().sort().to_list()\n",
    "fold_ids = df_folds.get_column(\"fold_id\").unique().sort().to_list()\n",
    "\n",
    "rows = []\n",
    "for sym in symbols:\n",
    "    df_sym = df_feat.filter(pl.col(\"symbol\") == sym).sort(\"time_utc\")\n",
    "    for fid in fold_ids:\n",
    "        fold_row = df_folds.filter(pl.col(\"fold_id\") == fid).row(0, named=True)\n",
    "        is_s = fold_row[\"is_start_utc\"]\n",
    "        is_e = fold_row[\"is_end_utc\"]\n",
    "        oos_s = fold_row[\"oos_start_utc\"]\n",
    "        oos_e = fold_row[\"oos_end_utc\"]\n",
    "\n",
    "        df_is = df_sym.filter(\n",
    "            (pl.col(\"time_utc\") >= is_s) & (pl.col(\"time_utc\") <= is_e)\n",
    "        ).drop_nulls([ER_COL, MOM_COL, VOL_COL])\n",
    "\n",
    "        df_oos = df_sym.filter(\n",
    "            (pl.col(\"time_utc\") >= oos_s) & (pl.col(\"time_utc\") <= oos_e)\n",
    "        ).drop_nulls([ER_COL, MOM_COL, VOL_COL])\n",
    "\n",
    "        for side in (\"LONG\", \"SHORT\"):\n",
    "            cal = _calibrate_side(df_is, side) if df_is.height >= MIN_IS_ROWS else {\n",
    "                \"scheme\": \"SKIP\", \"side\": side, \"thr_er\": None, \"thr_mom\": None, \"thr_vol\": None, \"cov_is\": 0.0\n",
    "            }\n",
    "\n",
    "            # OOS coverage\n",
    "            cov_oos = 0.0\n",
    "            if cal[\"thr_er\"] is not None:\n",
    "                if side == \"LONG\":\n",
    "                    g = (pl.col(ER_COL) >= cal[\"thr_er\"]) & (pl.col(MOM_COL) >= cal[\"thr_mom\"]) & (pl.col(VOL_COL) <= cal[\"thr_vol\"])\n",
    "                else:\n",
    "                    g = (pl.col(ER_COL) >= cal[\"thr_er\"]) & (pl.col(MOM_COL) <= cal[\"thr_mom\"]) & (pl.col(VOL_COL) <= cal[\"thr_vol\"])\n",
    "                if df_oos.height > 0:\n",
    "                    cov_oos = float(df_oos.select(g.mean()).item())\n",
    "\n",
    "            rows.append({\n",
    "                \"symbol\": sym, \"fold_id\": fid, \"side\": side,\n",
    "                \"scheme\": cal[\"scheme\"],\n",
    "                \"thr_er\": cal[\"thr_er\"], \"thr_mom\": cal[\"thr_mom\"], \"thr_vol\": cal[\"thr_vol\"],\n",
    "                \"cov_is\": cal[\"cov_is\"], \"cov_oos\": cov_oos,\n",
    "                \"n_is\": df_is.height, \"n_oos\": df_oos.height,\n",
    "            })\n",
    "            print(f\"[Celda 06] {sym} fold={fid} {side} :: scheme={cal['scheme']} cov_IS={cal['cov_is']:.3f} cov_OOS={cov_oos:.3f}\")\n",
    "\n",
    "gate_df = pl.DataFrame(rows).sort([\"symbol\", \"fold_id\", \"side\"])\n",
    "gate_df.write_parquet(str(OUT_REGIME), compression=\"zstd\")\n",
    "\n",
    "snap = {\n",
    "    \"created_utc\": _now_utc_iso(),\n",
    "    \"version\": \"v2.0.1\",\n",
    "    \"symbols\": symbols,\n",
    "    \"fold_ids\": [str(f) for f in fold_ids],\n",
    "    \"params\": {\"ER_COL\": ER_COL, \"MOM_COL\": MOM_COL, \"VOL_COL\": VOL_COL, \"Q_SCHEMES\": Q_SCHEMES},\n",
    "    \"bug_fix\": \"SHORT gate calibrado independientemente con percentil negativo de momentum\",\n",
    "}\n",
    "Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, ensure_ascii=False, default=str), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"\\n[Celda 06] OUT: {OUT_REGIME} ({gate_df.height} rows)\")\n",
    "print(f\"[Celda 06] OUT: {OUT_SNAP}\")\n",
    "print(\">>> Celda 06 v2.0.1 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5ae0ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Celda 07 v2.0.1 :: Senales + Ejecucion t+1 + Costos\n",
      "[Celda 07] BNBUSD fold=1 LONG: 30479 trades\n",
      "[Celda 07] BNBUSD fold=1 SHORT: 29975 trades\n",
      "[Celda 07] BNBUSD fold=2 LONG: 35172 trades\n",
      "[Celda 07] BNBUSD fold=2 SHORT: 33627 trades\n",
      "[Celda 07] BNBUSD fold=3 LONG: 40682 trades\n",
      "[Celda 07] BNBUSD fold=3 SHORT: 37459 trades\n",
      "[Celda 07] BNBUSD fold=4 LONG: 45750 trades\n",
      "[Celda 07] BNBUSD fold=4 SHORT: 39866 trades\n",
      "[Celda 07] BNBUSD fold=5 LONG: 52125 trades\n",
      "[Celda 07] BNBUSD fold=5 SHORT: 44683 trades\n",
      "[Celda 07] BNBUSD fold=6 LONG: 57370 trades\n",
      "[Celda 07] BNBUSD fold=6 SHORT: 48356 trades\n",
      "[Celda 07] BNBUSD fold=7 LONG: 61413 trades\n",
      "[Celda 07] BNBUSD fold=7 SHORT: 51858 trades\n",
      "[Celda 07] BNBUSD fold=8 LONG: 67073 trades\n",
      "[Celda 07] BNBUSD fold=8 SHORT: 55839 trades\n",
      "[Celda 07] BNBUSD fold=9 LONG: 73506 trades\n",
      "[Celda 07] BNBUSD fold=9 SHORT: 59774 trades\n",
      "[Celda 07] BNBUSD fold=10 LONG: 77828 trades\n",
      "[Celda 07] BNBUSD fold=10 SHORT: 62265 trades\n",
      "[Celda 07] BTCUSD fold=1 LONG: 18715 trades\n",
      "[Celda 07] BTCUSD fold=1 SHORT: 17775 trades\n",
      "[Celda 07] BTCUSD fold=2 LONG: 23508 trades\n",
      "[Celda 07] BTCUSD fold=2 SHORT: 21381 trades\n",
      "[Celda 07] BTCUSD fold=3 LONG: 30235 trades\n",
      "[Celda 07] BTCUSD fold=3 SHORT: 24826 trades\n",
      "[Celda 07] BTCUSD fold=4 LONG: 34996 trades\n",
      "[Celda 07] BTCUSD fold=4 SHORT: 27498 trades\n",
      "[Celda 07] BTCUSD fold=5 LONG: 40359 trades\n",
      "[Celda 07] BTCUSD fold=5 SHORT: 32898 trades\n",
      "[Celda 07] BTCUSD fold=6 LONG: 45737 trades\n",
      "[Celda 07] BTCUSD fold=6 SHORT: 36195 trades\n",
      "[Celda 07] BTCUSD fold=7 LONG: 50118 trades\n",
      "[Celda 07] BTCUSD fold=7 SHORT: 40195 trades\n",
      "[Celda 07] BTCUSD fold=8 LONG: 55013 trades\n",
      "[Celda 07] BTCUSD fold=8 SHORT: 43067 trades\n",
      "[Celda 07] BTCUSD fold=9 LONG: 60578 trades\n",
      "[Celda 07] BTCUSD fold=9 SHORT: 48224 trades\n",
      "[Celda 07] BTCUSD fold=10 LONG: 65195 trades\n",
      "[Celda 07] BTCUSD fold=10 SHORT: 51805 trades\n",
      "[Celda 07] LVMH fold=1 LONG: 9354 trades\n",
      "[Celda 07] LVMH fold=1 SHORT: 7612 trades\n",
      "[Celda 07] LVMH fold=2 LONG: 9666 trades\n",
      "[Celda 07] LVMH fold=2 SHORT: 8591 trades\n",
      "[Celda 07] LVMH fold=3 LONG: 11140 trades\n",
      "[Celda 07] LVMH fold=3 SHORT: 9335 trades\n",
      "[Celda 07] LVMH fold=4 LONG: 11646 trades\n",
      "[Celda 07] LVMH fold=4 SHORT: 10828 trades\n",
      "[Celda 07] LVMH fold=5 LONG: 13451 trades\n",
      "[Celda 07] LVMH fold=5 SHORT: 12181 trades\n",
      "[Celda 07] LVMH fold=6 LONG: 13017 trades\n",
      "[Celda 07] LVMH fold=6 SHORT: 13661 trades\n",
      "[Celda 07] LVMH fold=7 LONG: 14939 trades\n",
      "[Celda 07] LVMH fold=7 SHORT: 14270 trades\n",
      "[Celda 07] LVMH fold=8 LONG: 14950 trades\n",
      "[Celda 07] LVMH fold=8 SHORT: 15959 trades\n",
      "[Celda 07] LVMH fold=9 LONG: 15926 trades\n",
      "[Celda 07] LVMH fold=9 SHORT: 17265 trades\n",
      "[Celda 07] LVMH fold=10 LONG: 17535 trades\n",
      "[Celda 07] LVMH fold=10 SHORT: 18397 trades\n",
      "[Celda 07] XAUAUD fold=1 LONG: 21854 trades\n",
      "[Celda 07] XAUAUD fold=1 SHORT: 21279 trades\n",
      "[Celda 07] XAUAUD fold=2 LONG: 25359 trades\n",
      "[Celda 07] XAUAUD fold=2 SHORT: 26191 trades\n",
      "[Celda 07] XAUAUD fold=3 LONG: 27184 trades\n",
      "[Celda 07] XAUAUD fold=3 SHORT: 27397 trades\n",
      "[Celda 07] XAUAUD fold=4 LONG: 31779 trades\n",
      "[Celda 07] XAUAUD fold=4 SHORT: 29718 trades\n",
      "[Celda 07] XAUAUD fold=5 LONG: 35850 trades\n",
      "[Celda 07] XAUAUD fold=5 SHORT: 31314 trades\n",
      "[Celda 07] XAUAUD fold=6 LONG: 41387 trades\n",
      "[Celda 07] XAUAUD fold=6 SHORT: 33631 trades\n",
      "[Celda 07] XAUAUD fold=7 LONG: 45408 trades\n",
      "[Celda 07] XAUAUD fold=7 SHORT: 35287 trades\n",
      "[Celda 07] XAUAUD fold=8 LONG: 47455 trades\n",
      "[Celda 07] XAUAUD fold=8 SHORT: 35383 trades\n",
      "[Celda 07] XAUAUD fold=9 LONG: 51619 trades\n",
      "[Celda 07] XAUAUD fold=9 SHORT: 39261 trades\n",
      "[Celda 07] XAUAUD fold=10 LONG: 56582 trades\n",
      "[Celda 07] XAUAUD fold=10 SHORT: 40321 trades\n",
      "\n",
      "[Celda 07] OUT: C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\signals_all_v2.parquet (2737400 rows)\n",
      ">>> Celda 07 v2.0.1 :: OK\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# Celda 07 v2.0.1 — Senales TREND + Ejecucion t+1 + Costos (BASE/STRESS)\n",
    "# Entry en open(t+1), exit en open(t+2). Segmento IS/OOS por entry_time.\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 07 v2.0.1 :: Senales + Ejecucion t+1 + Costos\")\n",
    "\n",
    "if \"RUN\" not in globals():\n",
    "    raise RuntimeError(\"[Celda 07] ERROR: RUN no existe.\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "\n",
    "FEATURES_PATH = ARTIFACTS[\"features_m5\"]\n",
    "WFO_PATH = ARTIFACTS[\"wfo_folds\"]\n",
    "REGIME_PATH = ARTIFACTS[\"regime_params_by_fold\"]\n",
    "COST_SNAP_PATH = ARTIFACTS.get(\"cost_model_snapshot\", RUN_DIR / \"cost_model_snapshot_v2.json\")\n",
    "\n",
    "for p, label in [(FEATURES_PATH, \"features\"), (WFO_PATH, \"wfo_folds\"), (REGIME_PATH, \"regime_params\")]:\n",
    "    if not Path(p).exists():\n",
    "        raise RuntimeError(f\"[Celda 07] ERROR: falta {label}: {p}\")\n",
    "\n",
    "OUT_SIGNALS = ARTIFACTS.get(\"signals_all\", RUN_DIR / \"signals_all_v2.parquet\")\n",
    "OUT_SNAP = ARTIFACTS.get(\"signals_snapshot\", RUN_DIR / \"signals_snapshot_v2.json\")\n",
    "\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "# ---------- Parametros ----------\n",
    "ER_COL = \"er_288\"\n",
    "MOM_COL = \"mom_bps_288\"\n",
    "VOL_COL = \"vol_bps_288\"\n",
    "\n",
    "# ---------- Load ----------\n",
    "df_feat = pl.read_parquet(FEATURES_PATH)\n",
    "df_folds = pl.read_parquet(WFO_PATH)\n",
    "df_regime = pl.read_parquet(REGIME_PATH)\n",
    "cost_snap = json.loads(Path(COST_SNAP_PATH).read_text(encoding=\"utf-8\"))\n",
    "costs_by_sym = cost_snap.get(\"costs_by_symbol\", {})\n",
    "\n",
    "symbols = df_feat.get_column(\"symbol\").unique().sort().to_list()\n",
    "fold_ids = df_folds.get_column(\"fold_id\").unique().sort().to_list()\n",
    "\n",
    "all_trades = []\n",
    "for sym in symbols:\n",
    "    df_sym = df_feat.filter(pl.col(\"symbol\") == sym).sort(\"time_utc\")\n",
    "    cinfo = costs_by_sym.get(sym, {})\n",
    "    cost_base_bps = float(cinfo.get(\"cost_base_bps\", cinfo.get(\"COST_BASE_BPS\", 3.0)))\n",
    "    cost_stress_bps = float(cinfo.get(\"cost_stress_bps\", cinfo.get(\"COST_STRESS_BPS\", 6.0)))\n",
    "    cost_base_rt = cost_base_bps / 10_000\n",
    "    cost_stress_rt = cost_stress_bps / 10_000\n",
    "\n",
    "    for fid in fold_ids:\n",
    "        fold_row = df_folds.filter(pl.col(\"fold_id\") == fid).row(0, named=True)\n",
    "        is_s, is_e = fold_row[\"is_start_utc\"], fold_row[\"is_end_utc\"]\n",
    "        oos_s, oos_e = fold_row[\"oos_start_utc\"], fold_row[\"oos_end_utc\"]\n",
    "\n",
    "        for side in (\"LONG\", \"SHORT\"):\n",
    "            rg = df_regime.filter(\n",
    "                (pl.col(\"symbol\") == sym) & (pl.col(\"fold_id\") == fid) & (pl.col(\"side\") == side)\n",
    "            )\n",
    "            if rg.is_empty():\n",
    "                continue\n",
    "            rg_row = rg.row(0, named=True)\n",
    "            if rg_row[\"thr_er\"] is None:\n",
    "                continue\n",
    "\n",
    "            thr_er = float(rg_row[\"thr_er\"])\n",
    "            thr_mom = float(rg_row[\"thr_mom\"])\n",
    "            thr_vol = float(rg_row[\"thr_vol\"])\n",
    "\n",
    "            if side == \"LONG\":\n",
    "                gate_expr = (\n",
    "                    (pl.col(ER_COL) >= thr_er) &\n",
    "                    (pl.col(MOM_COL) >= thr_mom) &\n",
    "                    (pl.col(VOL_COL) <= thr_vol)\n",
    "                )\n",
    "            else:\n",
    "                gate_expr = (\n",
    "                    (pl.col(ER_COL) >= thr_er) &\n",
    "                    (pl.col(MOM_COL) <= thr_mom) &\n",
    "                    (pl.col(VOL_COL) <= thr_vol)\n",
    "                )\n",
    "\n",
    "            dfx = (\n",
    "                df_sym\n",
    "                .with_columns(gate_expr.alias(\"signal_gate\"))\n",
    "                .with_columns([\n",
    "                    pl.col(\"time_utc\").shift(-1).alias(\"entry_time\"),\n",
    "                    pl.col(\"time_utc\").shift(-2).alias(\"exit_time\"),\n",
    "                    pl.col(\"open\").shift(-1).alias(\"entry_price\"),\n",
    "                    pl.col(\"open\").shift(-2).alias(\"exit_price\"),\n",
    "                ])\n",
    "                .filter(pl.col(\"signal_gate\"))\n",
    "                .filter(pl.col(\"entry_price\").is_not_null() & pl.col(\"exit_price\").is_not_null())\n",
    "                .filter((pl.col(\"entry_price\") > 0) & (pl.col(\"exit_price\") > 0))\n",
    "            )\n",
    "\n",
    "            # Segment by entry_time\n",
    "            seg_expr = (\n",
    "                pl.when((pl.col(\"entry_time\") >= is_s) & (pl.col(\"entry_time\") <= is_e)).then(pl.lit(\"IS\"))\n",
    "                .when((pl.col(\"entry_time\") >= oos_s) & (pl.col(\"entry_time\") <= oos_e)).then(pl.lit(\"OOS\"))\n",
    "                .otherwise(pl.lit(None))\n",
    "            )\n",
    "\n",
    "            sign = 1.0 if side == \"LONG\" else -1.0\n",
    "            dfx = (\n",
    "                dfx\n",
    "                .with_columns([\n",
    "                    seg_expr.alias(\"segment\"),\n",
    "                    pl.lit(sym).alias(\"symbol_col\"),\n",
    "                    pl.lit(fid).alias(\"fold_id_col\"),\n",
    "                    pl.lit(side).alias(\"side_col\"),\n",
    "                    (sign * (pl.col(\"exit_price\") / pl.col(\"entry_price\") - 1.0)).alias(\"gross_ret\"),\n",
    "                ])\n",
    "                .filter(pl.col(\"segment\").is_not_null())\n",
    "                .with_columns([\n",
    "                    (pl.col(\"gross_ret\") - cost_base_rt).alias(\"net_ret_base\"),\n",
    "                    (pl.col(\"gross_ret\") - cost_stress_rt).alias(\"net_ret_stress\"),\n",
    "                ])\n",
    "                .select([\n",
    "                    pl.col(\"symbol_col\").alias(\"symbol\"),\n",
    "                    pl.col(\"fold_id_col\").alias(\"fold_id\"),\n",
    "                    \"segment\",\n",
    "                    pl.col(\"side_col\").alias(\"side\"),\n",
    "                    pl.col(\"time_utc\").alias(\"signal_time\"),\n",
    "                    \"entry_time\", \"exit_time\",\n",
    "                    \"entry_price\", \"exit_price\",\n",
    "                    \"gross_ret\", \"net_ret_base\", \"net_ret_stress\",\n",
    "                    ER_COL, MOM_COL, VOL_COL,\n",
    "                ])\n",
    "            )\n",
    "            if dfx.height > 0:\n",
    "                all_trades.append(dfx)\n",
    "                print(f\"[Celda 07] {sym} fold={fid} {side}: {dfx.height} trades\")\n",
    "\n",
    "if not all_trades:\n",
    "    raise RuntimeError(\"[Celda 07] GATE FAIL: 0 trades generados.\")\n",
    "\n",
    "signals_df = pl.concat(all_trades, how=\"vertical_relaxed\").sort([\"symbol\", \"fold_id\", \"signal_time\"])\n",
    "signals_df.write_parquet(str(OUT_SIGNALS), compression=\"zstd\")\n",
    "\n",
    "snap = {\"created_utc\": _now_utc_iso(), \"version\": \"v2.0.1\", \"n_trades\": signals_df.height,\n",
    "        \"symbols\": symbols, \"sides\": [\"LONG\", \"SHORT\"], \"convention\": \"entry=open(t+1), exit=open(t+2)\"}\n",
    "Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, ensure_ascii=False, default=str), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"\\n[Celda 07] OUT: {OUT_SIGNALS} ({signals_df.height} rows)\")\n",
    "print(\">>> Celda 07 v2.0.1 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e61335a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Celda 08 v2.0.1 :: QA Timing Trades\n",
      "shape: (8, 13)\n",
      "┌────────┬─────────┬──────────┬────────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
      "│ symbol ┆ segment ┆ n_trades ┆ dt_entry_m ┆ … ┆ dt_hold_ma ┆ share_hold ┆ share_hold ┆ share_hold │\n",
      "│ ---    ┆ ---     ┆ ---      ┆ edian_s    ┆   ┆ x_s        ┆ _gt_900s   ┆ _gt_3600s  ┆ _gt_86400s │\n",
      "│ str    ┆ str     ┆ u32      ┆ ---        ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n",
      "│        ┆         ┆          ┆ f64        ┆   ┆ i64        ┆ f64        ┆ f64        ┆ f64        │\n",
      "╞════════╪═════════╪══════════╪════════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
      "│ BNBUSD ┆ IS      ┆ 916838   ┆ 300.0      ┆ … ┆ 125100     ┆ 0.000215   ┆ 0.000149   ┆ 0.000002   │\n",
      "│ BNBUSD ┆ OOS     ┆ 88262    ┆ 300.0      ┆ … ┆ 125100     ┆ 0.000351   ┆ 0.000295   ┆ 0.000023   │\n",
      "│ BTCUSD ┆ IS      ┆ 676767   ┆ 300.0      ┆ … ┆ 90900      ┆ 0.000598   ┆ 0.000585   ┆ 0.000001   │\n",
      "│ BTCUSD ┆ OOS     ┆ 91551    ┆ 300.0      ┆ … ┆ 90900      ┆ 0.000721   ┆ 0.000699   ┆ 0.000022   │\n",
      "│ LVMH   ┆ IS      ┆ 234784   ┆ 300.0      ┆ … ┆ 401700     ┆ 0.010103   ┆ 0.010022   ┆ 0.002125   │\n",
      "│ LVMH   ┆ OOS     ┆ 24939    ┆ 300.0      ┆ … ┆ 398400     ┆ 0.009623   ┆ 0.009583   ┆ 0.001965   │\n",
      "│ XAUAUD ┆ IS      ┆ 641904   ┆ 300.0      ┆ … ┆ 264000     ┆ 0.003723   ┆ 0.003712   ┆ 0.000821   │\n",
      "│ XAUAUD ┆ OOS     ┆ 62355    ┆ 300.0      ┆ … ┆ 264000     ┆ 0.003689   ┆ 0.003673   ┆ 0.00093    │\n",
      "└────────┴─────────┴──────────┴────────────┴───┴────────────┴────────────┴────────────┴────────────┘\n",
      "\n",
      "[Celda 08] OUT: C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\qa_timing_v2.parquet (8 rows)\n",
      ">>> Celda 08 v2.0.1 :: OK\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# Celda 08 v2.0.1 — QA Timing Trades (gap-aware diagnostics)\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 08 v2.0.1 :: QA Timing Trades\")\n",
    "\n",
    "if \"RUN\" not in globals():\n",
    "    raise RuntimeError(\"[Celda 08] ERROR: RUN no existe.\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "\n",
    "SIGNALS_PATH = ARTIFACTS.get(\"signals_all\", RUN_DIR / \"signals_all_v2.parquet\")\n",
    "if not SIGNALS_PATH.exists():\n",
    "    raise RuntimeError(f\"[Celda 08] ERROR: falta signals: {SIGNALS_PATH}\")\n",
    "\n",
    "OUT_QA = ARTIFACTS.get(\"qa_timing\", RUN_DIR / \"qa_timing_v2.parquet\")\n",
    "\n",
    "df = pl.read_parquet(SIGNALS_PATH)\n",
    "\n",
    "df = df.with_columns([\n",
    "    ((pl.col(\"entry_time\") - pl.col(\"signal_time\")).dt.total_seconds()).alias(\"dt_signal_to_entry_s\"),\n",
    "    ((pl.col(\"exit_time\") - pl.col(\"entry_time\")).dt.total_seconds()).alias(\"dt_hold_s\"),\n",
    "])\n",
    "\n",
    "THRESHOLDS = [900, 3600, 86400]\n",
    "\n",
    "qa = (\n",
    "    df.group_by([\"symbol\", \"segment\"])\n",
    "    .agg([\n",
    "        pl.len().alias(\"n_trades\"),\n",
    "        pl.col(\"dt_signal_to_entry_s\").median().alias(\"dt_entry_median_s\"),\n",
    "        pl.col(\"dt_signal_to_entry_s\").quantile(0.90, interpolation=\"nearest\").alias(\"dt_entry_p90_s\"),\n",
    "        pl.col(\"dt_signal_to_entry_s\").max().alias(\"dt_entry_max_s\"),\n",
    "        pl.col(\"dt_hold_s\").median().alias(\"dt_hold_median_s\"),\n",
    "        pl.col(\"dt_hold_s\").quantile(0.90, interpolation=\"nearest\").alias(\"dt_hold_p90_s\"),\n",
    "        pl.col(\"dt_hold_s\").quantile(0.99, interpolation=\"nearest\").alias(\"dt_hold_p99_s\"),\n",
    "        pl.col(\"dt_hold_s\").max().alias(\"dt_hold_max_s\"),\n",
    "        *[(pl.col(\"dt_hold_s\") > t).mean().alias(f\"share_hold_gt_{t}s\") for t in THRESHOLDS],\n",
    "    ])\n",
    "    .sort([\"symbol\", \"segment\"])\n",
    ")\n",
    "\n",
    "qa.write_parquet(str(OUT_QA), compression=\"zstd\")\n",
    "print(qa)\n",
    "print(f\"\\n[Celda 08] OUT: {OUT_QA} ({qa.height} rows)\")\n",
    "print(\">>> Celda 08 v2.0.1 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62f367d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Celda 09 v2.0.1 :: Alpha Multi-Horizon Report\n",
      "\n",
      "[Celda 09] OUT: C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\alpha_multi_horizon_report_v2.parquet (1280 rows)\n",
      ">>> Celda 09 v2.0.1 :: OK\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# Celda 09 v2.0.1 — Alpha Multi-Horizon Report (LONG/SHORT) + Costs + Mon-Fri\n",
    "# Horizontes: [1, 3, 6, 12, 24, 48, 96, 288] bars\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json, math\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 09 v2.0.1 :: Alpha Multi-Horizon Report\")\n",
    "\n",
    "if \"RUN\" not in globals():\n",
    "    raise RuntimeError(\"[Celda 09] ERROR: RUN no existe.\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "\n",
    "FEATURES_PATH = ARTIFACTS[\"features_m5\"]\n",
    "WFO_PATH = ARTIFACTS[\"wfo_folds\"]\n",
    "REGIME_PATH = ARTIFACTS[\"regime_params_by_fold\"]\n",
    "COST_SNAP_PATH = ARTIFACTS.get(\"cost_model_snapshot\", RUN_DIR / \"cost_model_snapshot_v2.json\")\n",
    "\n",
    "OUT_ALPHA = ARTIFACTS.get(\"alpha_multi_horizon_report\", RUN_DIR / \"alpha_multi_horizon_report_v2.parquet\")\n",
    "OUT_SNAP = ARTIFACTS.get(\"alpha_multi_horizon_snapshot\", RUN_DIR / \"alpha_multi_horizon_snapshot_v2.json\")\n",
    "\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "HORIZONS = [1, 3, 6, 12, 24, 48, 96, 288]\n",
    "ER_COL = \"er_288\"\n",
    "MOM_COL = \"mom_bps_288\"\n",
    "VOL_COL = \"vol_bps_288\"\n",
    "\n",
    "df_feat = pl.read_parquet(FEATURES_PATH)\n",
    "df_folds = pl.read_parquet(WFO_PATH)\n",
    "df_regime = pl.read_parquet(REGIME_PATH)\n",
    "cost_snap = json.loads(Path(COST_SNAP_PATH).read_text(encoding=\"utf-8\"))\n",
    "costs_by_sym = cost_snap.get(\"costs_by_symbol\", {})\n",
    "\n",
    "symbols = df_feat.get_column(\"symbol\").unique().sort().to_list()\n",
    "fold_ids = df_folds.get_column(\"fold_id\").unique().sort().to_list()\n",
    "\n",
    "rows = []\n",
    "for sym in symbols:\n",
    "    df_sym = df_feat.filter(pl.col(\"symbol\") == sym).sort(\"time_utc\")\n",
    "    cinfo = costs_by_sym.get(sym, {})\n",
    "    cost_base_rt = float(cinfo.get(\"cost_base_bps\", cinfo.get(\"COST_BASE_BPS\", 3.0))) / 10_000\n",
    "    cost_stress_rt = float(cinfo.get(\"cost_stress_bps\", cinfo.get(\"COST_STRESS_BPS\", 6.0))) / 10_000\n",
    "\n",
    "    # Precompute forward returns for all horizons\n",
    "    fwd_cols = []\n",
    "    for h in HORIZONS:\n",
    "        df_sym = df_sym.with_columns(\n",
    "            (pl.col(\"close\").shift(-h) / pl.col(\"close\") - 1.0).alias(f\"fwd_ret_{h}\")\n",
    "        )\n",
    "\n",
    "    # weekday filter (Mon-Fri)\n",
    "    df_sym = df_sym.with_columns(pl.col(\"time_utc\").dt.weekday().alias(\"_dow\"))\n",
    "    # Polars weekday: 1=Mon..7=Sun\n",
    "    df_sym = df_sym.filter(pl.col(\"_dow\") <= 5)\n",
    "\n",
    "    for fid in fold_ids:\n",
    "        fold_row = df_folds.filter(pl.col(\"fold_id\") == fid).row(0, named=True)\n",
    "        is_s, is_e = fold_row[\"is_start_utc\"], fold_row[\"is_end_utc\"]\n",
    "        oos_s, oos_e = fold_row[\"oos_start_utc\"], fold_row[\"oos_end_utc\"]\n",
    "\n",
    "        for side in (\"LONG\", \"SHORT\"):\n",
    "            rg = df_regime.filter(\n",
    "                (pl.col(\"symbol\") == sym) & (pl.col(\"fold_id\") == fid) & (pl.col(\"side\") == side)\n",
    "            )\n",
    "            if rg.is_empty() or rg.row(0, named=True)[\"thr_er\"] is None:\n",
    "                continue\n",
    "            rg_row = rg.row(0, named=True)\n",
    "            thr_er, thr_mom, thr_vol = float(rg_row[\"thr_er\"]), float(rg_row[\"thr_mom\"]), float(rg_row[\"thr_vol\"])\n",
    "\n",
    "            if side == \"LONG\":\n",
    "                gate = (pl.col(ER_COL) >= thr_er) & (pl.col(MOM_COL) >= thr_mom) & (pl.col(VOL_COL) <= thr_vol)\n",
    "            else:\n",
    "                gate = (pl.col(ER_COL) >= thr_er) & (pl.col(MOM_COL) <= thr_mom) & (pl.col(VOL_COL) <= thr_vol)\n",
    "\n",
    "            for seg_name, seg_s, seg_e in [(\"IS\", is_s, is_e), (\"OOS\", oos_s, oos_e)]:\n",
    "                df_seg = df_sym.filter(\n",
    "                    (pl.col(\"time_utc\") >= seg_s) & (pl.col(\"time_utc\") <= seg_e)\n",
    "                ).filter(gate)\n",
    "\n",
    "                if df_seg.height == 0:\n",
    "                    continue\n",
    "\n",
    "                for h in HORIZONS:\n",
    "                    col = f\"fwd_ret_{h}\"\n",
    "                    vals = df_seg.get_column(col).drop_nulls()\n",
    "                    if vals.len() < 5:\n",
    "                        continue\n",
    "                    sign = 1.0 if side == \"LONG\" else -1.0\n",
    "                    rets = vals.to_list()\n",
    "                    rets_signed = [sign * r for r in rets]\n",
    "                    n = len(rets_signed)\n",
    "                    mean_r = sum(rets_signed) / n\n",
    "                    std_r = (sum((r - mean_r)**2 for r in rets_signed) / max(1, n - 1)) ** 0.5\n",
    "                    sharpe = mean_r / std_r if std_r > 1e-12 else 0.0\n",
    "                    wr = sum(1 for r in rets_signed if r > 0) / n\n",
    "\n",
    "                    rows.append({\n",
    "                        \"symbol\": sym, \"fold_id\": fid, \"side\": side, \"segment\": seg_name,\n",
    "                        \"horizon_bars\": h, \"n_trades\": n,\n",
    "                        \"gross_mean\": mean_r, \"gross_std\": std_r,\n",
    "                        \"net_base_mean\": mean_r - cost_base_rt,\n",
    "                        \"net_stress_mean\": mean_r - cost_stress_rt,\n",
    "                        \"sharpe_like\": sharpe, \"win_rate\": wr,\n",
    "                    })\n",
    "\n",
    "alpha_df = pl.DataFrame(rows).sort([\"symbol\", \"fold_id\", \"side\", \"segment\", \"horizon_bars\"])\n",
    "alpha_df.write_parquet(str(OUT_ALPHA), compression=\"zstd\")\n",
    "\n",
    "snap = {\"created_utc\": _now_utc_iso(), \"version\": \"v2.0.1\", \"horizons\": HORIZONS,\n",
    "        \"n_rows\": alpha_df.height, \"symbols\": symbols}\n",
    "Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, ensure_ascii=False, default=str), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"\\n[Celda 09] OUT: {OUT_ALPHA} ({alpha_df.height} rows)\")\n",
    "print(\">>> Celda 09 v2.0.1 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be93fd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n# Celda 10 v2.2.0 — Backtest Engine (TREND, M5)\n# CAMBIO v2.2.0: Weekend gate valida bar de EJECUCIÓN (idx+1), no solo señal (idx).\n# CAMBIO v2.1.0: _simulate() acepta kwargs (sl_atr, tp_atr, trail_atr, time_stop,\n#   min_hold) para permitir tuning real en Celda 14.\n# BUG FIXES previos: Trail>SL, SHORT gate, dedup keep=\"last\"\n# ======================================================================================\n\nfrom __future__ import annotations\nimport json, math\nfrom pathlib import Path\nfrom datetime import datetime, timezone\nfrom typing import Dict, List, Optional\nimport polars as pl\n\nprint(\">>> Celda 10 v2.2.0 :: Backtest Engine (TREND) [weekend exec-bar fix]\")\n\nif \"RUN\" not in globals():\n    raise RuntimeError(\"[Celda 10] ERROR: RUN no existe.\")\n\nRUN_DIR: Path = RUN[\"RUN_DIR\"]\nARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n\nFEATURES_PATH = ARTIFACTS[\"features_m5\"]\nWFO_PATH = ARTIFACTS[\"wfo_folds\"]\nREGIME_PATH = ARTIFACTS[\"regime_params_by_fold\"]\nCOST_SNAP_PATH = ARTIFACTS.get(\"cost_model_snapshot\", RUN_DIR / \"cost_model_snapshot_v2.json\")\n\nOUT_TRADES = ARTIFACTS.get(\"trades_engine\", RUN_DIR / \"trades_engine_v2.parquet\")\nOUT_SUMMARY = ARTIFACTS.get(\"summary_engine\", RUN_DIR / \"summary_engine_v2.parquet\")\n\ndef _now_utc_iso() -> str:\n    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n\n# ---------- Parametros por defecto ----------\nSL_ATR     = 3.0\nTP_ATR     = 14.0\nTRAIL_ATR  = 0\nTIME_STOP  = 1440\nENTRY_CONFIRM = 28\nEXIT_GATE_OFF = 72\nMIN_HOLD   = 72\nCOOLDOWN   = 48\nMON_FRI    = True\nEMA_FILTER = True\nEMA_FAST   = 48\nEMA_SLOW   = 288\nRISK_PER_TRADE = 0.01\nMIN_POS_SIZE = 0.25\nMAX_POS_SIZE = 3.00\n\nER_COL = \"er_288\"\nMOM_COL = \"mom_bps_288\"\nVOL_COL = \"vol_bps_288\"\nATR_COL = \"atr_bps_96\"\n\nprint(f\"[Celda 10] SL_ATR={SL_ATR} TP_ATR={TP_ATR} TRAIL_ATR={TRAIL_ATR} TIME_STOP={TIME_STOP}\")\n\n# ---------- Load ----------\ndf_feat = pl.read_parquet(FEATURES_PATH)\ndf_folds = pl.read_parquet(WFO_PATH)\ndf_regime = pl.read_parquet(REGIME_PATH)\ncost_snap = json.loads(Path(COST_SNAP_PATH).read_text(encoding=\"utf-8\"))\ncosts_by_sym = {e[\"symbol\"]: e for e in cost_snap.get(\"per_symbol\", [])}\n\nsymbols = df_feat.get_column(\"symbol\").unique().sort().to_list()\nfold_ids = df_folds.get_column(\"fold_id\").unique().sort().to_list()\n\n# ---------- Helpers ----------\ndef _is_finite(x) -> bool:\n    if x is None:\n        return False\n    try:\n        return math.isfinite(float(x))\n    except Exception:\n        return False\n\ndef _simulate(sym, df_j, fold_row, thr_er, thr_mom_long, thr_mom_short, thr_vol,\n              cost_base_dec, cost_stress_dec,\n              *, sl_atr=None, tp_atr=None, trail_atr=None, time_stop=None, min_hold=None, entry_confirm_bars=None):\n    \"\"\"Bar-by-bar simulation for one symbol/fold. Accepts optional engine param overrides.\"\"\"\n    # Parametros locales (overridable por tuning)\n    _SL    = sl_atr    if sl_atr    is not None else SL_ATR\n    _TP    = tp_atr    if tp_atr    is not None else TP_ATR\n    _TRAIL = trail_atr if trail_atr is not None else TRAIL_ATR\n    _TRAIL = None if _TRAIL == 0 else _TRAIL   # TRAIL=0 -> sin trailing stop\n    _TSTOP = time_stop if time_stop is not None else TIME_STOP\n    _MHOLD = min_hold  if min_hold  is not None else MIN_HOLD\n    _EC    = entry_confirm_bars if entry_confirm_bars is not None else ENTRY_CONFIRM\n\n    is_s = fold_row[\"is_start_utc\"]\n    is_e = fold_row[\"is_end_utc\"]\n    oos_s = fold_row[\"oos_start_utc\"]\n    oos_e = fold_row[\"oos_end_utc\"]\n    fid = fold_row[\"fold_id\"]\n\n    df_j = df_j.unique(subset=[\"time_utc\"], keep=\"last\").sort(\"time_utc\")\n\n    # EMA filter\n    if EMA_FILTER:\n        df_j = df_j.with_columns([\n            pl.col(\"close\").ewm_mean(span=EMA_FAST, adjust=False).alias(\"_ema_f\"),\n            pl.col(\"close\").ewm_mean(span=EMA_SLOW, adjust=False).alias(\"_ema_s\"),\n        ])\n\n    # Gates\n    long_gate = (pl.col(ER_COL) >= thr_er) & (pl.col(MOM_COL) >= thr_mom_long) & (pl.col(VOL_COL) <= thr_vol)\n    short_gate = (pl.col(ER_COL) >= thr_er) & (pl.col(MOM_COL) <= thr_mom_short) & (pl.col(VOL_COL) <= thr_vol)\n    if EMA_FILTER:\n        long_gate = long_gate & (pl.col(\"_ema_f\") > pl.col(\"_ema_s\"))\n        short_gate = short_gate & (pl.col(\"_ema_f\") < pl.col(\"_ema_s\"))\n\n    df_j = df_j.with_columns([long_gate.alias(\"_gL\"), short_gate.alias(\"_gS\")])\n    df_j = df_j.with_columns(pl.col(\"time_utc\").dt.weekday().alias(\"_dow\"))\n    df_j = df_j.with_columns((pl.col(\"_dow\") >= 6).alias(\"_is_wk\"))\n\n    # Confirm\n    df_j = df_j.with_columns([\n        (pl.col(\"_gL\").cast(pl.Int8).rolling_sum(_EC, min_samples=_EC).eq(_EC))\n            .fill_null(False).alias(\"_confL\"),\n        (pl.col(\"_gS\").cast(pl.Int8).rolling_sum(_EC, min_samples=_EC).eq(_EC))\n            .fill_null(False).alias(\"_confS\"),\n    ])\n\n    # Extract lists\n    t_list   = df_j.get_column(\"time_utc\").to_list()\n    o_list   = df_j.get_column(\"open\").to_list()\n    h_list   = df_j.get_column(\"high\").to_list()\n    l_list   = df_j.get_column(\"low\").to_list()\n    c_list   = df_j.get_column(\"close\").to_list()\n    atr_list = df_j.get_column(ATR_COL).to_list() if ATR_COL in df_j.columns else [None]*df_j.height\n    gL_list  = df_j.get_column(\"_gL\").to_list()\n    gS_list  = df_j.get_column(\"_gS\").to_list()\n    cfL_list = df_j.get_column(\"_confL\").to_list()\n    cfS_list = df_j.get_column(\"_confS\").to_list()\n    wk_list  = df_j.get_column(\"_is_wk\").to_list()\n\n    n = len(t_list)\n    trades = []\n\n    pos = 0; side_str = None; entry_idx = None; entry_price = None\n    stop = None; tp_price = None; trail_stop = None; best_price = None\n    sl_dist = None; trail_dist = None; pos_size = 1.0\n    gate_off_streak = 0; cooldown_cnt = 0\n\n    def _seg(et):\n        if is_s <= et <= is_e: return \"IS\"\n        if oos_s <= et <= oos_e: return \"OOS\"\n        return None\n\n    for idx in range(n):\n        # --- EXIT LOGIC ---\n        if pos != 0 and entry_idx is not None:\n            bars_held = idx - entry_idx\n            gn = bool(gL_list[idx]) if pos == 1 else bool(gS_list[idx])\n            gate_off_streak = 0 if gn else gate_off_streak + 1\n\n            hi = float(h_list[idx]) if _is_finite(h_list[idx]) else float(c_list[idx])\n            lo = float(l_list[idx]) if _is_finite(l_list[idx]) else float(c_list[idx])\n\n            exit_reason = None; exit_price = None\n\n            if pos == 1:\n                if best_price is None: best_price = float(entry_price)\n                best_price = max(best_price, hi)\n                if trail_dist is not None:\n                    ts = best_price - trail_dist\n                    trail_stop = ts if trail_stop is None else max(trail_stop, ts)\n                if stop is not None and lo <= stop:\n                    exit_reason, exit_price = \"SL\", stop\n                elif trail_stop is not None and lo <= trail_stop:\n                    exit_reason, exit_price = \"TRAIL\", trail_stop\n                elif tp_price is not None and hi >= tp_price:\n                    exit_reason, exit_price = \"TP\", tp_price\n            else:\n                if best_price is None: best_price = float(entry_price)\n                best_price = min(best_price, lo)\n                if trail_dist is not None:\n                    ts = best_price + trail_dist\n                    trail_stop = ts if trail_stop is None else min(trail_stop, ts)\n                if stop is not None and hi >= stop:\n                    exit_reason, exit_price = \"SL\", stop\n                elif trail_stop is not None and hi >= trail_stop:\n                    exit_reason, exit_price = \"TRAIL\", trail_stop\n                elif tp_price is not None and lo <= tp_price:\n                    exit_reason, exit_price = \"TP\", tp_price\n\n            if exit_reason is None and bars_held >= _TSTOP:\n                exit_reason, exit_price = \"TIME\", float(c_list[idx])\n            if exit_reason is None and bars_held >= _MHOLD and gate_off_streak >= EXIT_GATE_OFF:\n                exit_reason, exit_price = \"REGIME_OFF\", float(c_list[idx])\n            if exit_reason is None and MON_FRI and bool(wk_list[idx]):\n                exit_reason, exit_price = \"WEEKEND\", float(c_list[idx])\n\n            if exit_reason is not None:\n                sign = 1.0 if pos == 1 else -1.0\n                gross_pnl = sign * (exit_price / entry_price - 1.0)\n                seg = _seg(t_list[entry_idx])\n                trades.append({\n                    \"symbol\": sym, \"fold_id\": fid, \"segment\": seg,\n                    \"side\": \"LONG\" if pos == 1 else \"SHORT\",\n                    \"signal_time_utc\": t_list[entry_idx],\n                    \"entry_time_utc\": t_list[min(entry_idx + 1, n - 1)],\n                    \"exit_time_utc\": t_list[idx],\n                    \"entry_price\": entry_price, \"exit_price\": exit_price,\n                    \"gross_pnl\": gross_pnl,\n                    \"net_pnl_base\": gross_pnl - cost_base_dec,\n                    \"net_pnl_stress\": gross_pnl - cost_stress_dec,\n                    \"hold_bars\": bars_held, \"exit_reason\": exit_reason,\n                    \"pos_size\": pos_size,\n                })\n                pos = 0; side_str = None; entry_idx = None; entry_price = None\n                stop = None; tp_price = None; trail_stop = None; best_price = None\n                cooldown_cnt = COOLDOWN\n                continue\n\n        # --- COOLDOWN ---\n        if cooldown_cnt > 0:\n            cooldown_cnt -= 1\n            continue\n\n        # --- ENTRY LOGIC ---\n        if pos == 0 and idx < n - 2:\n            if MON_FRI and bool(wk_list[idx]):\n                continue\n            # v2.2.0: también validar bar de ejecución (idx+1)\n            exec_i = min(idx + 1, n - 1)\n            if MON_FRI and bool(wk_list[exec_i]):\n                continue\n\n            atr_val = float(atr_list[idx]) / 10_000 * float(c_list[idx]) if _is_finite(atr_list[idx]) else float(c_list[idx]) * 0.005\n            if atr_val <= 0:\n                continue\n\n            # LONG entry\n            if bool(cfL_list[idx]):\n                entry_price = float(o_list[idx + 1]) if _is_finite(o_list[idx + 1]) else float(c_list[idx])\n                sl_dist = _SL * atr_val\n                trail_dist = _TRAIL * atr_val if _TRAIL is not None else None\n                stop = entry_price - sl_dist\n                tp_price = entry_price + _TP * atr_val\n                trail_stop = None; best_price = entry_price\n                pos_size = min(MAX_POS_SIZE, max(MIN_POS_SIZE, RISK_PER_TRADE / (sl_dist / entry_price)))\n                pos = 1; side_str = \"LONG\"; entry_idx = idx\n                gate_off_streak = 0\n            elif bool(cfS_list[idx]):\n                entry_price = float(o_list[idx + 1]) if _is_finite(o_list[idx + 1]) else float(c_list[idx])\n                sl_dist = _SL * atr_val\n                trail_dist = _TRAIL * atr_val if _TRAIL is not None else None\n                stop = entry_price + sl_dist\n                tp_price = entry_price - _TP * atr_val\n                trail_stop = None; best_price = entry_price\n                pos_size = min(MAX_POS_SIZE, max(MIN_POS_SIZE, RISK_PER_TRADE / (sl_dist / entry_price)))\n                pos = -1; side_str = \"SHORT\"; entry_idx = idx\n                gate_off_streak = 0\n\n    return trades\n\n# ---------- Main ----------\nall_trades = []\nfor sym in symbols:\n    df_sym = df_feat.filter(pl.col(\"symbol\") == sym).sort(\"time_utc\")\n    cinfo = costs_by_sym.get(sym, {})\n    cost_base_bps = float(cinfo.get(\"base_cost_bps\", 8.0))\n    cost_stress_bps = float(cinfo.get(\"stress_cost_bps\", 16.0))\n    cost_base_dec = cost_base_bps / 10_000\n    cost_stress_dec = cost_stress_bps / 10_000\n    print(f\"  [{sym}] cost_base={cost_base_bps:.1f}bps, cost_stress={cost_stress_bps:.1f}bps \"\n          f\"(from={'snapshot' if cinfo else 'default'})\")\n\n    for fid in fold_ids:\n        fold_row = df_folds.filter(pl.col(\"fold_id\") == fid).row(0, named=True)\n\n        rg_long = df_regime.filter(\n            (pl.col(\"symbol\") == sym) & (pl.col(\"fold_id\") == fid) & (pl.col(\"side\") == \"LONG\")\n        )\n        rg_short = df_regime.filter(\n            (pl.col(\"symbol\") == sym) & (pl.col(\"fold_id\") == fid) & (pl.col(\"side\") == \"SHORT\")\n        )\n\n        thr_er = None; thr_mom_long = 0.0; thr_mom_short = 0.0; thr_vol = None\n        if not rg_long.is_empty():\n            rl = rg_long.row(0, named=True)\n            thr_er = rl[\"thr_er\"]; thr_mom_long = rl[\"thr_mom\"]; thr_vol = rl[\"thr_vol\"]\n        if not rg_short.is_empty():\n            rs = rg_short.row(0, named=True)\n            thr_mom_short = rs[\"thr_mom\"]\n            if thr_er is None: thr_er = rs[\"thr_er\"]\n            if thr_vol is None: thr_vol = rs[\"thr_vol\"]\n\n        if thr_er is None:\n            continue\n\n        trades = _simulate(sym, df_sym, fold_row,\n                           float(thr_er), float(thr_mom_long), float(thr_mom_short), float(thr_vol),\n                           cost_base_dec, cost_stress_dec)\n        if trades:\n            all_trades.extend(trades)\n            n_is = sum(1 for t in trades if t[\"segment\"] == \"IS\")\n            n_oos = sum(1 for t in trades if t[\"segment\"] == \"OOS\")\n            print(f\"[Celda 10] {sym} fold={fid}: {len(trades)} trades (IS={n_is} OOS={n_oos})\")\n\nif not all_trades:\n    print(\"[Celda 10] WARNING: 0 trades generados por el engine.\")\n    trades_df = pl.DataFrame()\nelse:\n    trades_df = pl.DataFrame(all_trades).sort([\"symbol\", \"fold_id\", \"signal_time_utc\"])\n\ntrades_df.write_parquet(str(OUT_TRADES), compression=\"zstd\")\n\n# Summary\nif trades_df.height > 0:\n    summary = (\n        trades_df\n        .group_by([\"symbol\", \"fold_id\", \"segment\", \"side\"])\n        .agg([\n            pl.len().alias(\"n_trades\"),\n            pl.col(\"gross_pnl\").mean().alias(\"gross_mean\"),\n            pl.col(\"net_pnl_base\").mean().alias(\"net_base_mean\"),\n            pl.col(\"net_pnl_base\").std().alias(\"net_base_std\"),\n            (pl.col(\"net_pnl_base\") > 0).mean().alias(\"win_rate\"),\n            pl.col(\"hold_bars\").median().alias(\"hold_bars_median\"),\n        ])\n        .sort([\"symbol\", \"fold_id\", \"segment\"])\n    )\nelse:\n    summary = pl.DataFrame()\n\nsummary.write_parquet(str(OUT_SUMMARY), compression=\"zstd\")\n\nprint(f\"\\n[Celda 10] OUT: {OUT_TRADES} ({trades_df.height} trades)\")\nprint(f\"[Celda 10] OUT: {OUT_SUMMARY} ({summary.height} rows)\")\nprint(\">>> Celda 10 v2.2.0 :: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b476806a",
   "metadata": {},
   "outputs": [],
   "source": "# ======================================================================================\n# Celda 11 v2.1.0 — QA: No-Lookahead + Weekend Entries\n# CAMBIO v2.1.0: Verifica entry_time_utc > signal_time_utc (no-lookahead)\n# ======================================================================================\n\nfrom __future__ import annotations\nimport json\nfrom pathlib import Path\nfrom datetime import datetime, timezone\nfrom typing import Dict\nimport polars as pl\n\nprint(\">>> Celda 11 v2.1.0 :: QA No-Lookahead + Weekend Entries\")\n\nif \"RUN\" not in globals():\n    raise RuntimeError(\"[Celda 11] ERROR: RUN no existe.\")\n\nRUN_DIR: Path = RUN[\"RUN_DIR\"]\nARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n\nTRADES_PATH = ARTIFACTS.get(\"trades_engine\", RUN_DIR / \"trades_engine_v2.parquet\")\nOUT_QA = ARTIFACTS.get(\"engine_qa_report\", RUN_DIR / \"engine_qa_report_v2.json\")\n\nif not TRADES_PATH.exists():\n    print(\"[Celda 11] WARNING: trades_engine no existe, skip.\")\n    qa = {\"status\": \"SKIPPED\", \"reason\": \"no trades file\"}\nelse:\n    df = pl.read_parquet(TRADES_PATH)\n    if df.height == 0:\n        qa = {\"status\": \"PASS\", \"reason\": \"0 trades\", \"weekend_entries\": 0, \"lookahead_violations\": 0}\n    else:\n        # Weekend entries check\n        df = df.with_columns(pl.col(\"entry_time_utc\").dt.weekday().alias(\"_dow\"))\n        wk_entries = df.filter(pl.col(\"_dow\") >= 6).height\n\n        # No-lookahead check: entry_time_utc must be > signal_time_utc\n        lookahead_violations = df.filter(\n            pl.col(\"entry_time_utc\") <= pl.col(\"signal_time_utc\")\n        ).height\n\n        status = \"PASS\"\n        issues = []\n        if wk_entries > 0:\n            status = \"FAIL\"\n            issues.append(f\"{wk_entries} weekend entries\")\n            print(f\"[Celda 11] FAIL: {wk_entries} weekend entries detectadas!\")\n        if lookahead_violations > 0:\n            status = \"FAIL\"\n            issues.append(f\"{lookahead_violations} lookahead violations\")\n            print(f\"[Celda 11] FAIL: {lookahead_violations} lookahead violations (entry <= signal)!\")\n\n        qa = {\n            \"status\": status,\n            \"total_trades\": df.height,\n            \"weekend_entries\": wk_entries,\n            \"lookahead_violations\": lookahead_violations,\n            \"issues\": issues if issues else None,\n        }\n\n        if status == \"PASS\":\n            print(f\"[Celda 11] PASS: {df.height} trades, 0 weekend, 0 lookahead\")\n\nPath(OUT_QA).write_text(json.dumps(qa, indent=2), encoding=\"utf-8\")\nprint(f\"[Celda 11] OUT: {OUT_QA} :: status={qa['status']}\")\nprint(\">>> Celda 11 v2.1.0 :: OK\")"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df9078ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Celda 12 v2.0.1 :: Engine Report\n",
      "[Celda 12] total_ret=-32.2199 MDD=-32.9071 sharpe=-0.077 WR=0.318 n=83385\n",
      "[Celda 12] exit_reasons: {'TRAIL': 36533, 'SL': 33983, 'TP': 9923, 'REGIME_OFF': 2226, 'WEEKEND': 720}\n",
      "[Celda 12] OUT: C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\equity_curve_engine_v2.parquet (83385 rows)\n",
      ">>> Celda 12 v2.0.1 :: OK\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# Celda 12 v2.0.1 — Engine Report: Equity Curve + KPIs + Exit Reasons\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json, math\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 12 v2.0.1 :: Engine Report\")\n",
    "\n",
    "if \"RUN\" not in globals():\n",
    "    raise RuntimeError(\"[Celda 12] ERROR: RUN no existe.\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "\n",
    "TRADES_PATH = ARTIFACTS.get(\"trades_engine\", RUN_DIR / \"trades_engine_v2.parquet\")\n",
    "OUT_EQUITY = ARTIFACTS.get(\"equity_engine\", RUN_DIR / \"equity_curve_engine_v2.parquet\")\n",
    "OUT_SNAP = ARTIFACTS.get(\"engine_report_snapshot\", RUN_DIR / \"engine_report_snapshot_v2.json\")\n",
    "\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "if not TRADES_PATH.exists():\n",
    "    print(\"[Celda 12] WARNING: trades_engine no existe, skip.\")\n",
    "else:\n",
    "    df = pl.read_parquet(TRADES_PATH)\n",
    "    if df.height == 0:\n",
    "        print(\"[Celda 12] WARNING: 0 trades.\")\n",
    "        pl.DataFrame().write_parquet(str(OUT_EQUITY))\n",
    "        snap = {\"created_utc\": _now_utc_iso(), \"status\": \"EMPTY\"}\n",
    "        Path(OUT_SNAP).write_text(json.dumps(snap, indent=2), encoding=\"utf-8\")\n",
    "    else:\n",
    "        # Equity curve (cum log returns)\n",
    "        eq = (\n",
    "            df.sort(\"exit_time_utc\")\n",
    "            .with_columns([\n",
    "                pl.col(\"net_pnl_base\").cum_sum().alias(\"cum_ret\"),\n",
    "            ])\n",
    "            .with_columns([\n",
    "                pl.col(\"cum_ret\").cum_max().alias(\"peak\"),\n",
    "            ])\n",
    "            .with_columns([\n",
    "                (pl.col(\"cum_ret\") - pl.col(\"peak\")).alias(\"drawdown\"),\n",
    "            ])\n",
    "            .select([\"symbol\", \"fold_id\", \"segment\", \"side\", \"exit_time_utc\",\n",
    "                      \"net_pnl_base\", \"cum_ret\", \"peak\", \"drawdown\"])\n",
    "        )\n",
    "        eq.write_parquet(str(OUT_EQUITY), compression=\"zstd\")\n",
    "\n",
    "        # KPIs\n",
    "        tot_ret = float(df.get_column(\"net_pnl_base\").sum())\n",
    "        mdd = float(eq.get_column(\"drawdown\").min())\n",
    "        n_trades = df.height\n",
    "        mean_ret = float(df.get_column(\"net_pnl_base\").mean())\n",
    "        std_ret = float(df.get_column(\"net_pnl_base\").std())\n",
    "        sharpe = mean_ret / std_ret if std_ret > 1e-12 else 0.0\n",
    "        wr = float((df.get_column(\"net_pnl_base\") > 0).mean())\n",
    "\n",
    "        # Exit reasons\n",
    "        exit_counts = df.group_by(\"exit_reason\").agg(pl.len().alias(\"count\")).sort(\"count\", descending=True)\n",
    "        exit_dict = {r[\"exit_reason\"]: r[\"count\"] for r in exit_counts.to_dicts()}\n",
    "\n",
    "        snap = {\n",
    "            \"created_utc\": _now_utc_iso(), \"version\": \"v2.0.1\",\n",
    "            \"kpis\": {\n",
    "                \"total_return\": tot_ret, \"mdd\": mdd, \"n_trades\": n_trades,\n",
    "                \"sharpe_like\": sharpe, \"win_rate\": wr, \"mean_ret\": mean_ret,\n",
    "            },\n",
    "            \"exit_reasons\": exit_dict,\n",
    "        }\n",
    "        Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, default=str), encoding=\"utf-8\")\n",
    "\n",
    "        print(f\"[Celda 12] total_ret={tot_ret:.4f} MDD={mdd:.4f} sharpe={sharpe:.3f} WR={wr:.3f} n={n_trades}\")\n",
    "        print(f\"[Celda 12] exit_reasons: {exit_dict}\")\n",
    "        print(f\"[Celda 12] OUT: {OUT_EQUITY} ({eq.height} rows)\")\n",
    "\n",
    "print(\">>> Celda 12 v2.0.1 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92f40609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Celda 13 v2.0.1 :: Diagnostico + Edge Alignment\n",
      "[Celda 13] OUT: C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\diagnostics_v2.parquet (4 rows)\n",
      "  BNBUSD: best_alpha=SHORT/H96 hold_p90=36 trail_share=0.44 kills=True\n",
      "  BTCUSD: best_alpha=LONG/H288 hold_p90=38 trail_share=0.47 kills=True\n",
      "  LVMH: best_alpha=SHORT/H288 hold_p90=36 trail_share=0.36 kills=False\n",
      "  XAUAUD: best_alpha=LONG/H96 hold_p90=44 trail_share=0.43 kills=True\n",
      ">>> Celda 13 v2.0.1 :: OK\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# Celda 13 v2.0.1 — Diagnostico de Rentabilidad + Edge Alignment (alpha<->motor)\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 13 v2.0.1 :: Diagnostico + Edge Alignment\")\n",
    "\n",
    "if \"RUN\" not in globals():\n",
    "    raise RuntimeError(\"[Celda 13] ERROR: RUN no existe.\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "\n",
    "ALPHA_PATH = ARTIFACTS.get(\"alpha_multi_horizon_report\", RUN_DIR / \"alpha_multi_horizon_report_v2.parquet\")\n",
    "TRADES_PATH = ARTIFACTS.get(\"trades_engine\", RUN_DIR / \"trades_engine_v2.parquet\")\n",
    "\n",
    "OUT_DIAG = ARTIFACTS.get(\"diagnostics\", RUN_DIR / \"diagnostics_v2.parquet\")\n",
    "OUT_SNAP = ARTIFACTS.get(\"diagnostics_snapshot\", RUN_DIR / \"diagnostics_snapshot_v2.json\")\n",
    "\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "if not ALPHA_PATH.exists() or not TRADES_PATH.exists():\n",
    "    print(\"[Celda 13] WARNING: faltan alpha_report o trades_engine, skip.\")\n",
    "    snap = {\"created_utc\": _now_utc_iso(), \"status\": \"SKIPPED\"}\n",
    "    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2), encoding=\"utf-8\")\n",
    "else:\n",
    "    alpha = pl.read_parquet(ALPHA_PATH)\n",
    "    trades = pl.read_parquet(TRADES_PATH)\n",
    "\n",
    "    diag_rows = []\n",
    "    if trades.height > 0 and alpha.height > 0:\n",
    "        for sym in trades.get_column(\"symbol\").unique().sort().to_list():\n",
    "            t_sym = trades.filter(pl.col(\"symbol\") == sym)\n",
    "            a_sym = alpha.filter(pl.col(\"symbol\") == sym)\n",
    "\n",
    "            # Best alpha side/horizon in IS\n",
    "            a_is = a_sym.filter(pl.col(\"segment\") == \"IS\")\n",
    "            if a_is.height > 0:\n",
    "                best_alpha = a_is.sort(\"sharpe_like\", descending=True).row(0, named=True)\n",
    "            else:\n",
    "                best_alpha = None\n",
    "\n",
    "            # Engine hold time distribution\n",
    "            hold_p50 = float(t_sym.get_column(\"hold_bars\").median()) if t_sym.height > 0 else 0\n",
    "            hold_p90 = float(t_sym.get_column(\"hold_bars\").quantile(0.90, interpolation=\"nearest\")) if t_sym.height > 0 else 0\n",
    "\n",
    "            # Trail kill analysis: fraction of trades exited by TRAIL\n",
    "            trail_share = float(t_sym.filter(pl.col(\"exit_reason\") == \"TRAIL\").height / max(1, t_sym.height))\n",
    "\n",
    "            diag_rows.append({\n",
    "                \"symbol\": sym,\n",
    "                \"best_alpha_side_IS\": best_alpha[\"side\"] if best_alpha else None,\n",
    "                \"best_alpha_horizon_IS\": best_alpha[\"horizon_bars\"] if best_alpha else None,\n",
    "                \"best_alpha_sharpe_IS\": best_alpha[\"sharpe_like\"] if best_alpha else None,\n",
    "                \"engine_hold_p50\": hold_p50,\n",
    "                \"engine_hold_p90\": hold_p90,\n",
    "                \"trail_exit_share\": trail_share,\n",
    "                \"hold_vs_alpha_ratio\": hold_p90 / best_alpha[\"horizon_bars\"] if best_alpha and best_alpha[\"horizon_bars\"] > 0 else None,\n",
    "                \"trail_kills_alpha\": trail_share > 0.40 and (hold_p90 < (best_alpha[\"horizon_bars\"] * 0.5 if best_alpha else 999)),\n",
    "            })\n",
    "\n",
    "    diag_df = pl.DataFrame(diag_rows) if diag_rows else pl.DataFrame()\n",
    "    diag_df.write_parquet(str(OUT_DIAG), compression=\"zstd\")\n",
    "\n",
    "    snap = {\n",
    "        \"created_utc\": _now_utc_iso(), \"version\": \"v2.0.1\",\n",
    "        \"n_symbols\": len(diag_rows),\n",
    "        \"diagnostics\": diag_rows,\n",
    "    }\n",
    "    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, default=str), encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"[Celda 13] OUT: {OUT_DIAG} ({diag_df.height} rows)\")\n",
    "    if diag_rows:\n",
    "        for d in diag_rows:\n",
    "            print(f\"  {d['symbol']}: best_alpha={d['best_alpha_side_IS']}/H{d['best_alpha_horizon_IS']} \"\n",
    "                  f\"hold_p90={d['engine_hold_p90']:.0f} trail_share={d['trail_exit_share']:.2f} \"\n",
    "                  f\"kills={d['trail_kills_alpha']}\")\n",
    "\n",
    "print(\">>> Celda 13 v2.0.1 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515f5bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n# Celda 14 v2.1.0 — Engine Tuning REAL (IS-only)\n# CAMBIO v2.1.0: Re-ejecuta _simulate() con cada combinacion de parametros.\n#   Score = sum(net_pnl_base) / max(1e-12, std(net_pnl_base))  (Sharpe-like)\n#   Anti-placebo: assert que scores varian entre combos.\n#\n# Grid: SL=[1.5-3.0] TP=[7.0-14.0] Trail=[0] time_stop=[288-576]\n#   min_hold=[3,6,12].  Enforce Trail > SL or Trail=0 (no trail).\n# ======================================================================================\n\nfrom __future__ import annotations\nimport json, math, itertools, time\nfrom pathlib import Path\nfrom datetime import datetime, timezone\nfrom typing import Dict\nimport polars as pl\n\nprint(\">>> Celda 14 v2.1.0 :: Engine Tuning REAL (IS-only)\")\n\nif \"RUN\" not in globals():\n    raise RuntimeError(\"[Celda 14] ERROR: RUN no existe.\")\n\nRUN_DIR: Path = RUN[\"RUN_DIR\"]\nARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n\nFEATURES_PATH = ARTIFACTS[\"features_m5\"]\nWFO_PATH = ARTIFACTS[\"wfo_folds\"]\nREGIME_PATH = ARTIFACTS[\"regime_params_by_fold\"]\nCOST_SNAP_PATH = ARTIFACTS.get(\"cost_model_snapshot\", RUN_DIR / \"cost_model_snapshot_v2.json\")\n\nOUT_TUNING = ARTIFACTS.get(\"tuning_results\", RUN_DIR / \"tuning_results_v2.parquet\")\nOUT_BEST = ARTIFACTS.get(\"tuning_best_params\", RUN_DIR / \"tuning_best_params_v2.parquet\")\nOUT_SNAP = ARTIFACTS.get(\"tuning_snapshot\", RUN_DIR / \"tuning_snapshot_v2.json\")\n\ndef _now_utc_iso() -> str:\n    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n\n# Grid\nSL_ATR_GRID    = [2.5, 3.0, 3.5, 4.0]\nTP_ATR_GRID    = [10.0, 14.0, 20.0]\nTRAIL_ATR_GRID = [0]\nTIME_STOP_GRID = [576, 1440, 2880]\nMIN_HOLD_GRID  = [12, 48, 72]\nENTRY_CONFIRM_GRID = [12, 28, 48]\nMAX_COMBOS = 200\nMIN_TRADES_SCORE = 20\n\n# Enforce Trail > SL\ncombos = [(sl, tp, tr, ts, mh, ec)\n          for sl, tp, tr, ts, mh, ec in itertools.product(\n              SL_ATR_GRID, TP_ATR_GRID, TRAIL_ATR_GRID, TIME_STOP_GRID, MIN_HOLD_GRID, ENTRY_CONFIRM_GRID)\n          if tr == 0 or tr > sl][:MAX_COMBOS]\n\nprint(f\"[Celda 14] {len(combos)} valid combos (Trail > SL enforced)\")\n\n# --- Load data (same as Cell 10) ---\ndf_feat_tuning = pl.read_parquet(FEATURES_PATH)\ndf_folds_tuning = pl.read_parquet(WFO_PATH)\ndf_regime_tuning = pl.read_parquet(REGIME_PATH)\ncost_snap_tuning = json.loads(Path(COST_SNAP_PATH).read_text(encoding=\"utf-8\"))\ncosts_by_sym_tuning = {e[\"symbol\"]: e for e in cost_snap_tuning.get(\"per_symbol\", [])}\n\nsymbols_tuning = df_feat_tuning.get_column(\"symbol\").unique().sort().to_list()\nfold_ids_tuning = df_folds_tuning.get_column(\"fold_id\").unique().sort().to_list()\n\n# --- Tuning loop: re-execute engine per combo ---\nt0 = time.time()\nresults = []\n\nfor sym in symbols_tuning:\n    df_sym = df_feat_tuning.filter(pl.col(\"symbol\") == sym).sort(\"time_utc\")\n    cinfo = costs_by_sym_tuning.get(sym, {})\n    cost_base_dec = float(cinfo.get(\"base_cost_bps\", 8.0)) / 10_000\n    cost_stress_dec = float(cinfo.get(\"stress_cost_bps\", 16.0)) / 10_000\n    print(f\"  [{sym}] cost_base={cost_base_dec*10_000:.1f}bps, cost_stress={cost_stress_dec*10_000:.1f}bps \"\n          f\"(from={'snapshot' if cinfo else 'default'})\")\n\n    for fid in fold_ids_tuning:\n        fold_row = df_folds_tuning.filter(pl.col(\"fold_id\") == fid).row(0, named=True)\n\n        # Regime params\n        rg_long = df_regime_tuning.filter(\n            (pl.col(\"symbol\") == sym) & (pl.col(\"fold_id\") == fid) & (pl.col(\"side\") == \"LONG\"))\n        rg_short = df_regime_tuning.filter(\n            (pl.col(\"symbol\") == sym) & (pl.col(\"fold_id\") == fid) & (pl.col(\"side\") == \"SHORT\"))\n\n        thr_er = None; thr_mom_long = 0.0; thr_mom_short = 0.0; thr_vol = None\n        if not rg_long.is_empty():\n            rl = rg_long.row(0, named=True)\n            thr_er = rl[\"thr_er\"]; thr_mom_long = rl[\"thr_mom\"]; thr_vol = rl[\"thr_vol\"]\n        if not rg_short.is_empty():\n            rs = rg_short.row(0, named=True)\n            thr_mom_short = rs[\"thr_mom\"]\n            if thr_er is None: thr_er = rs[\"thr_er\"]\n            if thr_vol is None: thr_vol = rs[\"thr_vol\"]\n\n        if thr_er is None:\n            continue\n\n        for sl, tp, tr, ts, mh, ec in combos:\n            # RE-RUN ENGINE with this param combo (IS-only trades)\n            trades = _simulate(sym, df_sym, fold_row,\n                               float(thr_er), float(thr_mom_long), float(thr_mom_short), float(thr_vol),\n                               cost_base_dec, cost_stress_dec,\n                               sl_atr=sl, tp_atr=tp, trail_atr=tr, time_stop=ts, min_hold=mh, entry_confirm_bars=ec)\n\n            # Filter IS-only trades\n            is_trades = [t for t in trades if t.get(\"segment\") == \"IS\"]\n            n = len(is_trades)\n            if n < MIN_TRADES_SCORE:\n                continue\n\n            rets = [t[\"net_pnl_base\"] for t in is_trades]\n            mean_r = sum(rets) / n\n            std_r = (sum((r - mean_r)**2 for r in rets) / max(1, n - 1)) ** 0.5\n            score = sum(rets) / max(1e-12, std_r)\n\n            results.append({\n                \"symbol\": sym, \"fold_id\": fid,\n                \"sl_atr\": sl, \"tp_atr\": tp, \"trail_atr\": tr,\n                \"time_stop\": ts, \"min_hold\": mh, \"entry_confirm\": ec,\n                \"n_trades\": n, \"sum_ret\": sum(rets), \"std_ret\": std_r,\n                \"mean_ret\": mean_r, \"score\": score,\n            })\n\n    print(f\"[Celda 14] {sym}: {sum(1 for r in results if r['symbol'] == sym)} results\")\n\nelapsed = time.time() - t0\nprint(f\"[Celda 14] Tuning completado en {elapsed:.1f}s\")\n\n# --- Build results DataFrame ---\nif results:\n    tuning_df = pl.DataFrame(results).sort([\"symbol\", \"fold_id\", \"score\"], descending=[False, False, True])\nelse:\n    tuning_df = pl.DataFrame()\n    print(\"[Celda 14] WARNING: 0 results (no trades above MIN_TRADES_SCORE)\")\n\ntuning_df.write_parquet(str(OUT_TUNING), compression=\"zstd\")\n\n# Best per symbol/fold\nif tuning_df.height > 0:\n    best = tuning_df.group_by([\"symbol\", \"fold_id\"]).first().sort([\"symbol\", \"fold_id\"])\nelse:\n    best = pl.DataFrame()\nbest.write_parquet(str(OUT_BEST), compression=\"zstd\")\n\n# --- Anti-placebo assertion ---\nn_unique_scores = 0\nif tuning_df.height > 0:\n    for sym in tuning_df.get_column(\"symbol\").unique().to_list():\n        for fid in tuning_df.filter(pl.col(\"symbol\") == sym).get_column(\"fold_id\").unique().to_list():\n            grp = tuning_df.filter((pl.col(\"symbol\") == sym) & (pl.col(\"fold_id\") == fid))\n            unique_scores = grp.get_column(\"score\").n_unique()\n            n_unique_scores = max(n_unique_scores, unique_scores)\n            if unique_scores <= 1 and grp.height > 1:\n                print(f\"[Celda 14] WARNING PLACEBO: {sym} fold={fid} tiene {grp.height} combos pero solo {unique_scores} score unico\")\n\nprint(f\"[Celda 14] Anti-placebo: max unique scores per (sym,fold) = {n_unique_scores}\")\nif n_unique_scores > 1:\n    print(\"[Celda 14] PASS: Tuning es REAL (scores varian entre combos)\")\nelse:\n    print(\"[Celda 14] FAIL: Tuning puede ser placebo (scores identicos)\")\n\n# --- Snapshot ---\ntop5 = tuning_df.head(5).to_dicts() if tuning_df.height > 0 else []\nsnap = {\n    \"created_utc\": _now_utc_iso(), \"version\": \"v2.1.0\",\n    \"grid\": {\"SL\": SL_ATR_GRID, \"TP\": TP_ATR_GRID, \"TRAIL\": TRAIL_ATR_GRID,\n             \"TIME_STOP\": TIME_STOP_GRID, \"MIN_HOLD\": MIN_HOLD_GRID, \"ENTRY_CONFIRM\": ENTRY_CONFIRM_GRID},\n    \"n_combos\": len(combos), \"n_results\": tuning_df.height, \"n_best\": best.height,\n    \"max_unique_scores_per_group\": n_unique_scores,\n    \"anti_placebo\": \"PASS\" if n_unique_scores > 1 else \"FAIL\",\n    \"elapsed_seconds\": round(elapsed, 1),\n    \"top5_results\": top5,\n}\nPath(OUT_SNAP).write_text(json.dumps(snap, indent=2, default=str), encoding=\"utf-8\")\n\nprint(f\"\\n[Celda 14] OUT: {OUT_TUNING} ({tuning_df.height} rows)\")\nprint(f\"[Celda 14] OUT: {OUT_BEST} ({best.height} rows)\")\nprint(f\"[Celda 14] OUT: {OUT_SNAP}\")\nprint(\">>> Celda 14 v2.1.0 :: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40a2390f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Celda 15 v2.0.1 :: Alpha Design (IS-only)\n",
      "[Celda 15] OUT: C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\alpha_design_v2.parquet (19 rows)\n",
      "shape: (19, 10)\n",
      "┌────────┬─────────┬───────────┬─────────────┬───┬──────────┬────────────┬────────────┬────────────┐\n",
      "│ symbol ┆ fold_id ┆ best_side ┆ best_horizo ┆ … ┆ n_trades ┆ TIME_STOP_ ┆ MIN_HOLD_t ┆ ENTRY_CONF │\n",
      "│ ---    ┆ ---     ┆ ---       ┆ n           ┆   ┆ ---      ┆ target     ┆ arget      ┆ IRM_target │\n",
      "│ str    ┆ i64     ┆ str       ┆ ---         ┆   ┆ i64      ┆ ---        ┆ ---        ┆ ---        │\n",
      "│        ┆         ┆           ┆ i64         ┆   ┆          ┆ i64        ┆ i64        ┆ i64        │\n",
      "╞════════╪═════════╪═══════════╪═════════════╪═══╪══════════╪════════════╪════════════╪════════════╡\n",
      "│ BNBUSD ┆ 6       ┆ SHORT     ┆ 96          ┆ … ┆ 35779    ┆ 96         ┆ 24         ┆ 9          │\n",
      "│ BNBUSD ┆ 7       ┆ SHORT     ┆ 96          ┆ … ┆ 38296    ┆ 96         ┆ 24         ┆ 9          │\n",
      "│ BTCUSD ┆ 1       ┆ LONG      ┆ 288         ┆ … ┆ 11664    ┆ 288        ┆ 72         ┆ 28         │\n",
      "│ BTCUSD ┆ 2       ┆ LONG      ┆ 288         ┆ … ┆ 14696    ┆ 288        ┆ 72         ┆ 28         │\n",
      "│ BTCUSD ┆ 3       ┆ LONG      ┆ 288         ┆ … ┆ 18675    ┆ 288        ┆ 72         ┆ 28         │\n",
      "│ …      ┆ …       ┆ …         ┆ …           ┆ … ┆ …        ┆ …          ┆ …          ┆ …          │\n",
      "│ LVMH   ┆ 9       ┆ SHORT     ┆ 288         ┆ … ┆ 15839    ┆ 288        ┆ 72         ┆ 28         │\n",
      "│ LVMH   ┆ 10      ┆ SHORT     ┆ 288         ┆ … ┆ 17536    ┆ 288        ┆ 72         ┆ 28         │\n",
      "│ XAUAUD ┆ 8       ┆ LONG      ┆ 96          ┆ … ┆ 45115    ┆ 96         ┆ 24         ┆ 9          │\n",
      "│ XAUAUD ┆ 9       ┆ LONG      ┆ 96          ┆ … ┆ 48823    ┆ 96         ┆ 24         ┆ 9          │\n",
      "│ XAUAUD ┆ 10      ┆ LONG      ┆ 96          ┆ … ┆ 52152    ┆ 96         ┆ 24         ┆ 9          │\n",
      "└────────┴─────────┴───────────┴─────────────┴───┴──────────┴────────────┴────────────┴────────────┘\n",
      ">>> Celda 15 v2.0.1 :: OK\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# Celda 15 v2.0.1 — Alpha Design (IS-only) [side + horizon selection -> motor targets]\n",
    "# Gates: n_trades >= 80, net_base_mean >= 0\n",
    "# Score: sharpe_like * sqrt(n_trades)\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json, math\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 15 v2.0.1 :: Alpha Design (IS-only)\")\n",
    "\n",
    "if \"RUN\" not in globals():\n",
    "    raise RuntimeError(\"[Celda 15] ERROR: RUN no existe.\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "\n",
    "ALPHA_PATH = ARTIFACTS.get(\"alpha_multi_horizon_report\", RUN_DIR / \"alpha_multi_horizon_report_v2.parquet\")\n",
    "OUT_DESIGN = ARTIFACTS.get(\"alpha_design\", RUN_DIR / \"alpha_design_v2.parquet\")\n",
    "OUT_SNAP = ARTIFACTS.get(\"alpha_design_snapshot\", RUN_DIR / \"alpha_design_snapshot_v2.json\")\n",
    "\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "MIN_TRADES = 80\n",
    "MIN_NET_MEAN = 0.0\n",
    "\n",
    "if not ALPHA_PATH.exists():\n",
    "    print(\"[Celda 15] WARNING: alpha_report no existe, skip.\")\n",
    "    snap = {\"created_utc\": _now_utc_iso(), \"status\": \"SKIPPED\"}\n",
    "    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2), encoding=\"utf-8\")\n",
    "else:\n",
    "    alpha = pl.read_parquet(ALPHA_PATH)\n",
    "    a_is = alpha.filter(pl.col(\"segment\") == \"IS\")\n",
    "\n",
    "    # Gates\n",
    "    a_is = a_is.filter(\n",
    "        (pl.col(\"n_trades\") >= MIN_TRADES) &\n",
    "        (pl.col(\"net_base_mean\") >= MIN_NET_MEAN)\n",
    "    )\n",
    "\n",
    "    if a_is.height == 0:\n",
    "        print(\"[Celda 15] WARNING: no hay filas que pasen gates.\")\n",
    "        design_df = pl.DataFrame()\n",
    "    else:\n",
    "        # Score\n",
    "        a_is = a_is.with_columns(\n",
    "            (pl.col(\"sharpe_like\") * pl.col(\"n_trades\").cast(pl.Float64).sqrt()).alias(\"score\")\n",
    "        )\n",
    "\n",
    "        # Best per symbol/fold\n",
    "        design_rows = []\n",
    "        for sym in a_is.get_column(\"symbol\").unique().sort().to_list():\n",
    "            for fid in a_is.filter(pl.col(\"symbol\") == sym).get_column(\"fold_id\").unique().sort().to_list():\n",
    "                cand = a_is.filter((pl.col(\"symbol\") == sym) & (pl.col(\"fold_id\") == fid))\n",
    "                if cand.height == 0:\n",
    "                    continue\n",
    "                best = cand.sort(\"score\", descending=True).row(0, named=True)\n",
    "                h = best[\"horizon_bars\"]\n",
    "                design_rows.append({\n",
    "                    \"symbol\": sym, \"fold_id\": fid,\n",
    "                    \"best_side\": best[\"side\"], \"best_horizon\": h,\n",
    "                    \"sharpe_like\": best[\"sharpe_like\"], \"score\": best[\"score\"],\n",
    "                    \"n_trades\": best[\"n_trades\"],\n",
    "                    \"TIME_STOP_target\": h,\n",
    "                    \"MIN_HOLD_target\": max(6, int(0.25 * h)),\n",
    "                    \"ENTRY_CONFIRM_target\": max(3, int(0.10 * h)),\n",
    "                })\n",
    "\n",
    "        design_df = pl.DataFrame(design_rows) if design_rows else pl.DataFrame()\n",
    "\n",
    "    design_df.write_parquet(str(OUT_DESIGN), compression=\"zstd\")\n",
    "\n",
    "    snap = {\n",
    "        \"created_utc\": _now_utc_iso(), \"version\": \"v2.0.1\",\n",
    "        \"gates\": {\"min_trades\": MIN_TRADES, \"min_net_mean\": MIN_NET_MEAN},\n",
    "        \"n_designs\": design_df.height if design_df.height else 0,\n",
    "    }\n",
    "    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, default=str), encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"[Celda 15] OUT: {OUT_DESIGN} ({design_df.height} rows)\")\n",
    "    if design_df.height > 0:\n",
    "        print(design_df)\n",
    "\n",
    "print(\">>> Celda 15 v2.0.1 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab67bb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Celda 16 v2.0.1 :: Execution & Risk Overlay\n",
      "[Celda 16] trades: 83385 -> 3253 (filtered 80132)\n",
      "[Celda 16] OUT: C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\overlay_trades_v2.parquet\n",
      ">>> Celda 16 v2.0.1 :: OK\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n# Celda 16 v3.0.0 — Challenge-Ready Overlay (ChallengeOverlayStateMachine)\n# Edge filter: BTCUSD LONG only (fwd_ret +0.356% @24h)\n# Challenge rules: daily -$1,250 / total -$2,500 / target +$1,250 / min 2 days\n# Sizing: risk_per_trade / median_SL_loss -> 1 SL ~ $risk\n# ======================================================================================\n\nfrom __future__ import annotations\nimport json\nfrom pathlib import Path\nfrom datetime import datetime, timezone\nfrom typing import Dict\nimport polars as pl\n\nprint(\">>> Celda 16 v3.0.0 :: Challenge-Ready Overlay\")\n\nif \"RUN\" not in globals():\n    raise RuntimeError(\"[Celda 16] ERROR: RUN no existe.\")\n\nif RUN.get(\"_overlay_applied\"):\n    raise RuntimeError(\"[Celda 16] Overlay ya aplicado en este run. Re-ejecutar desde Cell 00.\")\nRUN[\"_overlay_applied\"] = True\n\nRUN_DIR: Path = RUN[\"RUN_DIR\"]\nARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n\nTRADES_PATH = ARTIFACTS.get(\"trades_engine\", RUN_DIR / \"trades_engine_v2.parquet\")\nOUT_OVERLAY_TRADES = ARTIFACTS.get(\"overlay_trades\", RUN_DIR / \"overlay_trades_v2.parquet\")\nOUT_OVERLAY_SUMMARY = ARTIFACTS.get(\"overlay_summary\", RUN_DIR / \"overlay_summary_v2.parquet\")\nOUT_SNAP = ARTIFACTS.get(\"overlay_snapshot\", RUN_DIR / \"overlay_snapshot_v2.json\")\nOUT_CHALLENGE = RUN_DIR / \"challenge_dashboard_v2.json\"\n\ndef _now_utc_iso() -> str:\n    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n\n# ── Edge filter params ──\nSYMBOL_WHITELIST = [\"XAUAUD\"]\nSIDE_FILTER = \"LONG\"\nENTRY_WEEKDAYS_ONLY = True\n\n# ── Challenge params (prop-firm exam) ──\nCHALLENGE_CAPITAL        = 25_000\nCHALLENGE_DAILY_MAX_LOSS = 1_250   # USD\nCHALLENGE_TOTAL_MAX_LOSS = 2_500   # USD\nCHALLENGE_PROFIT_TARGET  = 1_250   # USD\nCHALLENGE_MIN_DAYS       = 2\nRISK_PER_TRADE_USD       = 75     # optimal from sweep (worst fold DD = -$1,955, no violations)\n\nif not TRADES_PATH.exists():\n    print(\"[Celda 16] WARNING: trades_engine no existe, skip.\")\n    snap = {\"created_utc\": _now_utc_iso(), \"status\": \"SKIPPED\"}\n    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2), encoding=\"utf-8\")\nelse:\n    df = pl.read_parquet(TRADES_PATH)\n    n_engine = df.height\n\n    # ── Step 1: Edge filter ──\n    df = df.filter(\n        pl.col(\"symbol\").is_in(SYMBOL_WHITELIST) &\n        (pl.col(\"side\") == SIDE_FILTER)\n    )\n    n_after_edge = df.height\n    print(f\"[Celda 16] Edge filter: {n_engine} -> {n_after_edge} (XAUAUD LONG only)\")\n\n    # ── Step 2: Weekday filter ──\n    df = df.with_columns([\n        pl.col(\"entry_time_utc\").cast(pl.Date).alias(\"_date\"),\n        pl.col(\"entry_time_utc\").dt.weekday().alias(\"_dow\"),\n    ])\n    if ENTRY_WEEKDAYS_ONLY:\n        df = df.filter(pl.col(\"_dow\") <= 5)\n    n_after_weekday = df.height\n\n    # ── Step 3: Sizing (from SL-exit trades) ──\n    sl_trades = df.filter(pl.col(\"exit_reason\") == \"SL\")\n    if sl_trades.height > 0:\n        sl_return_median = float(sl_trades[\"net_pnl_base\"].abs().median())\n    else:\n        sl_return_median = 0.003  # fallback\n    sl_return_median = max(sl_return_median, 1e-8)\n    pos_notional = RISK_PER_TRADE_USD / sl_return_median\n\n    # Sanity check: 1 SL should cost ~$RISK_PER_TRADE_USD\n    if sl_trades.height > 0:\n        actual_sl_usd = sl_return_median * pos_notional\n        print(f\"[Celda 16] Sizing: risk=${RISK_PER_TRADE_USD}, SL_ret={sl_return_median:.4%}, \"\n              f\"notional=${pos_notional:,.0f}, 1-SL=${actual_sl_usd:,.2f}\")\n\n    # ── Step 4: ChallengeOverlayStateMachine (OOS simulation) ──\n    # Save ALL trades (IS+OOS) for overlay output, but simulate challenge on OOS only\n    df_sorted = df.sort(\"entry_time_utc\")\n\n    # For overlay_trades: keep all (no filtering by challenge rules on the parquet)\n    df_sorted.write_parquet(str(OUT_OVERLAY_TRADES), compression=\"zstd\")\n    n_overlay = df_sorted.height\n\n    # Challenge simulation on OOS\n    oos = df_sorted.filter(pl.col(\"segment\") == \"OOS\")\n\n    challenge_result = None\n    if oos.height > 0:\n        equity = CHALLENGE_CAPITAL\n        trading_days = set()\n        daily_log = {}\n        trades_taken = 0\n        trades_skipped = 0\n        target_reached = False\n        target_day = None\n        violated_daily = False\n        violated_total = False\n        max_daily_loss_seen = 0.0\n        max_total_dd_seen = 0.0\n        total_wins = 0\n        total_win_usd = 0.0\n        total_loss_usd = 0.0\n\n        for row in oos.iter_rows(named=True):\n            trade_date = row[\"_date\"]\n            pnl_usd = row[\"net_pnl_base\"] * pos_notional\n\n            if trade_date not in daily_log:\n                daily_log[trade_date] = {\"n_trades\": 0, \"pnl_usd\": 0.0, \"skipped\": 0}\n            day = daily_log[trade_date]\n\n            # Daily stop BEFORE trade\n            if day[\"pnl_usd\"] <= -CHALLENGE_DAILY_MAX_LOSS:\n                day[\"skipped\"] += 1\n                trades_skipped += 1\n                continue\n\n            # Total stop BEFORE trade\n            if (equity - CHALLENGE_CAPITAL) <= -CHALLENGE_TOTAL_MAX_LOSS:\n                violated_total = True\n                break\n\n            # Take trade\n            equity += pnl_usd\n            day[\"n_trades\"] += 1\n            day[\"pnl_usd\"] += pnl_usd\n            trades_taken += 1\n            trading_days.add(trade_date)\n\n            if pnl_usd > 0:\n                total_wins += 1\n                total_win_usd += pnl_usd\n            else:\n                total_loss_usd += abs(pnl_usd)\n\n            # Daily violation check\n            if day[\"pnl_usd\"] <= -CHALLENGE_DAILY_MAX_LOSS:\n                violated_daily = True\n\n            # Total DD tracking\n            total_dd = equity - CHALLENGE_CAPITAL\n            max_total_dd_seen = min(max_total_dd_seen, total_dd)\n            if total_dd <= -CHALLENGE_TOTAL_MAX_LOSS:\n                violated_total = True\n                break\n\n            # Target check\n            if total_dd >= CHALLENGE_PROFIT_TARGET and len(trading_days) >= CHALLENGE_MIN_DAYS:\n                target_reached = True\n                target_day = str(trade_date)\n                break\n\n        # Worst daily loss\n        for info in daily_log.values():\n            max_daily_loss_seen = min(max_daily_loss_seen, info[\"pnl_usd\"])\n\n        # Discipline\n        r_days = len(trading_days) >= CHALLENGE_MIN_DAYS\n        r_daily = max_daily_loss_seen > -CHALLENGE_DAILY_MAX_LOSS\n        r_total = max_total_dd_seen > -CHALLENGE_TOTAL_MAX_LOSS\n        r_target = target_reached\n        discipline = sum([r_days, r_daily, r_total, r_target]) * 25\n\n        wr = total_wins / trades_taken if trades_taken > 0 else 0\n        avg_win = total_win_usd / total_wins if total_wins > 0 else 0\n        n_losses = trades_taken - total_wins\n        avg_loss = total_loss_usd / n_losses if n_losses > 0 else 0\n\n        # Daily summary\n        daily_summary = []\n        for d in sorted(daily_log.keys()):\n            info = daily_log[d]\n            if info[\"n_trades\"] > 0 or info[\"skipped\"] > 0:\n                daily_summary.append({\n                    \"date\": str(d), \"n_trades\": info[\"n_trades\"],\n                    \"pnl_usd\": round(info[\"pnl_usd\"], 2), \"skipped\": info[\"skipped\"],\n                })\n\n        challenge_result = {\n            \"created_utc\": _now_utc_iso(),\n            \"version\": \"v3.0.0\",\n            \"sizing\": {\n                \"risk_per_trade_usd\": RISK_PER_TRADE_USD,\n                \"sl_return_median\": round(sl_return_median, 6),\n                \"position_notional\": round(pos_notional, 2),\n            },\n            \"challenge\": {\n                \"initial_capital\": CHALLENGE_CAPITAL,\n                \"daily_max_loss_usd\": CHALLENGE_DAILY_MAX_LOSS,\n                \"total_max_loss_usd\": CHALLENGE_TOTAL_MAX_LOSS,\n                \"profit_target_usd\": CHALLENGE_PROFIT_TARGET,\n                \"min_trading_days\": CHALLENGE_MIN_DAYS,\n            },\n            \"results\": {\n                \"final_equity\": round(equity, 2),\n                \"final_pnl_usd\": round(equity - CHALLENGE_CAPITAL, 2),\n                \"trades_taken\": trades_taken,\n                \"trades_skipped_daily_stop\": trades_skipped,\n                \"trading_days\": len(trading_days),\n                \"win_rate\": round(wr, 4),\n                \"avg_win_usd\": round(avg_win, 2),\n                \"avg_loss_usd\": round(avg_loss, 2),\n                \"payoff_ratio\": round(avg_win / avg_loss, 2) if avg_loss > 0 else 0,\n                \"max_daily_loss_usd\": round(max_daily_loss_seen, 2),\n                \"max_total_dd_usd\": round(max_total_dd_seen, 2),\n                \"target_reached\": target_reached,\n                \"target_day\": target_day,\n                \"violated_daily_limit\": violated_daily,\n                \"violated_total_limit\": violated_total,\n                \"discipline_pct\": discipline,\n            },\n            \"rules\": {\n                \"min_2_days\": r_days,\n                \"daily_loss_ok\": r_daily,\n                \"total_loss_ok\": r_total,\n                \"target_hit\": r_target,\n            },\n            \"daily_summary\": daily_summary,\n        }\n\n        # Print dashboard\n        res = challenge_result[\"results\"]\n        print(f\"[Celda 16] Challenge OOS (base): PnL=${res['final_pnl_usd']:+,.0f}, \"\n              f\"disc={res['discipline_pct']}%, target={'SI' if res['target_reached'] else 'NO'}\")\n        print(f\"[Celda 16] MaxDayLoss=${res['max_daily_loss_usd']:,.0f} \"\n              f\"MaxTotDD=${res['max_total_dd_usd']:,.0f} \"\n              f\"trades={res['trades_taken']} days={res['trading_days']}\")\n\n    # Save challenge dashboard\n    if challenge_result:\n        Path(OUT_CHALLENGE).write_text(\n            json.dumps(challenge_result, indent=2, default=str), encoding=\"utf-8\")\n        print(f\"[Celda 16] OUT: {OUT_CHALLENGE}\")\n\n    # Summary\n    if n_overlay > 0:\n        summary = (\n            df_sorted.group_by([\"symbol\", \"segment\"])\n            .agg([\n                pl.len().alias(\"n_trades\"),\n                pl.col(\"net_pnl_base\").sum().alias(\"total_ret\"),\n                pl.col(\"net_pnl_base\").mean().alias(\"mean_ret\"),\n                (pl.col(\"net_pnl_base\") > 0).mean().alias(\"win_rate\"),\n            ])\n            .sort([\"symbol\", \"segment\"])\n        )\n    else:\n        summary = pl.DataFrame()\n    summary.write_parquet(str(OUT_OVERLAY_SUMMARY), compression=\"zstd\")\n\n    snap = {\n        \"created_utc\": _now_utc_iso(), \"version\": \"v3.0.0\",\n        \"edge_filter\": {\"symbols\": SYMBOL_WHITELIST, \"side\": SIDE_FILTER},\n        \"challenge\": {\n            \"capital\": CHALLENGE_CAPITAL,\n            \"daily_max_loss\": CHALLENGE_DAILY_MAX_LOSS,\n            \"total_max_loss\": CHALLENGE_TOTAL_MAX_LOSS,\n            \"profit_target\": CHALLENGE_PROFIT_TARGET,\n            \"risk_per_trade\": RISK_PER_TRADE_USD,\n        },\n        \"sizing\": {\"sl_return_median\": round(sl_return_median, 6),\n                   \"pos_notional\": round(pos_notional, 2)},\n        \"n_engine\": n_engine, \"n_after_edge\": n_after_edge,\n        \"n_after_weekday\": n_after_weekday, \"n_overlay\": n_overlay,\n    }\n    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, default=str), encoding=\"utf-8\")\n\n    print(f\"[Celda 16] trades: {n_engine} -> {n_overlay} (edge+weekday filter)\")\n    print(f\"[Celda 16] OUT: {OUT_OVERLAY_TRADES}\")\n\nprint(\">>> Celda 16 v3.0.0 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf14989a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Celda 17 v2.0.1 :: Seleccion Institucional\n",
      "[Celda 17] 0/8 symbols GO\n",
      "[Celda 17] OUT: C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\selection_v2.parquet\n",
      ">>> Celda 17 v2.0.1 :: OK\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n# Celda 17 v2.0.1 — Seleccion Institucional (OOS-first + gates + score)\n# Gates: min_oos_trades=30, max_mdd=-0.20, min_totret=-0.05, min_wr=0.15, max_exposure=0.65\n# ======================================================================================\n\nfrom __future__ import annotations\nimport json\nfrom pathlib import Path\nfrom datetime import datetime, timezone\nfrom typing import Dict\nimport polars as pl\n\nprint(\">>> Celda 17 v2.0.1 :: Seleccion Institucional\")\n\nif \"RUN\" not in globals():\n    raise RuntimeError(\"[Celda 17] ERROR: RUN no existe.\")\n\nRUN_DIR: Path = RUN[\"RUN_DIR\"]\nARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n\nOVERLAY_PATH = ARTIFACTS.get(\"overlay_trades\", RUN_DIR / \"overlay_trades_v2.parquet\")\nENGINE_SNAP_PATH = ARTIFACTS.get(\"engine_report_snapshot\", RUN_DIR / \"engine_report_snapshot_v2.json\")\nOUT_SEL = ARTIFACTS.get(\"selection\", RUN_DIR / \"selection_v2.parquet\")\nOUT_SNAP = ARTIFACTS.get(\"selection_snapshot\", RUN_DIR / \"selection_snapshot_v2.json\")\n\ndef _now_utc_iso() -> str:\n    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n\n# Gates\nMIN_OOS_TRADES = 20\nMAX_MDD = -0.35\nMIN_TOTRET = -0.15\nMIN_WINRATE = 0.10   # BE_WR=17.6% for SL=3/TP=14, 0.10 filters strategies without real edge\nMAX_EXPOSURE = 0.65\n\nif not OVERLAY_PATH.exists():\n    print(\"[Celda 17] WARNING: overlay_trades no existe, skip.\")\n    snap = {\"created_utc\": _now_utc_iso(), \"status\": \"SKIPPED\"}\n    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2), encoding=\"utf-8\")\nelse:\n    df = pl.read_parquet(OVERLAY_PATH)\n    df_oos = df.filter(pl.col(\"segment\") == \"OOS\") if df.height > 0 else df\n\n    sel_rows = []\n    if df_oos.height > 0:\n        for sym in df_oos.get_column(\"symbol\").unique().sort().to_list():\n            for side in df_oos.filter(pl.col(\"symbol\") == sym).get_column(\"side\").unique().to_list():\n                sub = df_oos.filter((pl.col(\"symbol\") == sym) & (pl.col(\"side\") == side))\n                n = sub.height\n                if n < MIN_OOS_TRADES:\n                    sel_rows.append({\"symbol\": sym, \"side\": side, \"decision\": \"NO_GO\", \"reason\": f\"n_oos={n}<{MIN_OOS_TRADES}\", \"score\": 0.0, \"n_oos\": n})\n                    continue\n\n                tot_ret = float(sub.get_column(\"net_pnl_base\").sum())\n                wr = float((sub.get_column(\"net_pnl_base\") > 0).mean())\n                cum = sub.sort(\"exit_time_utc\").with_columns(pl.col(\"net_pnl_base\").cum_sum().alias(\"_cr\"))\n                mdd = float((cum.get_column(\"_cr\") - cum.get_column(\"_cr\").cum_max()).min())\n\n                # Score\n                sharpe = float(sub.get_column(\"net_pnl_base\").mean()) / max(1e-12, float(sub.get_column(\"net_pnl_base\").std()))\n                score = tot_ret + 0.15 * sharpe + 0.05 * (wr - 0.5) - 1.25 * (-mdd) - 0.25 * 0.5\n\n                go = (tot_ret >= MIN_TOTRET and mdd >= MAX_MDD and wr >= MIN_WINRATE)\n                sel_rows.append({\n                    \"symbol\": sym, \"side\": side,\n                    \"decision\": \"GO\" if go else \"NO_GO\",\n                    \"reason\": \"PASS\" if go else \"gates\",\n                    \"score\": score, \"n_oos\": n,\n                    \"tot_ret\": tot_ret, \"mdd\": mdd, \"win_rate\": wr, \"sharpe\": sharpe,\n                })\n\n    sel_df = pl.DataFrame(sel_rows) if sel_rows else pl.DataFrame()\n    sel_df.write_parquet(str(OUT_SEL), compression=\"zstd\")\n\n    snap = {\n        \"created_utc\": _now_utc_iso(), \"version\": \"v2.0.1\",\n        \"gates\": {\"min_oos_trades\": MIN_OOS_TRADES, \"max_mdd\": MAX_MDD, \"min_totret\": MIN_TOTRET,\n                  \"min_wr\": MIN_WINRATE, \"max_exposure\": MAX_EXPOSURE},\n        \"selections\": sel_rows,\n    }\n    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, default=str), encoding=\"utf-8\")\n\n    n_go = sum(1 for r in sel_rows if r[\"decision\"] == \"GO\")\n    print(f\"[Celda 17] {n_go}/{len(sel_rows)} symbols GO\")\n    print(f\"[Celda 17] OUT: {OUT_SEL}\")\n\nprint(\">>> Celda 17 v2.0.1 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5067d5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Celda 18 v2.0.1 :: Deploy Pack\n",
      "[Celda 18] No GO symbols, fallback TOPK=2\n",
      "[Celda 18] 2 symbols deployed\n",
      "[Celda 18] OUT: C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\deploy_pack_v2.parquet\n",
      "[Celda 18] OUT: C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\deploy/\n",
      ">>> Celda 18 v2.0.1 :: OK\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# Celda 18 v2.0.1 — Deploy Pack (freeze config + per-symbol JSONs)\n",
    "# Reads selection, filters GO (fallback TOPK=2), exports deploy configs.\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 18 v2.0.1 :: Deploy Pack\")\n",
    "\n",
    "if \"RUN\" not in globals():\n",
    "    raise RuntimeError(\"[Celda 18] ERROR: RUN no existe.\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "\n",
    "SEL_PATH = ARTIFACTS.get(\"selection\", RUN_DIR / \"selection_v2.parquet\")\n",
    "REGIME_PATH = ARTIFACTS[\"regime_params_by_fold\"]\n",
    "COST_SNAP_PATH = ARTIFACTS.get(\"cost_model_snapshot\", RUN_DIR / \"cost_model_snapshot_v2.json\")\n",
    "\n",
    "OUT_DEPLOY = ARTIFACTS.get(\"deploy_pack\", RUN_DIR / \"deploy_pack_v2.parquet\")\n",
    "OUT_DEPLOY_JSON = ARTIFACTS.get(\"deploy_pack_json\", RUN_DIR / \"deploy_pack_v2.json\")\n",
    "\n",
    "DEPLOY_DIR = RUN_DIR / \"deploy\"\n",
    "DEPLOY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TOPK = 2\n",
    "\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "if not SEL_PATH.exists():\n",
    "    print(\"[Celda 18] WARNING: selection no existe, skip.\")\n",
    "else:\n",
    "    sel = pl.read_parquet(SEL_PATH)\n",
    "    regime = pl.read_parquet(REGIME_PATH)\n",
    "    cost_snap = json.loads(Path(COST_SNAP_PATH).read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    go = sel.filter(pl.col(\"decision\") == \"GO\") if sel.height > 0 and \"decision\" in sel.columns else pl.DataFrame()\n",
    "    if go.height == 0 and sel.height > 0 and \"score\" in sel.columns:\n",
    "        go = sel.sort(\"score\", descending=True).head(TOPK)\n",
    "        print(f\"[Celda 18] No GO symbols, fallback TOPK={TOPK}\")\n",
    "\n",
    "    deploy_rows = []\n",
    "    for row in go.iter_rows(named=True):\n",
    "        sym = row[\"symbol\"]\n",
    "        side = row[\"side\"]\n",
    "        rg = regime.filter((pl.col(\"symbol\") == sym) & (pl.col(\"side\") == side))\n",
    "        rg_dict = rg.to_dicts() if rg.height > 0 else []\n",
    "\n",
    "        config = {\n",
    "            \"symbol\": sym, \"side\": side, \"score\": row.get(\"score\", 0),\n",
    "            \"regime_gates\": json.dumps(rg_dict, default=str),\n",
    "            \"costs\": json.dumps(cost_snap.get(\"costs_by_symbol\", {}).get(sym, {}), default=str),\n",
    "            \"created_utc\": _now_utc_iso(),\n",
    "        }\n",
    "        deploy_rows.append(config)\n",
    "\n",
    "        # Per-symbol JSON\n",
    "        sym_json = DEPLOY_DIR / f\"{sym}_{side}_config.json\"\n",
    "        sym_json.write_text(json.dumps(config, indent=2, default=str), encoding=\"utf-8\")\n",
    "\n",
    "    deploy_df = pl.DataFrame(deploy_rows) if deploy_rows else pl.DataFrame()\n",
    "    deploy_df.write_parquet(str(OUT_DEPLOY), compression=\"zstd\")\n",
    "    Path(OUT_DEPLOY_JSON).write_text(json.dumps(deploy_rows, indent=2, default=str), encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"[Celda 18] {len(deploy_rows)} symbols deployed\")\n",
    "    print(f\"[Celda 18] OUT: {OUT_DEPLOY}\")\n",
    "    print(f\"[Celda 18] OUT: {DEPLOY_DIR}/\")\n",
    "\n",
    "print(\">>> Celda 18 v2.0.1 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be68f008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Celda 19 v2.0.1 :: QA Alpha<->Motor Alignment\n",
      "[Celda 19] OUT: C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\qa_alignment_v2.parquet (4 rows)\n",
      "  BNBUSD: alpha=LONG engine=LONG [OK]\n",
      "  BTCUSD: alpha=LONG engine=LONG [OK]\n",
      "  LVMH: alpha=SHORT engine=LONG [MISMATCH]\n",
      "  XAUAUD: alpha=LONG engine=LONG [OK]\n",
      ">>> Celda 19 v2.0.1 :: OK\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# Celda 19 v2.0.1 — QA Alpha<->Motor Alignment (OOS-first + mismatch report)\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 19 v2.0.1 :: QA Alpha<->Motor Alignment\")\n",
    "\n",
    "if \"RUN\" not in globals():\n",
    "    raise RuntimeError(\"[Celda 19] ERROR: RUN no existe.\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "\n",
    "ALPHA_PATH = ARTIFACTS.get(\"alpha_multi_horizon_report\", RUN_DIR / \"alpha_multi_horizon_report_v2.parquet\")\n",
    "TRADES_PATH = ARTIFACTS.get(\"trades_engine\", RUN_DIR / \"trades_engine_v2.parquet\")\n",
    "OUT_QA = ARTIFACTS.get(\"qa_alignment\", RUN_DIR / \"qa_alignment_v2.parquet\")\n",
    "OUT_SNAP = ARTIFACTS.get(\"qa_alignment_snapshot\", RUN_DIR / \"qa_alignment_snapshot_v2.json\")\n",
    "\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "if not ALPHA_PATH.exists() or not TRADES_PATH.exists():\n",
    "    print(\"[Celda 19] WARNING: faltan inputs, skip.\")\n",
    "    snap = {\"created_utc\": _now_utc_iso(), \"status\": \"SKIPPED\"}\n",
    "    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2), encoding=\"utf-8\")\n",
    "else:\n",
    "    alpha = pl.read_parquet(ALPHA_PATH)\n",
    "    trades = pl.read_parquet(TRADES_PATH)\n",
    "\n",
    "    qa_rows = []\n",
    "    if trades.height > 0 and alpha.height > 0:\n",
    "        a_oos = alpha.filter(pl.col(\"segment\") == \"OOS\")\n",
    "        t_oos = trades.filter(pl.col(\"segment\") == \"OOS\")\n",
    "\n",
    "        for sym in t_oos.get_column(\"symbol\").unique().sort().to_list():\n",
    "            # Best alpha side OOS\n",
    "            a_sym = a_oos.filter(pl.col(\"symbol\") == sym)\n",
    "            if a_sym.height == 0:\n",
    "                continue\n",
    "            best_alpha = a_sym.sort(\"sharpe_like\", descending=True).row(0, named=True)\n",
    "\n",
    "            # Engine best side OOS\n",
    "            t_sym = t_oos.filter(pl.col(\"symbol\") == sym)\n",
    "            if t_sym.height == 0:\n",
    "                continue\n",
    "            eng_sides = (\n",
    "                t_sym.group_by(\"side\")\n",
    "                .agg(pl.col(\"net_pnl_base\").sum().alias(\"tot\"))\n",
    "                .sort(\"tot\", descending=True)\n",
    "            )\n",
    "            eng_best_side = eng_sides.row(0, named=True)[\"side\"]\n",
    "\n",
    "            # Mismatch flags\n",
    "            hold_p90 = float(t_sym.get_column(\"hold_bars\").quantile(0.90, interpolation=\"nearest\"))\n",
    "            alpha_h = best_alpha[\"horizon_bars\"]\n",
    "            trail_share = t_sym.filter(pl.col(\"exit_reason\") == \"TRAIL\").height / max(1, t_sym.height)\n",
    "\n",
    "            qa_rows.append({\n",
    "                \"symbol\": sym,\n",
    "                \"alpha_best_side_oos\": best_alpha[\"side\"],\n",
    "                \"alpha_best_horizon_oos\": alpha_h,\n",
    "                \"alpha_sharpe_oos\": best_alpha[\"sharpe_like\"],\n",
    "                \"engine_best_side_oos\": eng_best_side,\n",
    "                \"side_mismatch\": best_alpha[\"side\"] != eng_best_side,\n",
    "                \"hold_p90_over_alphaH\": hold_p90 / alpha_h if alpha_h > 0 else None,\n",
    "                \"trail_dominates_short_hold\": trail_share > 0.40,\n",
    "                \"alpha_edge_nonpos_oos\": best_alpha[\"net_base_mean\"] <= 0 if \"net_base_mean\" in best_alpha else False,\n",
    "            })\n",
    "\n",
    "    qa_df = pl.DataFrame(qa_rows) if qa_rows else pl.DataFrame()\n",
    "    qa_df.write_parquet(str(OUT_QA), compression=\"zstd\")\n",
    "\n",
    "    snap = {\n",
    "        \"created_utc\": _now_utc_iso(), \"version\": \"v2.0.1\",\n",
    "        \"alignment_report\": qa_rows,\n",
    "    }\n",
    "    Path(OUT_SNAP).write_text(json.dumps(snap, indent=2, default=str), encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"[Celda 19] OUT: {OUT_QA} ({qa_df.height} rows)\")\n",
    "    if qa_rows:\n",
    "        for q in qa_rows:\n",
    "            mismatch = \"MISMATCH\" if q[\"side_mismatch\"] else \"OK\"\n",
    "            print(f\"  {q['symbol']}: alpha={q['alpha_best_side_oos']} engine={q['engine_best_side_oos']} [{mismatch}]\")\n",
    "\n",
    "print(\">>> Celda 19 v2.0.1 :: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2dd7ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Celda 20 v2.0.1 :: Run Summary + Manifest Final\n",
      "[Celda 20] Artifacts: 37 exist, 2 missing\n",
      "[Celda 20] MISSING: ['trades_baseline', 'summary_baseline']\n",
      "\n",
      "============================================================\n",
      "  RUN SUMMARY — TREND v2\n",
      "============================================================\n",
      "  run_id                        : 20260218_000143_164d8480\n",
      "  completion_utc                : 2026-02-18T00:02:20+00:00\n",
      "  symbols_go                    : 0\n",
      "  symbols_total                 : 8\n",
      "  best_sharpe                   : -0.0770189238547151\n",
      "  worst_mdd                     : -32.90706074948353\n",
      "  total_return                  : -32.219949031643154\n",
      "  artifacts_existing            : 37\n",
      "  artifacts_missing             : 2\n",
      "  artifacts_missing_keys        : ['trades_baseline', 'summary_baseline']\n",
      "============================================================\n",
      "[Celda 20] Manifest updated: C:\\Quant\\projects\\MT5_Data_Extraction\\outputs\\trend_v2\\run_20260218_000143_164d8480\\run_manifest_v2.json\n",
      ">>> Celda 20 v2.0.1 :: OK\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# Celda 20 v2.0.1 — Run Summary + Manifest Final\n",
    "# Verifica todos los artifacts, calcula resumen ejecutivo, cierra manifest.\n",
    "# ======================================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict\n",
    "import polars as pl\n",
    "\n",
    "print(\">>> Celda 20 v2.0.1 :: Run Summary + Manifest Final\")\n",
    "\n",
    "if \"RUN\" not in globals():\n",
    "    raise RuntimeError(\"[Celda 20] ERROR: RUN no existe.\")\n",
    "\n",
    "RUN_DIR: Path = RUN[\"RUN_DIR\"]\n",
    "ARTIFACTS: Dict[str, Path] = RUN[\"ARTIFACTS\"]\n",
    "RUN_ID = RUN[\"RUN_ID\"]\n",
    "\n",
    "def _now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "\n",
    "# Verify all artifacts exist\n",
    "missing = []\n",
    "existing = []\n",
    "for key, path in ARTIFACTS.items():\n",
    "    if Path(path).exists():\n",
    "        existing.append(key)\n",
    "    else:\n",
    "        missing.append(key)\n",
    "\n",
    "print(f\"[Celda 20] Artifacts: {len(existing)} exist, {len(missing)} missing\")\n",
    "if missing:\n",
    "    print(f\"[Celda 20] MISSING: {missing}\")\n",
    "\n",
    "# Summary stats\n",
    "summary = {\"run_id\": RUN_ID, \"completion_utc\": _now_utc_iso()}\n",
    "\n",
    "sel_path = ARTIFACTS.get(\"selection\", RUN_DIR / \"selection_v2.parquet\")\n",
    "if Path(sel_path).exists():\n",
    "    sel = pl.read_parquet(sel_path)\n",
    "    if sel.height > 0 and \"decision\" in sel.columns:\n",
    "        summary[\"symbols_go\"] = sel.filter(pl.col(\"decision\") == \"GO\").height\n",
    "        summary[\"symbols_total\"] = sel.height\n",
    "\n",
    "eng_snap_path = ARTIFACTS.get(\"engine_report_snapshot\", RUN_DIR / \"engine_report_snapshot_v2.json\")\n",
    "if Path(eng_snap_path).exists():\n",
    "    eng_snap = json.loads(Path(eng_snap_path).read_text(encoding=\"utf-8\"))\n",
    "    kpis = eng_snap.get(\"kpis\", {})\n",
    "    summary[\"best_sharpe\"] = kpis.get(\"sharpe_like\")\n",
    "    summary[\"worst_mdd\"] = kpis.get(\"mdd\")\n",
    "    summary[\"total_return\"] = kpis.get(\"total_return\")\n",
    "\n",
    "summary[\"artifacts_existing\"] = len(existing)\n",
    "summary[\"artifacts_missing\"] = len(missing)\n",
    "summary[\"artifacts_missing_keys\"] = missing\n",
    "\n",
    "# Update manifest\n",
    "manifest_path = RUN_DIR / \"run_manifest_v2.json\"\n",
    "if manifest_path.exists():\n",
    "    manifest = json.loads(manifest_path.read_text(encoding=\"utf-8\"))\n",
    "else:\n",
    "    manifest = {}\n",
    "\n",
    "manifest[\"completion_utc\"] = summary[\"completion_utc\"]\n",
    "manifest[\"summary\"] = summary\n",
    "manifest_path.write_text(json.dumps(manifest, indent=2, default=str), encoding=\"utf-8\")\n",
    "\n",
    "# Latest\n",
    "latest_path = RUN_DIR.parent / \"run_manifest_v2_latest.json\"\n",
    "latest_path.write_text(json.dumps(manifest, indent=2, default=str), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"  RUN SUMMARY — TREND v2\")\n",
    "print(f\"{'='*60}\")\n",
    "for k, v in summary.items():\n",
    "    print(f\"  {k:30s}: {v}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"[Celda 20] Manifest updated: {manifest_path}\")\n",
    "print(\">>> Celda 20 v2.0.1 :: OK\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1 (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}